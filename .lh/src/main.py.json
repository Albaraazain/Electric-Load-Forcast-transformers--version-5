{
    "sourceFile": "src/main.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 9,
            "patches": [
                {
                    "date": 1733311800828,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733315221125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,9 +132,10 @@\n         e_layers=config['e_layers'],\r\n         d_ff=config['d_ff'],\r\n         dropout=config['dropout'],\r\n         activation=config['activation'],\r\n-        distil=config['distil']\r\n+        distil=config['distil'],\r\n+        prediction_window=config['prediction_window']\r\n     ).to(device)\r\n     \r\n     optimizer = torch.optim.AdamW(\r\n         model.parameters(),\r\n"
                },
                {
                    "date": 1733316887740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,8 +147,12 @@\n     \r\n     return model, optimizer, criterion\r\n \r\n def main():\r\n+    \r\n+    torch.backends.cuda.max_split_size_mb = 128  # Helps prevent fragmentation\r\n+    torch.backends.cudnn.benchmark = True        # Optimize CUDA operations\r\n+    torch.backends.cudnn.deterministic = True    # More memory efficient\r\n     # Parse arguments\r\n     parser = argparse.ArgumentParser()\r\n     parser.add_argument('--config', type=str, required=True, help='Path to config file')\r\n     args = parser.parse_args()\r\n"
                },
                {
                    "date": 1733316899760,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,8 +151,11 @@\n     \r\n     torch.backends.cuda.max_split_size_mb = 128  # Helps prevent fragmentation\r\n     torch.backends.cudnn.benchmark = True        # Optimize CUDA operations\r\n     torch.backends.cudnn.deterministic = True    # More memory efficient\r\n+    \r\n+    scaler = torch.cuda.amp.GradScaler()\r\n+\r\n     # Parse arguments\r\n     parser = argparse.ArgumentParser()\r\n     parser.add_argument('--config', type=str, required=True, help='Path to config file')\r\n     args = parser.parse_args()\r\n"
                },
                {
                    "date": 1733317026663,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,8 +22,10 @@\n from utils.cuda_utils import verify_cuda_environment, get_device\r\n from utils.metrics import ModelEvaluator\r\n from utils.visualization import TimeSeriesVisualizer\r\n \r\n+os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\r\n+\r\n def setup_logging(config: dict):\r\n     \"\"\"Setup logging configuration\"\"\"\r\n     log_dir = config.get('log_dir', 'logs')\r\n     os.makedirs(log_dir, exist_ok=True)\r\n"
                },
                {
                    "date": 1733317192012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,8 +12,9 @@\n import torch\r\n import pandas as pd\r\n from torch.utils.data import DataLoader\r\n from datetime import datetime\r\n+from torch.cuda.amp import GradScaler\r\n \r\n from data.preprocessing import DataPreprocessor\r\n from data.dataset import InformerDataset, DatasetSplitter\r\n from model.informer import Informer\r\n@@ -154,10 +155,9 @@\n     torch.backends.cuda.max_split_size_mb = 128  # Helps prevent fragmentation\r\n     torch.backends.cudnn.benchmark = True        # Optimize CUDA operations\r\n     torch.backends.cudnn.deterministic = True    # More memory efficient\r\n     \r\n-    scaler = torch.cuda.amp.GradScaler()\r\n-\r\n+    scaler = GradScaler()\r\n     # Parse arguments\r\n     parser = argparse.ArgumentParser()\r\n     parser.add_argument('--config', type=str, required=True, help='Path to config file')\r\n     args = parser.parse_args()\r\n"
                },
                {
                    "date": 1733317348725,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n import torch\r\n import pandas as pd\r\n from torch.utils.data import DataLoader\r\n from datetime import datetime\r\n-from torch.cuda.amp import GradScaler\r\n+from torch.cuda.amp.grad_scaler import GradScaler\r\n \r\n from data.preprocessing import DataPreprocessor\r\n from data.dataset import InformerDataset, DatasetSplitter\r\n from model.informer import Informer\r\n@@ -150,13 +150,12 @@\n     \r\n     return model, optimizer, criterion\r\n \r\n def main():\r\n+    torch.cuda.set_per_process_memory_fraction(0.5)  # Helps prevent fragmentation\r\n+    torch.backends.cudnn.benchmark = True            # Optimize CUDA operations\r\n+    torch.backends.cudnn.deterministic = True        # More memory efficient\r\n     \r\n-    torch.backends.cuda.max_split_size_mb = 128  # Helps prevent fragmentation\r\n-    torch.backends.cudnn.benchmark = True        # Optimize CUDA operations\r\n-    torch.backends.cudnn.deterministic = True    # More memory efficient\r\n-    \r\n     scaler = GradScaler()\r\n     # Parse arguments\r\n     parser = argparse.ArgumentParser()\r\n     parser.add_argument('--config', type=str, required=True, help='Path to config file')\r\n"
                },
                {
                    "date": 1733318504491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,8 +13,10 @@\n import pandas as pd\r\n from torch.utils.data import DataLoader\r\n from datetime import datetime\r\n from torch.cuda.amp.grad_scaler import GradScaler\r\n+import torch.backends.cuda\r\n+import torch.backends.cudnn\r\n \r\n from data.preprocessing import DataPreprocessor\r\n from data.dataset import InformerDataset, DatasetSplitter\r\n from model.informer import Informer\r\n"
                },
                {
                    "date": 1733345428149,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,22 +209,33 @@\n     for metric_name, value in test_metrics.items():\r\n         logger.info(f\"{metric_name}: {value:.4f}\")\r\n     \r\n     # Visualize results\r\n-    visualizer = TimeSeriesVisualizer()\r\n-    \r\n+    visualizer = TimeSeriesVisualizer(figsize=(15, 7))\r\n+\r\n+    # Plot overall predictions\r\n+    pred_fig = visualizer.plot_predictions(\r\n+        true_values=targets,\r\n+        predictions=predictions,\r\n+        title=\"Overall Prediction Performance\"\r\n+    )\r\n+    visualizer.save_figure(pred_fig, os.path.join(config['output_dir'], 'predictions.png'))\r\n+\r\n+    # Plot sample predictions from batches\r\n+    batch_fig = visualizer.plot_batch_predictions(\r\n+        true_values=targets[:32],  # Take first batch\r\n+        predictions=predictions[:32],\r\n+        n_samples=5,\r\n+        title=\"Sample Prediction Cases\"\r\n+    )\r\n+    visualizer.save_figure(batch_fig, os.path.join(config['output_dir'], 'sample_predictions.png'))\r\n+\r\n     # Plot training history\r\n-    history_fig = visualizer.plot_training_history(train_losses, val_losses)\r\n-    visualizer.save_figure(\r\n-        history_fig,\r\n-        os.path.join(config['output_dir'], 'training_history.png')\r\n+    history_fig = visualizer.plot_training_history(\r\n+        train_losses=train_losses,\r\n+        val_losses=val_losses\r\n     )\r\n-    \r\n-    # Plot predictions\r\n-    pred_fig = visualizer.plot_predictions(targets, predictions)\r\n-    visualizer.save_figure(\r\n-        pred_fig,\r\n-        os.path.join(config['output_dir'], 'predictions.png')\r\n+    visualizer.save_figure(history_fig, os.path.join(config['output_dir'], 'training_history.png'))\r\n     )\r\n     \r\n     logger.info(\"Training completed successfully!\")\r\n \r\n"
                },
                {
                    "date": 1733346714897,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -183,20 +183,24 @@\n     \r\n     # Initialize model\r\n     model, optimizer, criterion = init_model(config, device)\r\n     \r\n-    # Initialize trainer\r\n+    # Initialize visualizer early\r\n+    visualizer = TimeSeriesVisualizer(figsize=(15, 7))\r\n+    \r\n+    # Initialize trainer with visualizer\r\n     trainer = Trainer(\r\n         model=model,\r\n         train_loader=train_loader,\r\n         val_loader=val_loader,\r\n         optimizer=optimizer,\r\n         criterion=criterion,\r\n         config=config,\r\n-        device=device\r\n+        device=device,\r\n+        visualizer=visualizer  # Pass visualizer to trainer\r\n     )\r\n     \r\n-    # Train model\r\n+    # Train model (now includes per-epoch visualization)\r\n     logger.info(\"Starting training...\")\r\n     train_losses, val_losses = trainer.train()\r\n     \r\n     # Evaluate model\r\n"
                }
            ],
            "date": 1733311800828,
            "name": "Commit-0",
            "content": "\"\"\"\r\nMain training script for the Informer model.\r\n\r\nUsage:\r\n    python main.py --config config.yaml\r\n\"\"\"\r\n\r\nimport os\r\nimport argparse\r\nimport yaml\r\nimport logging\r\nimport torch\r\nimport pandas as pd\r\nfrom torch.utils.data import DataLoader\r\nfrom datetime import datetime\r\n\r\nfrom data.preprocessing import DataPreprocessor\r\nfrom data.dataset import InformerDataset, DatasetSplitter\r\nfrom model.informer import Informer\r\nfrom model.config import InformerConfig\r\nfrom training.trainer import Trainer\r\nfrom utils.cuda_utils import verify_cuda_environment, get_device\r\nfrom utils.metrics import ModelEvaluator\r\nfrom utils.visualization import TimeSeriesVisualizer\r\n\r\ndef setup_logging(config: dict):\r\n    \"\"\"Setup logging configuration\"\"\"\r\n    log_dir = config.get('log_dir', 'logs')\r\n    os.makedirs(log_dir, exist_ok=True)\r\n    \r\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\r\n    log_file = os.path.join(log_dir, f'training_{timestamp}.log')\r\n    \r\n    logging.basicConfig(\r\n        level=logging.INFO,\r\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\r\n        handlers=[\r\n            logging.FileHandler(log_file),\r\n            logging.StreamHandler()\r\n        ]\r\n    )\r\n    return logging.getLogger(__name__)\r\n\r\ndef load_config(config_path: str) -> dict:\r\n    \"\"\"Load configuration from YAML file\"\"\"\r\n    with open(config_path, 'r') as f:\r\n        config = yaml.safe_load(f)\r\n    return config\r\n\r\ndef prepare_data(config: dict, logger: logging.Logger):\r\n    \"\"\"Prepare datasets and dataloaders\"\"\"\r\n    logger.info(\"Loading and preprocessing data...\")\r\n    \r\n    # Load data\r\n    df = pd.read_csv(config['data_path'], parse_dates=[config['timestamp_col']])\r\n    \r\n    # Initialize preprocessor\r\n    preprocessor = DataPreprocessor()\r\n    \r\n    # Preprocess data\r\n    features, preprocess_info = preprocessor.preprocess(\r\n        df,\r\n        timestamp_col=config['timestamp_col'],\r\n        target_col=config['target_col'],\r\n        is_training=True\r\n    )\r\n    \r\n    # Split data\r\n    train_data, val_data, test_data = DatasetSplitter.split_data(\r\n        features,\r\n        train_ratio=config['train_ratio'],\r\n        val_ratio=config['val_ratio'],\r\n        test_ratio=config['test_ratio']\r\n    )\r\n    \r\n    # Create datasets\r\n    train_dataset = InformerDataset(\r\n        train_data,\r\n        input_window=config['input_window'],\r\n        prediction_window=config['prediction_window'],\r\n        stride=config['stride']\r\n    )\r\n    \r\n    val_dataset = InformerDataset(\r\n        val_data,\r\n        input_window=config['input_window'],\r\n        prediction_window=config['prediction_window'],\r\n        stride=config['stride']\r\n    )\r\n    \r\n    test_dataset = InformerDataset(\r\n        test_data,\r\n        input_window=config['input_window'],\r\n        prediction_window=config['prediction_window'],\r\n        stride=config['stride']\r\n    )\r\n    \r\n    # Create dataloaders\r\n    train_loader = DataLoader(\r\n        train_dataset,\r\n        batch_size=config['batch_size'],\r\n        shuffle=True,\r\n        num_workers=config['num_workers'],\r\n        pin_memory=True\r\n    )\r\n    \r\n    val_loader = DataLoader(\r\n        val_dataset,\r\n        batch_size=config['batch_size'],\r\n        shuffle=False,\r\n        num_workers=config['num_workers'],\r\n        pin_memory=True\r\n    )\r\n    \r\n    test_loader = DataLoader(\r\n        test_dataset,\r\n        batch_size=config['batch_size'],\r\n        shuffle=False,\r\n        num_workers=config['num_workers'],\r\n        pin_memory=True\r\n    )\r\n    \r\n    return train_loader, val_loader, test_loader, preprocessor\r\n\r\ndef init_model(config: dict, device: torch.device):\r\n    \"\"\"Initialize model and optimizer\"\"\"\r\n    model = Informer(\r\n        input_dim=config['input_dim'],\r\n        output_dim=config['output_dim'],\r\n        d_model=config['d_model'],\r\n        n_heads=config['n_heads'],\r\n        e_layers=config['e_layers'],\r\n        d_ff=config['d_ff'],\r\n        dropout=config['dropout'],\r\n        activation=config['activation'],\r\n        distil=config['distil']\r\n    ).to(device)\r\n    \r\n    optimizer = torch.optim.AdamW(\r\n        model.parameters(),\r\n        lr=config['learning_rate'],\r\n        weight_decay=config['weight_decay']\r\n    )\r\n    \r\n    criterion = torch.nn.MSELoss()\r\n    \r\n    return model, optimizer, criterion\r\n\r\ndef main():\r\n    # Parse arguments\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--config', type=str, required=True, help='Path to config file')\r\n    args = parser.parse_args()\r\n    \r\n    # Load configuration\r\n    config = load_config(args.config)\r\n    \r\n    # Setup logging\r\n    logger = setup_logging(config)\r\n    \r\n    # Check CUDA environment\r\n    device = get_device(use_cuda=config['use_cuda'])\r\n    logger.info(\"CUDA Environment:\")\r\n    logger.info(verify_cuda_environment())\r\n    \r\n    # Create output directories\r\n    os.makedirs(config['checkpoint_dir'], exist_ok=True)\r\n    os.makedirs(config['output_dir'], exist_ok=True)\r\n    \r\n    # Prepare data\r\n    train_loader, val_loader, test_loader, preprocessor = prepare_data(config, logger)\r\n    \r\n    # Initialize model\r\n    model, optimizer, criterion = init_model(config, device)\r\n    \r\n    # Initialize trainer\r\n    trainer = Trainer(\r\n        model=model,\r\n        train_loader=train_loader,\r\n        val_loader=val_loader,\r\n        optimizer=optimizer,\r\n        criterion=criterion,\r\n        config=config,\r\n        device=device\r\n    )\r\n    \r\n    # Train model\r\n    logger.info(\"Starting training...\")\r\n    train_losses, val_losses = trainer.train()\r\n    \r\n    # Evaluate model\r\n    logger.info(\"Evaluating model...\")\r\n    evaluator = ModelEvaluator(model, device)\r\n    test_metrics, predictions, targets = evaluator.evaluate(test_loader)\r\n    \r\n    # Log results\r\n    logger.info(\"Test Metrics:\")\r\n    for metric_name, value in test_metrics.items():\r\n        logger.info(f\"{metric_name}: {value:.4f}\")\r\n    \r\n    # Visualize results\r\n    visualizer = TimeSeriesVisualizer()\r\n    \r\n    # Plot training history\r\n    history_fig = visualizer.plot_training_history(train_losses, val_losses)\r\n    visualizer.save_figure(\r\n        history_fig,\r\n        os.path.join(config['output_dir'], 'training_history.png')\r\n    )\r\n    \r\n    # Plot predictions\r\n    pred_fig = visualizer.plot_predictions(targets, predictions)\r\n    visualizer.save_figure(\r\n        pred_fig,\r\n        os.path.join(config['output_dir'], 'predictions.png')\r\n    )\r\n    \r\n    logger.info(\"Training completed successfully!\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()"
        }
    ]
}