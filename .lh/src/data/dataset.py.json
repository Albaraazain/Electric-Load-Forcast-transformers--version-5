{
    "sourceFile": "src/data/dataset.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1733311619267,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733312500723,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,21 +79,9 @@\n         return len(self.indices)\r\n \r\n     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\r\n         \"\"\"\r\n-        Get a single sample\r\n-\r\n-        Args:\r\n-            idx: Index of the sequence to retrieve\r\n-\r\n-        Returns:\r\n-            Tuple of (encoder_input, decoder_input, target)\r\n-            - encoder_input: Input sequence [input_window, feature_dim]\r\n-            - decoder_input: Decoder input sequence [prediction_window, feature_dim]\r\n-            - target: Target values [prediction_window, 1]\r\n-\r\n-        Note:\r\n-            All tensors are returned as float32 for compatibility\r\n+        Get a single sample with enhanced debugging\r\n         \"\"\"\r\n         start_idx = self.indices[idx]\r\n         end_idx = start_idx + self.input_window + self.prediction_window\r\n \r\n@@ -103,14 +91,19 @@\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n         target_seq = sequence[self.input_window:end_idx]\r\n \r\n-        # For decoder input, we use all features but shifted by one\r\n-        decoder_input = target_seq[:-1]\r\n-        target = target_seq[1:, 0:1]  # Only use first feature (energy consumption) as target\r\n+        # For decoder input, adjust to match expected output length\r\n+        decoder_input = target_seq[:-1]  # Remove last timestep\r\n+        target = target_seq[1:]  # Remove first timestep\r\n \r\n+        # Add assertions for debugging\r\n+        assert input_seq.size(0) == self.input_window, \\\r\n+            f\"Input sequence length mismatch: {input_seq.size(0)} vs {self.input_window}\"\r\n+        assert target.size(0) == self.prediction_window - 1, \\\r\n+            f\"Target sequence length mismatch: {target.size(0)} vs {self.prediction_window - 1}\"\r\n+\r\n         return input_seq, decoder_input, target\r\n-\r\n class DatasetSplitter:\r\n     \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n \r\n     @staticmethod\r\n"
                },
                {
                    "date": 1733312732678,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,29 +27,17 @@\n             input_window: int,\r\n             prediction_window: int,\r\n             stride: int = 1\r\n     ):\r\n-        \"\"\"\r\n-        Initialize dataset\r\n-\r\n-        Args:\r\n-            data: Tensor of shape [sequence_length, feature_dim]\r\n-            input_window: Number of input timesteps\r\n-            prediction_window: Number of timesteps to predict\r\n-            stride: Stride for sliding window\r\n-\r\n-        Note:\r\n-            Using PyTorch 2.4.1 features for optimized tensor operations\r\n-        \"\"\"\r\n         super().__init__()\r\n         self.data = data\r\n         self.input_window = input_window\r\n         self.prediction_window = prediction_window\r\n         self.stride = stride\r\n-\r\n+        \r\n         # Calculate valid indices\r\n         self.indices = self._generate_indices()\r\n-\r\n+        \r\n         # Validate tensor device and dtype\r\n         self._validate_tensor()\r\n \r\n     def _validate_tensor(self):\r\n"
                },
                {
                    "date": 1733312755906,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,31 +67,37 @@\n         return len(self.indices)\r\n \r\n     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\r\n         \"\"\"\r\n-        Get a single sample with enhanced debugging\r\n+        Get a single sample with fixed dimensions\r\n+        \r\n+        Returns:\r\n+            Tuple of (encoder_input, decoder_input, target)\r\n+            - encoder_input: [input_window, feature_dim]\r\n+            - decoder_input: [prediction_window-1, feature_dim]\r\n+            - target: [prediction_window-1, 1]  # Only energy consumption as target\r\n         \"\"\"\r\n         start_idx = self.indices[idx]\r\n         end_idx = start_idx + self.input_window + self.prediction_window\r\n-\r\n+        \r\n         # Get full sequence\r\n         sequence = self.data[start_idx:end_idx]\r\n-\r\n+        \r\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n         target_seq = sequence[self.input_window:end_idx]\r\n-\r\n-        # For decoder input, adjust to match expected output length\r\n+        \r\n+        # Prepare decoder input (all features) and target (only energy consumption)\r\n         decoder_input = target_seq[:-1]  # Remove last timestep\r\n-        target = target_seq[1:]  # Remove first timestep\r\n-\r\n+        target = target_seq[1:, 0:1]  # Only first feature (energy consumption) and remove first timestep\r\n+        \r\n         # Add assertions for debugging\r\n-        assert input_seq.size(0) == self.input_window, \\\r\n-            f\"Input sequence length mismatch: {input_seq.size(0)} vs {self.input_window}\"\r\n-        assert target.size(0) == self.prediction_window - 1, \\\r\n-            f\"Target sequence length mismatch: {target.size(0)} vs {self.prediction_window - 1}\"\r\n-\r\n+        assert input_seq.size(0) == self.input_window, f\"Input sequence length mismatch: {input_seq.size(0)} vs {self.input_window}\"\r\n+        assert decoder_input.size(0) == self.prediction_window - 1, f\"Decoder input length mismatch: {decoder_input.size(0)} vs {self.prediction_window - 1}\"\r\n+        assert target.size(0) == self.prediction_window - 1, f\"Target length mismatch: {target.size(0)} vs {self.prediction_window - 1}\"\r\n+        \r\n         return input_seq, decoder_input, target\r\n+    \r\n class DatasetSplitter:\r\n     \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n \r\n     @staticmethod\r\n"
                },
                {
                    "date": 1733314662746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,18 +65,9 @@\n     def __len__(self) -> int:\r\n         \"\"\"Return the number of sequences in the dataset\"\"\"\r\n         return len(self.indices)\r\n \r\n-    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\r\n-        \"\"\"\r\n-        Get a single sample with fixed dimensions\r\n-        \r\n-        Returns:\r\n-            Tuple of (encoder_input, decoder_input, target)\r\n-            - encoder_input: [input_window, feature_dim]\r\n-            - decoder_input: [prediction_window-1, feature_dim]\r\n-            - target: [prediction_window-1, 1]  # Only energy consumption as target\r\n-        \"\"\"\r\n+    def __getitem__(self, idx: int):\r\n         start_idx = self.indices[idx]\r\n         end_idx = start_idx + self.input_window + self.prediction_window\r\n         \r\n         # Get full sequence\r\n@@ -85,16 +76,14 @@\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n         target_seq = sequence[self.input_window:end_idx]\r\n         \r\n-        # Prepare decoder input (all features) and target (only energy consumption)\r\n+        # Prepare decoder input and target\r\n         decoder_input = target_seq[:-1]  # Remove last timestep\r\n-        target = target_seq[1:, 0:1]  # Only first feature (energy consumption) and remove first timestep\r\n+        target = target_seq[1:, 0:1]  # Only energy consumption and remove first timestep\r\n         \r\n-        # Add assertions for debugging\r\n-        assert input_seq.size(0) == self.input_window, f\"Input sequence length mismatch: {input_seq.size(0)} vs {self.input_window}\"\r\n-        assert decoder_input.size(0) == self.prediction_window - 1, f\"Decoder input length mismatch: {decoder_input.size(0)} vs {self.prediction_window - 1}\"\r\n-        assert target.size(0) == self.prediction_window - 1, f\"Target length mismatch: {target.size(0)} vs {self.prediction_window - 1}\"\r\n+        # Ensure target length matches model output\r\n+        target = target[:self.prediction_window-1]  # Truncate to prediction window\r\n         \r\n         return input_seq, decoder_input, target\r\n     \r\n class DatasetSplitter:\r\n"
                },
                {
                    "date": 1733314806704,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,22 +69,34 @@\n     def __getitem__(self, idx: int):\r\n         start_idx = self.indices[idx]\r\n         end_idx = start_idx + self.input_window + self.prediction_window\r\n         \r\n+        # Add debugging prints\r\n+        print(f\"Debug - Sequence lengths:\")\r\n+        print(f\"start_idx: {start_idx}, end_idx: {end_idx}\")\r\n+        \r\n         # Get full sequence\r\n         sequence = self.data[start_idx:end_idx]\r\n+        print(f\"Full sequence shape: {sequence.shape}\")\r\n         \r\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n         target_seq = sequence[self.input_window:end_idx]\r\n         \r\n+        print(f\"Input sequence shape: {input_seq.shape}\")\r\n+        print(f\"Target sequence shape: {target_seq.shape}\")\r\n+        \r\n         # Prepare decoder input and target\r\n-        decoder_input = target_seq[:-1]  # Remove last timestep\r\n-        target = target_seq[1:, 0:1]  # Only energy consumption and remove first timestep\r\n+        decoder_input = target_seq[:-1]\r\n+        target = target_seq[1:, 0:1]\r\n         \r\n-        # Ensure target length matches model output\r\n-        target = target[:self.prediction_window-1]  # Truncate to prediction window\r\n+        print(f\"Decoder input shape: {decoder_input.shape}\")\r\n+        print(f\"Target shape: {target.shape}\")\r\n         \r\n+        # Make sure output and target lengths match\r\n+        if decoder_input.size(0) != target.size(0):\r\n+            print(\"WARNING: Decoder input and target lengths don't match!\")\r\n+        \r\n         return input_seq, decoder_input, target\r\n     \r\n class DatasetSplitter:\r\n     \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n"
                },
                {
                    "date": 1733315390210,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,36 +67,27 @@\n         return len(self.indices)\r\n \r\n     def __getitem__(self, idx: int):\r\n         start_idx = self.indices[idx]\r\n-        end_idx = start_idx + self.input_window + self.prediction_window\r\n+        end_idx = start_idx + self.input_window + self.prediction_window - 1  # Subtract 1 to get correct total length\r\n         \r\n-        # Add debugging prints\r\n-        print(f\"Debug - Sequence lengths:\")\r\n-        print(f\"start_idx: {start_idx}, end_idx: {end_idx}\")\r\n-        \r\n         # Get full sequence\r\n         sequence = self.data[start_idx:end_idx]\r\n-        print(f\"Full sequence shape: {sequence.shape}\")\r\n         \r\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n-        target_seq = sequence[self.input_window:end_idx]\r\n+        target_seq = sequence[self.input_window:]  # Rest is target sequence\r\n         \r\n-        print(f\"Input sequence shape: {input_seq.shape}\")\r\n-        print(f\"Target sequence shape: {target_seq.shape}\")\r\n-        \r\n         # Prepare decoder input and target\r\n-        decoder_input = target_seq[:-1]\r\n-        target = target_seq[1:, 0:1]\r\n+        decoder_input = target_seq[:-1]  # All but last timestep\r\n+        target = target_seq[1:, 0:1]  # From second timestep onwards, only first feature\r\n         \r\n-        print(f\"Decoder input shape: {decoder_input.shape}\")\r\n-        print(f\"Target shape: {target.shape}\")\r\n+        # Add assertions for debugging\r\n+        assert decoder_input.size(0) == self.prediction_window - 2, \\\r\n+            f\"Decoder input length {decoder_input.size(0)} != prediction_window-2 {self.prediction_window-2}\"\r\n+        assert target.size(0) == self.prediction_window - 2, \\\r\n+            f\"Target length {target.size(0)} != prediction_window-2 {self.prediction_window-2}\"\r\n         \r\n-        # Make sure output and target lengths match\r\n-        if decoder_input.size(0) != target.size(0):\r\n-            print(\"WARNING: Decoder input and target lengths don't match!\")\r\n-        \r\n         return input_seq, decoder_input, target\r\n     \r\n class DatasetSplitter:\r\n     \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n"
                },
                {
                    "date": 1733318611361,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,13 +15,9 @@\n \r\n class InformerDataset(Dataset):\r\n     \"\"\"\r\n     Dataset for Informer model with sliding window\r\n-\r\n-    Dependencies:\r\n-        - torch>=2.4.1 for tensor operations\r\n     \"\"\"\r\n-\r\n     def __init__(\r\n             self,\r\n             data: torch.Tensor,\r\n             input_window: int,\r\n@@ -47,14 +43,9 @@\n         if self.data.dtype != torch.float32:\r\n             self.data = self.data.float()\r\n \r\n     def _generate_indices(self) -> list:\r\n-        \"\"\"\r\n-        Generate valid start indices for windows\r\n-\r\n-        Returns:\r\n-            List of valid starting indices\r\n-        \"\"\"\r\n+        \"\"\"Generate valid start indices for windows\"\"\"\r\n         valid_indices = []\r\n         total_window = self.input_window + self.prediction_window\r\n \r\n         for i in range(0, len(self.data) - total_window + 1, self.stride):\r\n@@ -67,26 +58,26 @@\n         return len(self.indices)\r\n \r\n     def __getitem__(self, idx: int):\r\n         start_idx = self.indices[idx]\r\n-        end_idx = start_idx + self.input_window + self.prediction_window - 1  # Subtract 1 to get correct total length\r\n+        end_idx = start_idx + self.input_window + self.prediction_window\r\n         \r\n         # Get full sequence\r\n         sequence = self.data[start_idx:end_idx]\r\n         \r\n         # Split into input and target windows\r\n         input_seq = sequence[:self.input_window]\r\n-        target_seq = sequence[self.input_window:]  # Rest is target sequence\r\n+        target_seq = sequence[self.input_window:]\r\n         \r\n-        # Prepare decoder input and target\r\n+        # We need to adjust both decoder_input and target for the -2 reduction in the model\r\n         decoder_input = target_seq[:-1]  # All but last timestep\r\n         target = target_seq[1:, 0:1]  # From second timestep onwards, only first feature\r\n         \r\n         # Add assertions for debugging\r\n-        assert decoder_input.size(0) == self.prediction_window - 2, \\\r\n-            f\"Decoder input length {decoder_input.size(0)} != prediction_window-2 {self.prediction_window-2}\"\r\n-        assert target.size(0) == self.prediction_window - 2, \\\r\n-            f\"Target length {target.size(0)} != prediction_window-2 {self.prediction_window-2}\"\r\n+        assert decoder_input.size(0) == self.prediction_window - 1, \\\r\n+            f\"Decoder input length {decoder_input.size(0)} != prediction_window-1 {self.prediction_window-1}\"\r\n+        assert target.size(0) == self.prediction_window - 1, \\\r\n+            f\"Target length {target.size(0)} != prediction_window-1 {self.prediction_window-1}\"\r\n         \r\n         return input_seq, decoder_input, target\r\n     \r\n class DatasetSplitter:\r\n"
                },
                {
                    "date": 1733337827051,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,13 @@\n         self.input_window = input_window\r\n         self.prediction_window = prediction_window\r\n         self.stride = stride\r\n         \r\n+        print(f\"Dataset initialized with:\")\r\n+        print(f\"Input window: {input_window}\")\r\n+        print(f\"Prediction window: {prediction_window}\")\r\n+        print(f\"Data shape: {data.shape}\")\r\n+        \r\n         # Calculate valid indices\r\n         self.indices = self._generate_indices()\r\n         \r\n         # Validate tensor device and dtype\r\n@@ -63,22 +68,33 @@\n         \r\n         # Get full sequence\r\n         sequence = self.data[start_idx:end_idx]\r\n         \r\n-        # Split into input and target windows\r\n-        input_seq = sequence[:self.input_window]\r\n-        target_seq = sequence[self.input_window:]\r\n+        # Debug prints for first batch only\r\n+        if idx == 0:\r\n+            print(f\"\\nDataset Debug for batch 0:\")\r\n+            print(f\"Sequence shape: {sequence.shape}\")\r\n+            \r\n+            # Split into input and target windows\r\n+            input_seq = sequence[:self.input_window]\r\n+            target_seq = sequence[self.input_window:]\r\n+            \r\n+            print(f\"Input sequence shape: {input_seq.shape}\")\r\n+            print(f\"Target sequence full shape: {target_seq.shape}\")\r\n+            \r\n+            # Calculate and show shapes before final adjustments\r\n+            decoder_input = target_seq[:-1]\r\n+            target = target_seq[1:, 0:1]\r\n+            \r\n+            print(f\"Final decoder input shape: {decoder_input.shape}\")\r\n+            print(f\"Final target shape: {target.shape}\")\r\n+            print(\"=\" * 50)\r\n+        else:\r\n+            input_seq = sequence[:self.input_window]\r\n+            target_seq = sequence[self.input_window:]\r\n+            decoder_input = target_seq[:-1]\r\n+            target = target_seq[1:, 0:1]\r\n         \r\n-        # We need to adjust both decoder_input and target for the -2 reduction in the model\r\n-        decoder_input = target_seq[:-1]  # All but last timestep\r\n-        target = target_seq[1:, 0:1]  # From second timestep onwards, only first feature\r\n-        \r\n-        # Add assertions for debugging\r\n-        assert decoder_input.size(0) == self.prediction_window - 1, \\\r\n-            f\"Decoder input length {decoder_input.size(0)} != prediction_window-1 {self.prediction_window-1}\"\r\n-        assert target.size(0) == self.prediction_window - 1, \\\r\n-            f\"Target length {target.size(0)} != prediction_window-1 {self.prediction_window-1}\"\r\n-        \r\n         return input_seq, decoder_input, target\r\n     \r\n class DatasetSplitter:\r\n     \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n"
                }
            ],
            "date": 1733311619267,
            "name": "Commit-0",
            "content": "\"\"\"\r\nDataset implementation for the Informer model.\r\n\r\nDependencies:\r\n- torch>=2.4.1\r\n- numpy>=1.24.3\r\n\"\"\"\r\n\r\nimport torch\r\nfrom torch.utils.data import Dataset\r\nfrom typing import Tuple, Optional\r\nimport numpy as np\r\n\r\n__version__ = '1.0.0'\r\n\r\nclass InformerDataset(Dataset):\r\n    \"\"\"\r\n    Dataset for Informer model with sliding window\r\n\r\n    Dependencies:\r\n        - torch>=2.4.1 for tensor operations\r\n    \"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            data: torch.Tensor,\r\n            input_window: int,\r\n            prediction_window: int,\r\n            stride: int = 1\r\n    ):\r\n        \"\"\"\r\n        Initialize dataset\r\n\r\n        Args:\r\n            data: Tensor of shape [sequence_length, feature_dim]\r\n            input_window: Number of input timesteps\r\n            prediction_window: Number of timesteps to predict\r\n            stride: Stride for sliding window\r\n\r\n        Note:\r\n            Using PyTorch 2.4.1 features for optimized tensor operations\r\n        \"\"\"\r\n        super().__init__()\r\n        self.data = data\r\n        self.input_window = input_window\r\n        self.prediction_window = prediction_window\r\n        self.stride = stride\r\n\r\n        # Calculate valid indices\r\n        self.indices = self._generate_indices()\r\n\r\n        # Validate tensor device and dtype\r\n        self._validate_tensor()\r\n\r\n    def _validate_tensor(self):\r\n        \"\"\"Validate input tensor properties\"\"\"\r\n        if not isinstance(self.data, torch.Tensor):\r\n            raise TypeError(\"Data must be a PyTorch tensor\")\r\n        if self.data.dtype != torch.float32:\r\n            self.data = self.data.float()\r\n\r\n    def _generate_indices(self) -> list:\r\n        \"\"\"\r\n        Generate valid start indices for windows\r\n\r\n        Returns:\r\n            List of valid starting indices\r\n        \"\"\"\r\n        valid_indices = []\r\n        total_window = self.input_window + self.prediction_window\r\n\r\n        for i in range(0, len(self.data) - total_window + 1, self.stride):\r\n            valid_indices.append(i)\r\n\r\n        return valid_indices\r\n\r\n    def __len__(self) -> int:\r\n        \"\"\"Return the number of sequences in the dataset\"\"\"\r\n        return len(self.indices)\r\n\r\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\r\n        \"\"\"\r\n        Get a single sample\r\n\r\n        Args:\r\n            idx: Index of the sequence to retrieve\r\n\r\n        Returns:\r\n            Tuple of (encoder_input, decoder_input, target)\r\n            - encoder_input: Input sequence [input_window, feature_dim]\r\n            - decoder_input: Decoder input sequence [prediction_window, feature_dim]\r\n            - target: Target values [prediction_window, 1]\r\n\r\n        Note:\r\n            All tensors are returned as float32 for compatibility\r\n        \"\"\"\r\n        start_idx = self.indices[idx]\r\n        end_idx = start_idx + self.input_window + self.prediction_window\r\n\r\n        # Get full sequence\r\n        sequence = self.data[start_idx:end_idx]\r\n\r\n        # Split into input and target windows\r\n        input_seq = sequence[:self.input_window]\r\n        target_seq = sequence[self.input_window:end_idx]\r\n\r\n        # For decoder input, we use all features but shifted by one\r\n        decoder_input = target_seq[:-1]\r\n        target = target_seq[1:, 0:1]  # Only use first feature (energy consumption) as target\r\n\r\n        return input_seq, decoder_input, target\r\n\r\nclass DatasetSplitter:\r\n    \"\"\"Handles splitting data into train/val/test sets\"\"\"\r\n\r\n    @staticmethod\r\n    def split_data(\r\n            data: torch.Tensor,\r\n            train_ratio: float = 0.7,\r\n            val_ratio: float = 0.15,\r\n            test_ratio: float = 0.15\r\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\r\n        \"\"\"\r\n        Split data into train/val/test sets\r\n\r\n        Args:\r\n            data: Input tensor to split\r\n            train_ratio: Ratio of data for training\r\n            val_ratio: Ratio of data for validation\r\n            test_ratio: Ratio of data for testing\r\n\r\n        Returns:\r\n            Tuple of (train_data, val_data, test_data)\r\n\r\n        Raises:\r\n            AssertionError: If ratios don't sum to 1\r\n            TypeError: If input is not a PyTorch tensor\r\n        \"\"\"\r\n        if not isinstance(data, torch.Tensor):\r\n            raise TypeError(\"Input must be a PyTorch tensor\")\r\n\r\n        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1\"\r\n\r\n        n = len(data)\r\n        train_size = int(n * train_ratio)\r\n        val_size = int(n * val_ratio)\r\n\r\n        train_data = data[:train_size]\r\n        val_data = data[train_size:train_size + val_size]\r\n        test_data = data[train_size + val_size:]\r\n\r\n        return train_data, val_data, test_data"
        }
    ]
}