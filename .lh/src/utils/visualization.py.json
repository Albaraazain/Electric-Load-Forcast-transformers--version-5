{
    "sourceFile": "src/utils/visualization.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 15,
            "patches": [
                {
                    "date": 1733311728768,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733311945717,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,190 @@\n+\"\"\"\r\n+Visualization utilities for time series forecasting.\r\n+\r\n+Dependencies:\r\n+- matplotlib>=3.7.2\r\n+- seaborn>=0.12.2\r\n+\"\"\"\r\n+\r\n+import matplotlib.pyplot as plt\r\n+import seaborn as sns\r\n+import numpy as np\r\n+from typing import List, Optional, Tuple\r\n+import torch\r\n+\r\n+class TimeSeriesVisualizer:\r\n+    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n+    \r\n+    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n+        \"\"\"\r\n+        Initialize visualizer\r\n+        \r\n+        Args:\r\n+            figsize: Default figure size for plots\r\n+        \"\"\"\r\n+        self.figsize = figsize\r\n+        # Set style\r\n+        sns.set_style(\"whitegrid\")\r\n+        plt.rcParams['figure.figsize'] = figsize\r\n+        \r\n+    def plot_training_history(\r\n+        self,\r\n+        train_losses: List[float],\r\n+        val_losses: List[float],\r\n+        title: str = \"Training History\"\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot training and validation losses\r\n+        \r\n+        Args:\r\n+            train_losses: List of training losses\r\n+            val_losses: List of validation losses\r\n+            title: Plot title\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        epochs = range(1, len(train_losses) + 1)\r\n+        \r\n+        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n+        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n+        \r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Epoch')\r\n+        ax.set_ylabel('Loss')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        return fig\r\n+    \r\n+    def plot_predictions(\r\n+        self,\r\n+        true_values: torch.Tensor,\r\n+        predictions: torch.Tensor,\r\n+        timestamps: Optional[List] = None,\r\n+        title: str = \"Predictions vs Actual\"\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot predictions against actual values\r\n+        \r\n+        Args:\r\n+            true_values: Ground truth values\r\n+            predictions: Model predictions\r\n+            timestamps: Optional list of timestamps\r\n+            title: Plot title\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        # Convert to numpy if tensors\r\n+        if isinstance(true_values, torch.Tensor):\r\n+            true_values = true_values.cpu().numpy()\r\n+        if isinstance(predictions, torch.Tensor):\r\n+            predictions = predictions.cpu().numpy()\r\n+            \r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n+        \r\n+        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n+        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n+        \r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n+        ax.set_ylabel('Value')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        # Rotate x-axis labels if timestamps are provided\r\n+        if timestamps is not None:\r\n+            plt.xticks(rotation=45)\r\n+            \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    def plot_attention_weights(\r\n+        self,\r\n+        attention_weights: torch.Tensor,\r\n+        index: int = 0\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot attention weights heatmap\r\n+        \r\n+        Args:\r\n+            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n+            index: Batch index to plot\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        # Get weights for specified batch\r\n+        weights = attention_weights[index].cpu().numpy()\r\n+        \r\n+        # Create subplot for each attention head\r\n+        n_heads = weights.shape[0]\r\n+        fig, axes = plt.subplots(\r\n+            1, n_heads,\r\n+            figsize=(4 * n_heads, 4),\r\n+            squeeze=False\r\n+        )\r\n+        \r\n+        for i, ax in enumerate(axes[0]):\r\n+            sns.heatmap(\r\n+                weights[i],\r\n+                ax=ax,\r\n+                cmap='viridis',\r\n+                cbar=True\r\n+            )\r\n+            ax.set_title(f'Head {i+1}')\r\n+            ax.set_xlabel('Key')\r\n+            ax.set_ylabel('Query')\r\n+            \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    def plot_feature_importance(\r\n+        self,\r\n+        importance_scores: np.ndarray,\r\n+        feature_names: List[str]\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot feature importance scores\r\n+        \r\n+        Args:\r\n+            importance_scores: Array of importance scores\r\n+            feature_names: List of feature names\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        # Sort by importance\r\n+        sorted_idx = np.argsort(importance_scores)\r\n+        pos = np.arange(sorted_idx.shape[0]) + .5\r\n+        \r\n+        ax.barh(pos, importance_scores[sorted_idx])\r\n+        ax.set_yticks(pos)\r\n+        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n+        ax.set_xlabel('Importance Score')\r\n+        ax.set_title('Feature Importance')\r\n+        \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    @staticmethod\r\n+    def save_figure(\r\n+        fig: plt.Figure,\r\n+        filename: str,\r\n+        dpi: int = 300\r\n+    ):\r\n+        \"\"\"\r\n+        Save figure to file\r\n+        \r\n+        Args:\r\n+            fig: matplotlib figure\r\n+            filename: Output filename\r\n+            dpi: Resolution in dots per inch\r\n+        \"\"\"\r\n+        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733343947813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,195 +186,283 @@\n             fig: matplotlib figure\r\n             filename: Output filename\r\n             dpi: Resolution in dots per inch\r\n         \"\"\"\r\n-        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\n-\"\"\"\r\n-Visualization utilities for time series forecasting.\r\n+        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n+        \r\n+        \r\n \r\n-Dependencies:\r\n-- matplotlib>=3.7.2\r\n-- seaborn>=0.12.2\r\n-\"\"\"\r\n-\r\n+import os\r\n+import torch\r\n+import numpy as np\r\n import matplotlib.pyplot as plt\r\n-import seaborn as sns\r\n-import numpy as np\r\n-from typing import List, Optional, Tuple\r\n-import torch\r\n+from datetime import datetime, timedelta\r\n+import pandas as pd\r\n+from typing import Tuple, Optional, List\r\n \r\n-class TimeSeriesVisualizer:\r\n-    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n+class PredictionVisualizer:\r\n+    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n     \r\n-    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n+    def __init__(\r\n+            self,\r\n+            output_dir: str = \"prediction_plots\",\r\n+            fig_size: Tuple[int, int] = (15, 7),\r\n+            dpi: int = 300\r\n+    ):\r\n         \"\"\"\r\n         Initialize visualizer\r\n         \r\n         Args:\r\n-            figsize: Default figure size for plots\r\n+            output_dir: Directory to save plots\r\n+            fig_size: Figure size for plots\r\n+            dpi: DPI for saved figures\r\n         \"\"\"\r\n-        self.figsize = figsize\r\n+        self.output_dir = output_dir\r\n+        self.fig_size = fig_size\r\n+        self.dpi = dpi\r\n+        \r\n+        # Create output directory if it doesn't exist\r\n+        os.makedirs(output_dir, exist_ok=True)\r\n+        \r\n         # Set style\r\n-        sns.set_style(\"whitegrid\")\r\n-        plt.rcParams['figure.figsize'] = figsize\r\n-        \r\n-    def plot_training_history(\r\n-        self,\r\n-        train_losses: List[float],\r\n-        val_losses: List[float],\r\n-        title: str = \"Training History\"\r\n-    ) -> plt.Figure:\r\n+        plt.style.use('seaborn')\r\n+    \r\n+    def _generate_timestamps(\r\n+            self,\r\n+            start_time: datetime,\r\n+            sequence_length: int,\r\n+            freq: str = 'H'\r\n+    ) -> List[datetime]:\r\n         \"\"\"\r\n-        Plot training and validation losses\r\n+        Generate timestamps for x-axis\r\n         \r\n         Args:\r\n-            train_losses: List of training losses\r\n-            val_losses: List of validation losses\r\n-            title: Plot title\r\n+            start_time: Starting timestamp\r\n+            sequence_length: Number of timestamps to generate\r\n+            freq: Frequency of timestamps ('H' for hourly)\r\n             \r\n         Returns:\r\n-            matplotlib figure\r\n+            List of timestamps\r\n         \"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        epochs = range(1, len(train_losses) + 1)\r\n-        \r\n-        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n-        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n-        \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Epoch')\r\n-        ax.set_ylabel('Loss')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        return fig\r\n+        try:\r\n+            timestamps = [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+            return timestamps\r\n+        except Exception as e:\r\n+            print(f\"Error generating timestamps: {str(e)}\")\r\n+            # Return fallback numeric x-axis\r\n+            return list(range(sequence_length))\r\n     \r\n-    def plot_predictions(\r\n-        self,\r\n-        true_values: torch.Tensor,\r\n-        predictions: torch.Tensor,\r\n-        timestamps: Optional[List] = None,\r\n-        title: str = \"Predictions vs Actual\"\r\n-    ) -> plt.Figure:\r\n+    def plot_prediction_sample(\r\n+            self,\r\n+            input_seq: torch.Tensor,\r\n+            actual_seq: torch.Tensor,\r\n+            predicted_seq: torch.Tensor,\r\n+            sample_id: int,\r\n+            start_time: Optional[datetime] = None,\r\n+            scaler = None\r\n+    ):\r\n         \"\"\"\r\n-        Plot predictions against actual values\r\n+        Create and save a plot showing input, actual and predicted values\r\n         \r\n         Args:\r\n-            true_values: Ground truth values\r\n-            predictions: Model predictions\r\n-            timestamps: Optional list of timestamps\r\n-            title: Plot title\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n+            input_seq: Input sequence tensor\r\n+            actual_seq: Actual values tensor\r\n+            predicted_seq: Predicted values tensor\r\n+            sample_id: Sample identifier for filename\r\n+            start_time: Starting timestamp (optional)\r\n+            scaler: Scaler object for inverse transform (optional)\r\n         \"\"\"\r\n-        # Convert to numpy if tensors\r\n-        if isinstance(true_values, torch.Tensor):\r\n-            true_values = true_values.cpu().numpy()\r\n-        if isinstance(predictions, torch.Tensor):\r\n-            predictions = predictions.cpu().numpy()\r\n+        try:\r\n+            # Move tensors to CPU and convert to numpy\r\n+            input_seq = input_seq.cpu().numpy()\r\n+            actual_seq = actual_seq.cpu().numpy()\r\n+            predicted_seq = predicted_seq.cpu().numpy()\r\n             \r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n-        \r\n-        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n-        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n-        \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n-        ax.set_ylabel('Value')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        # Rotate x-axis labels if timestamps are provided\r\n-        if timestamps is not None:\r\n-            plt.xticks(rotation=45)\r\n+            # If we have a scaler, inverse transform the values\r\n+            if scaler is not None:\r\n+                try:\r\n+                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n+                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n+                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n             \r\n-        plt.tight_layout()\r\n-        return fig\r\n-    \r\n-    def plot_attention_weights(\r\n-        self,\r\n-        attention_weights: torch.Tensor,\r\n-        index: int = 0\r\n-    ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot attention weights heatmap\r\n-        \r\n-        Args:\r\n\\ No newline at end of file\n-            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n-            index: Batch index to plot\r\n+            # Get sequence lengths\r\n+            input_len = len(input_seq)\r\n+            prediction_len = len(predicted_seq)\r\n+            total_len = input_len + prediction_len\r\n             \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        # Get weights for specified batch\r\n-        weights = attention_weights[index].cpu().numpy()\r\n-        \r\n-        # Create subplot for each attention head\r\n-        n_heads = weights.shape[0]\r\n-        fig, axes = plt.subplots(\r\n-            1, n_heads,\r\n-            figsize=(4 * n_heads, 4),\r\n-            squeeze=False\r\n-        )\r\n-        \r\n-        for i, ax in enumerate(axes[0]):\r\n-            sns.heatmap(\r\n-                weights[i],\r\n-                ax=ax,\r\n-                cmap='viridis',\r\n-                cbar=True\r\n-            )\r\n-            ax.set_title(f'Head {i+1}')\r\n-            ax.set_xlabel('Key')\r\n-            ax.set_ylabel('Query')\r\n+            # Generate x-axis values\r\n+            if start_time is not None:\r\n+                x_values = self._generate_timestamps(start_time, total_len)\r\n+            else:\r\n+                x_values = list(range(total_len))\r\n             \r\n-        plt.tight_layout()\r\n-        return fig\r\n+            # Create figure\r\n+            plt.figure(figsize=self.fig_size)\r\n+            \r\n+            # Plot input sequence\r\n+            plt.plot(x_values[:input_len], \r\n+                    input_seq[:, 0], \r\n+                    'b-', \r\n+                    label='Input', \r\n+                    alpha=0.5)\r\n+            \r\n+            # Plot actual values\r\n+            plt.plot(x_values[input_len:], \r\n+                    actual_seq[:, 0], \r\n+                    'g-', \r\n+                    label='Actual', \r\n+                    linewidth=2)\r\n+            \r\n+            # Plot predictions\r\n+            plt.plot(x_values[input_len:], \r\n+                    predicted_seq[:, 0], \r\n+                    'r--', \r\n+                    label='Predicted', \r\n+                    linewidth=2)\r\n+            \r\n+            # Add vertical line separating input and prediction\r\n+            plt.axvline(x=x_values[input_len-1], \r\n+                       color='gray', \r\n+                       linestyle='--', \r\n+                       alpha=0.5)\r\n+            \r\n+            # Customize plot\r\n+            plt.title('Input Sequence and Predictions', pad=20)\r\n+            plt.xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n+            plt.ylabel('Value')\r\n+            plt.legend()\r\n+            plt.grid(True, alpha=0.3)\r\n+            \r\n+            # Rotate x-axis labels if using timestamps\r\n+            if isinstance(x_values[0], datetime):\r\n+                plt.xticks(rotation=45)\r\n+            \r\n+            # Tight layout to prevent label cutoff\r\n+            plt.tight_layout()\r\n+            \r\n+            # Save plot\r\n+            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n+            plt.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+            print(f\"Saved prediction plot to {filename}\")\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating prediction plot: {str(e)}\")\r\n+            # Ensure figure is closed even if error occurs\r\n+            plt.close()\r\n     \r\n-    def plot_feature_importance(\r\n-        self,\r\n-        importance_scores: np.ndarray,\r\n-        feature_names: List[str]\r\n-    ) -> plt.Figure:\r\n+    def plot_multiple_samples(\r\n+            self,\r\n+            model: torch.nn.Module,\r\n+            dataset,\r\n+            num_samples: int = 5,\r\n+            scaler = None,\r\n+            device: torch.device = torch.device('cpu')\r\n+    ):\r\n         \"\"\"\r\n-        Plot feature importance scores\r\n+        Create plots for multiple random samples from dataset\r\n         \r\n         Args:\r\n-            importance_scores: Array of importance scores\r\n-            feature_names: List of feature names\r\n+            model: Trained model\r\n+            dataset: Dataset containing samples\r\n+            num_samples: Number of samples to plot\r\n+            scaler: Scaler object for inverse transform\r\n+            device: Device to run model on\r\n+        \"\"\"\r\n+        try:\r\n+            model.eval()  # Set model to evaluation mode\r\n             \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        # Sort by importance\r\n-        sorted_idx = np.argsort(importance_scores)\r\n-        pos = np.arange(sorted_idx.shape[0]) + .5\r\n-        \r\n-        ax.barh(pos, importance_scores[sorted_idx])\r\n-        ax.set_yticks(pos)\r\n-        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n-        ax.set_xlabel('Importance Score')\r\n-        ax.set_title('Feature Importance')\r\n-        \r\n-        plt.tight_layout()\r\n-        return fig\r\n-    \r\n-    @staticmethod\r\n-    def save_figure(\r\n-        fig: plt.Figure,\r\n-        filename: str,\r\n-        dpi: int = 300\r\n+            # Generate random indices\r\n+            total_samples = len(dataset)\r\n+            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n+            \r\n+            with torch.no_grad():\r\n+                for idx in indices:\r\n+                    # Get sample from dataset\r\n+                    input_seq, decoder_input, target = dataset[idx]\r\n+                    \r\n+                    # Prepare input for model\r\n+                    input_batch = input_seq.unsqueeze(0).to(device)\r\n+                    \r\n+                    # Get prediction\r\n+                    prediction, _ = model(input_batch)\r\n+                    \r\n+                    # Remove batch dimension\r\n+                    prediction = prediction.squeeze(0)\r\n+                    \r\n+                    # Plot sample\r\n+                    self.plot_prediction_sample(\r\n+                        input_seq=input_seq,\r\n+                        actual_seq=target,\r\n+                        predicted_seq=prediction,\r\n+                        sample_id=idx,\r\n+                        scaler=scaler\r\n+                    )\r\n+                    \r\n+        except Exception as e:\r\n+            print(f\"Error plotting multiple samples: {str(e)}\")\r\n+\r\n+    def create_error_analysis_plots(\r\n+            self,\r\n+            actual_values: torch.Tensor,\r\n+            predicted_values: torch.Tensor,\r\n+            scaler = None\r\n     ):\r\n         \"\"\"\r\n-        Save figure to file\r\n+        Create error analysis plots (error distribution, scatter plot)\r\n         \r\n         Args:\r\n-            fig: matplotlib figure\r\n-            filename: Output filename\r\n-            dpi: Resolution in dots per inch\r\n+            actual_values: Tensor of actual values\r\n+            predicted_values: Tensor of predicted values\r\n+            scaler: Scaler object for inverse transform\r\n         \"\"\"\r\n-        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\n+        try:\r\n+            # Convert to numpy and reshape\r\n+            actual = actual_values.cpu().numpy().reshape(-1)\r\n+            predicted = predicted_values.cpu().numpy().reshape(-1)\r\n+            \r\n+            if scaler is not None:\r\n+                try:\r\n+                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n+                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-1)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n+            \r\n+            # Calculate errors\r\n+            errors = predicted - actual\r\n+            \r\n+            # Error distribution plot\r\n+            plt.figure(figsize=self.fig_size)\r\n+            plt.hist(errors, bins=50, edgecolor='black')\r\n+            plt.title('Error Distribution')\r\n+            plt.xlabel('Prediction Error')\r\n+            plt.ylabel('Frequency')\r\n+            plt.tight_layout()\r\n+            plt.savefig(os.path.join(self.output_dir, 'error_distribution.png'), \r\n+                       dpi=self.dpi, \r\n+                       bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+            # Scatter plot\r\n+            plt.figure(figsize=self.fig_size)\r\n+            plt.scatter(actual, predicted, alpha=0.5)\r\n+            \r\n+            # Add diagonal line\r\n+            min_val = min(actual.min(), predicted.min())\r\n+            max_val = max(actual.max(), predicted.max())\r\n+            plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n+            \r\n+            plt.title('Actual vs Predicted Values')\r\n+            plt.xlabel('Actual Values')\r\n+            plt.ylabel('Predicted Values')\r\n+            plt.tight_layout()\r\n+            plt.savefig(os.path.join(self.output_dir, 'actual_vs_predicted.png'), \r\n+                       dpi=self.dpi, \r\n+                       bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating analysis plots: {str(e)}\")\r\n+            plt.close()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733343963788,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -447,9 +447,9 @@\n             \r\n             # Scatter plot\r\n             plt.figure(figsize=self.fig_size)\r\n             plt.scatter(actual, predicted, alpha=0.5)\r\n-            \r\n+            z\r\n             # Add diagonal line\r\n             min_val = min(actual.min(), predicted.min())\r\n             max_val = max(actual.max(), predicted.max())\r\n             plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n"
                },
                {
                    "date": 1733344009859,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,467 @@\n+\"\"\"\r\n+Visualization utilities for time series forecasting.\r\n+\r\n+Dependencies:\r\n+- matplotlib>=3.7.2\r\n+- seaborn>=0.12.2\r\n+\"\"\"\r\n+\r\n+import matplotlib.pyplot as plt\r\n+import seaborn as sns\r\n+import numpy as np\r\n+from typing import List, Optional, Tuple\r\n+import torch\r\n+\r\n+class TimeSeriesVisualizer:\r\n+    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n+    \r\n+    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n+        \"\"\"\r\n+        Initialize visualizer\r\n+        \r\n+        Args:\r\n+            figsize: Default figure size for plots\r\n+        \"\"\"\r\n+        self.figsize = figsize\r\n+        # Set style\r\n+        sns.set_style(\"whitegrid\")\r\n+        plt.rcParams['figure.figsize'] = figsize\r\n+        \r\n+    def plot_training_history(\r\n+        self,\r\n+        train_losses: List[float],\r\n+        val_losses: List[float],\r\n+        title: str = \"Training History\"\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot training and validation losses\r\n+        \r\n+        Args:\r\n+            train_losses: List of training losses\r\n+            val_losses: List of validation losses\r\n+            title: Plot title\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        epochs = range(1, len(train_losses) + 1)\r\n+        \r\n+        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n+        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n+        \r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Epoch')\r\n+        ax.set_ylabel('Loss')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        return fig\r\n+    \r\n+    def plot_predictions(\r\n+        self,\r\n+        true_values: torch.Tensor,\r\n+        predictions: torch.Tensor,\r\n+        timestamps: Optional[List] = None,\r\n+        title: str = \"Predictions vs Actual\"\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot predictions against actual values\r\n+        \r\n+        Args:\r\n+            true_values: Ground truth values\r\n+            predictions: Model predictions\r\n+            timestamps: Optional list of timestamps\r\n+            title: Plot title\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        # Convert to numpy if tensors\r\n+        if isinstance(true_values, torch.Tensor):\r\n+            true_values = true_values.cpu().numpy()\r\n+        if isinstance(predictions, torch.Tensor):\r\n+            predictions = predictions.cpu().numpy()\r\n+            \r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n+        \r\n+        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n+        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n+        \r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n+        ax.set_ylabel('Value')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        # Rotate x-axis labels if timestamps are provided\r\n+        if timestamps is not None:\r\n+            plt.xticks(rotation=45)\r\n+            \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    def plot_attention_weights(\r\n+        self,\r\n+        attention_weights: torch.Tensor,\r\n+        index: int = 0\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot attention weights heatmap\r\n+        \r\n+        Args:\r\n+            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n+            index: Batch index to plot\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        # Get weights for specified batch\r\n+        weights = attention_weights[index].cpu().numpy()\r\n+        \r\n+        # Create subplot for each attention head\r\n+        n_heads = weights.shape[0]\r\n+        fig, axes = plt.subplots(\r\n+            1, n_heads,\r\n+            figsize=(4 * n_heads, 4),\r\n+            squeeze=False\r\n+        )\r\n+        \r\n+        for i, ax in enumerate(axes[0]):\r\n+            sns.heatmap(\r\n+                weights[i],\r\n+                ax=ax,\r\n+                cmap='viridis',\r\n+                cbar=True\r\n+            )\r\n+            ax.set_title(f'Head {i+1}')\r\n+            ax.set_xlabel('Key')\r\n+            ax.set_ylabel('Query')\r\n+            \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    def plot_feature_importance(\r\n+        self,\r\n+        importance_scores: np.ndarray,\r\n+        feature_names: List[str]\r\n+    ) -> plt.Figure:\r\n+        \"\"\"\r\n+        Plot feature importance scores\r\n+        \r\n+        Args:\r\n+            importance_scores: Array of importance scores\r\n+            feature_names: List of feature names\r\n+            \r\n+        Returns:\r\n+            matplotlib figure\r\n+        \"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        # Sort by importance\r\n+        sorted_idx = np.argsort(importance_scores)\r\n+        pos = np.arange(sorted_idx.shape[0]) + .5\r\n+        \r\n+        ax.barh(pos, importance_scores[sorted_idx])\r\n+        ax.set_yticks(pos)\r\n+        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n+        ax.set_xlabel('Importance Score')\r\n+        ax.set_title('Feature Importance')\r\n+        \r\n+        plt.tight_layout()\r\n+        return fig\r\n+    \r\n+    @staticmethod\r\n+    def save_figure(\r\n+        fig: plt.Figure,\r\n+        filename: str,\r\n+        dpi: int = 300\r\n+    ):\r\n+        \"\"\"\r\n+        Save figure to file\r\n+        \r\n+        Args:\r\n+            fig: matplotlib figure\r\n+            filename: Output filename\r\n+            dpi: Resolution in dots per inch\r\n+        \"\"\"\r\n+        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n+        \r\n+        \r\n+\r\n+import os\r\n+import torch\r\n+import numpy as np\r\n+import matplotlib.pyplot as plt\r\n+from datetime import datetime, timedelta\r\n+import pandas as pd\r\n+from typing import Tuple, Optional, List\r\n+\r\n+class PredictionVisualizer:\r\n+    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n+    \r\n+    def __init__(\r\n+            self,\r\n+            output_dir: str = \"prediction_plots\",\r\n+            fig_size: Tuple[int, int] = (15, 7),\r\n+            dpi: int = 300\r\n+    ):\r\n+        \"\"\"\r\n+        Initialize visualizer\r\n+        \r\n+        Args:\r\n+            output_dir: Directory to save plots\r\n+            fig_size: Figure size for plots\r\n+            dpi: DPI for saved figures\r\n+        \"\"\"\r\n+        self.output_dir = output_dir\r\n+        self.fig_size = fig_size\r\n+        self.dpi = dpi\r\n+        \r\n+        # Create output directory if it doesn't exist\r\n+        os.makedirs(output_dir, exist_ok=True)\r\n+        \r\n+        # Set style\r\n+        plt.style.use('seaborn')\r\n+    \r\n+    def _generate_timestamps(\r\n+            self,\r\n+            start_time: datetime,\r\n+            sequence_length: int,\r\n+            freq: str = 'H'\r\n+    ) -> List[datetime]:\r\n+        \"\"\"\r\n+        Generate timestamps for x-axis\r\n+        \r\n+        Args:\r\n+            start_time: Starting timestamp\r\n+            sequence_length: Number of timestamps to generate\r\n+            freq: Frequency of timestamps ('H' for hourly)\r\n+            \r\n+        Returns:\r\n+            List of timestamps\r\n+        \"\"\"\r\n+        try:\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+        except Exception as e:\r\n+            print(f\"Error generating timestamps: {str(e)}\")\r\n+            # Return fallback numeric x-axis\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+    \r\n+    def plot_prediction_sample(\r\n+            self,\r\n+            input_seq: torch.Tensor,\r\n+            actual_seq: torch.Tensor,\r\n+            predicted_seq: torch.Tensor,\r\n+            sample_id: int,\r\n+            start_time: Optional[datetime] = None,\r\n+            scaler = None\r\n+    ):\r\n+        \"\"\"\r\n+        Create and save a plot showing input, actual and predicted values\r\n+        \r\n+        Args:\r\n+            input_seq: Input sequence tensor\r\n+            actual_seq: Actual values tensor\r\n+            predicted_seq: Predicted values tensor\r\n+            sample_id: Sample identifier for filename\r\n+            start_time: Starting timestamp (optional)\r\n+            scaler: Scaler object for inverse transform (optional)\r\n+        \"\"\"\r\n+        try:\r\n+            # Move tensors to CPU and convert to numpy\r\n+            input_seq = input_seq.cpu().numpy()\r\n+            actual_seq = actual_seq.cpu().numpy()\r\n+            predicted_seq = predicted_seq.cpu().numpy()\r\n+            \r\n+            # If we have a scaler, inverse transform the values\r\n+            if scaler is not None:\r\n+                try:\r\n+                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n+                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n+                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n+            \r\n+            # Get sequence lengths\r\n+            input_len = len(input_seq)\r\n+            prediction_len = len(predicted_seq)\r\n+            total_len = input_len + prediction_len\r\n+            \r\n+            # Generate x-axis values\r\n+            if start_time is not None:\r\n+                x_values = self._generate_timestamps(start_time, total_len)\r\n+            else:\r\n+                x_values = list(range(total_len))\r\n+            \r\n+            # Create figure\r\n+            plt.figure(figsize=self.fig_size)\r\n+            \r\n+            # Plot input sequence\r\n+            plt.plot(x_values[:input_len], \r\n+                    input_seq[:, 0], \r\n+                    'b-', \r\n+                    label='Input', \r\n+                    alpha=0.5)\r\n+            \r\n+            # Plot actual values\r\n+            plt.plot(x_values[input_len:], \r\n+                    actual_seq[:, 0], \r\n+                    'g-', \r\n+                    label='Actual', \r\n+                    linewidth=2)\r\n+            \r\n+            # Plot predictions\r\n+            plt.plot(x_values[input_len:], \r\n+                    predicted_seq[:, 0], \r\n+                    'r--', \r\n+                    label='Predicted', \r\n+                    linewidth=2)\r\n+            \r\n+            # Add vertical line separating input and prediction\r\n+            plt.axvline(x=x_values[input_len-1], \r\n+                       color='gray', \r\n+                       linestyle='--', \r\n+                       alpha=0.5)\r\n+            \r\n+            # Customize plot\r\n+            plt.title('Input Sequence and Predictions', pad=20)\r\n+            plt.xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n+            plt.ylabel('Value')\r\n+            plt.legend()\r\n+            plt.grid(True, alpha=0.3)\r\n+            \r\n+            # Rotate x-axis labels if using timestamps\r\n+            if isinstance(x_values[0], datetime):\r\n+                plt.xticks(rotation=45)\r\n+            \r\n+            # Tight layout to prevent label cutoff\r\n+            plt.tight_layout()\r\n+            \r\n+            # Save plot\r\n+            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n+            plt.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+            print(f\"Saved prediction plot to {filename}\")\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating prediction plot: {str(e)}\")\r\n+            # Ensure figure is closed even if error occurs\r\n+            plt.close()\r\n+    \r\n+    def plot_multiple_samples(\r\n+            self,\r\n+            model: torch.nn.Module,\r\n+            dataset,\r\n+            num_samples: int = 5,\r\n+            scaler = None,\r\n+            device: torch.device = torch.device('cpu')\r\n+    ):\r\n+        \"\"\"\r\n+        Create plots for multiple random samples from dataset\r\n+        \r\n+        Args:\r\n+            model: Trained model\r\n+            dataset: Dataset containing samples\r\n+            num_samples: Number of samples to plot\r\n+            scaler: Scaler object for inverse transform\r\n+            device: Device to run model on\r\n+        \"\"\"\r\n+        try:\r\n+            model.eval()  # Set model to evaluation mode\r\n+            \r\n+            # Generate random indices\r\n+            total_samples = len(dataset)\r\n+            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n+            \r\n+            with torch.no_grad():\r\n+                for idx in indices:\r\n+                    # Get sample from dataset\r\n+                    input_seq, decoder_input, target = dataset[idx]\r\n+                    \r\n+                    # Prepare input for model\r\n+                    input_batch = input_seq.unsqueeze(0).to(device)\r\n+                    \r\n+                    # Get prediction\r\n+                    prediction, _ = model(input_batch)\r\n+                    \r\n+                    # Remove batch dimension\r\n+                    prediction = prediction.squeeze(0)\r\n+                    \r\n+                    # Plot sample\r\n+                    self.plot_prediction_sample(\r\n+                        input_seq=input_seq,\r\n+                        actual_seq=target,\r\n+                        predicted_seq=prediction,\r\n+                        sample_id=idx,\r\n+                        scaler=scaler\r\n+                    )\r\n+                    \r\n+        except Exception as e:\r\n+            print(f\"Error plotting multiple samples: {str(e)}\")\r\n+\r\n+    def create_error_analysis_plots(\r\n+            self,\r\n+            actual_values: torch.Tensor,\r\n+            predicted_values: torch.Tensor,\r\n+            scaler = None\r\n+    ):\r\n+        \"\"\"\r\n+        Create error analysis plots (error distribution, scatter plot)\r\n+        \r\n+        Args:\r\n+            actual_values: Tensor of actual values\r\n+            predicted_values: Tensor of predicted values\r\n+            scaler: Scaler object for inverse transform\r\n+        \"\"\"\r\n+        try:\r\n+            # Convert to numpy and reshape\r\n+            actual = actual_values.cpu().numpy().reshape(-1)\r\n+            predicted = predicted_values.cpu().numpy().reshape(-1)\r\n+            \r\n+            if scaler is not None:\r\n+                try:\r\n+                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n+                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-1)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n+            \r\n+            # Calculate errors\r\n+            errors = predicted - actual\r\n+            \r\n+            # Error distribution plot\r\n+            plt.figure(figsize=self.fig_size)\r\n+            plt.hist(errors, bins=50, edgecolor='black')\r\n+            plt.title('Error Distribution')\r\n+            plt.xlabel('Prediction Error')\r\n+            plt.ylabel('Frequency')\r\n+            plt.tight_layout()\r\n+            plt.savefig(os.path.join(self.output_dir, 'error_distribution.png'), \r\n+                       dpi=self.dpi, \r\n+                       bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+            # Scatter plot\r\n+            plt.figure(figsize=self.fig_size)\r\n+            plt.scatter(actual, predicted, alpha=0.5)\r\n+            z\r\n+            # Add diagonal line\r\n+            min_val = min(actual.min(), predicted.min())\r\n+            max_val = max(actual.max(), predicted.max())\r\n+            plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n+            \r\n+            plt.title('Actual vs Predicted Values')\r\n+            plt.xlabel('Actual Values')\r\n+            plt.ylabel('Predicted Values')\r\n+            plt.tight_layout()\r\n+            plt.savefig(os.path.join(self.output_dir, 'actual_vs_predicted.png'), \r\n+                       dpi=self.dpi, \r\n+                       bbox_inches='tight')\r\n+            plt.close()\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating analysis plots: {str(e)}\")\r\n+            plt.close()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733345332432,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,82 +15,59 @@\n class TimeSeriesVisualizer:\r\n     \"\"\"Visualization tools for time series data and model results\"\"\"\r\n     \r\n     def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n-        \"\"\"\r\n-        Initialize visualizer\r\n-        \r\n-        Args:\r\n-            figsize: Default figure size for plots\r\n-        \"\"\"\r\n+        \"\"\"Initialize visualizer\"\"\"\r\n         self.figsize = figsize\r\n-        # Set style\r\n         sns.set_style(\"whitegrid\")\r\n         plt.rcParams['figure.figsize'] = figsize\r\n-        \r\n-    def plot_training_history(\r\n-        self,\r\n-        train_losses: List[float],\r\n-        val_losses: List[float],\r\n-        title: str = \"Training History\"\r\n-    ) -> plt.Figure:\r\n+\r\n+    def _prepare_data_for_plotting(self, data: torch.Tensor) -> np.ndarray:\r\n         \"\"\"\r\n-        Plot training and validation losses\r\n+        Convert tensor to 2D numpy array suitable for plotting\r\n         \r\n         Args:\r\n-            train_losses: List of training losses\r\n-            val_losses: List of validation losses\r\n-            title: Plot title\r\n+            data: Input tensor of shape [batch, seq_len, features] or [seq_len, features]\r\n             \r\n         Returns:\r\n-            matplotlib figure\r\n+            2D numpy array of shape [seq_len]\r\n         \"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        epochs = range(1, len(train_losses) + 1)\r\n+        # Convert to numpy if it's a tensor\r\n+        if isinstance(data, torch.Tensor):\r\n+            data = data.cpu().detach().numpy()\r\n+            \r\n+        # Handle different input shapes\r\n+        if len(data.shape) == 3:  # [batch, seq_len, features]\r\n+            # Take first feature and average across batches\r\n+            data = data[:, :, 0].mean(axis=0)\r\n+        elif len(data.shape) == 2:  # [seq_len, features]\r\n+            data = data[:, 0]\r\n+            \r\n+        return data\r\n         \r\n-        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n-        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n-        \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Epoch')\r\n-        ax.set_ylabel('Loss')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        return fig\r\n-    \r\n     def plot_predictions(\r\n         self,\r\n         true_values: torch.Tensor,\r\n         predictions: torch.Tensor,\r\n         timestamps: Optional[List] = None,\r\n         title: str = \"Predictions vs Actual\"\r\n     ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot predictions against actual values\r\n+        \"\"\"Plot predictions against actual values\"\"\"\r\n+        # Prepare data for plotting\r\n+        true_values = self._prepare_data_for_plotting(true_values)\r\n+        predictions = self._prepare_data_for_plotting(predictions)\r\n         \r\n-        Args:\r\n-            true_values: Ground truth values\r\n-            predictions: Model predictions\r\n-            timestamps: Optional list of timestamps\r\n-            title: Plot title\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        # Convert to numpy if tensors\r\n-        if isinstance(true_values, torch.Tensor):\r\n-            true_values = true_values.cpu().numpy()\r\n-        if isinstance(predictions, torch.Tensor):\r\n-            predictions = predictions.cpu().numpy()\r\n-            \r\n+        # Create x-axis values\r\n+        x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n+        \r\n+        # Create figure\r\n         fig, ax = plt.subplots(figsize=self.figsize)\r\n         \r\n-        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n-        \r\n+        # Plot data\r\n         ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n         ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n         \r\n+        # Customize plot\r\n         ax.set_title(title)\r\n         ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n         ax.set_ylabel('Value')\r\n         ax.legend()\r\n@@ -101,64 +78,37 @@\n             plt.xticks(rotation=45)\r\n             \r\n         plt.tight_layout()\r\n         return fig\r\n-    \r\n-    def plot_attention_weights(\r\n+\r\n+    def plot_training_history(\r\n         self,\r\n-        attention_weights: torch.Tensor,\r\n-        index: int = 0\r\n+        train_losses: List[float],\r\n+        val_losses: List[float],\r\n+        title: str = \"Training History\"\r\n     ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot attention weights heatmap\r\n+        \"\"\"Plot training and validation losses\"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        epochs = range(1, len(train_losses) + 1)\r\n         \r\n-        Args:\r\n-            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n-            index: Batch index to plot\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        # Get weights for specified batch\r\n-        weights = attention_weights[index].cpu().numpy()\r\n+        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n+        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n         \r\n-        # Create subplot for each attention head\r\n-        n_heads = weights.shape[0]\r\n-        fig, axes = plt.subplots(\r\n-            1, n_heads,\r\n-            figsize=(4 * n_heads, 4),\r\n-            squeeze=False\r\n-        )\r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Epoch')\r\n+        ax.set_ylabel('Loss')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n         \r\n-        for i, ax in enumerate(axes[0]):\r\n-            sns.heatmap(\r\n-                weights[i],\r\n-                ax=ax,\r\n-                cmap='viridis',\r\n-                cbar=True\r\n-            )\r\n-            ax.set_title(f'Head {i+1}')\r\n-            ax.set_xlabel('Key')\r\n-            ax.set_ylabel('Query')\r\n-            \r\n         plt.tight_layout()\r\n         return fig\r\n-    \r\n+\r\n     def plot_feature_importance(\r\n         self,\r\n         importance_scores: np.ndarray,\r\n         feature_names: List[str]\r\n     ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot feature importance scores\r\n-        \r\n-        Args:\r\n-            importance_scores: Array of importance scores\r\n-            feature_names: List of feature names\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n+        \"\"\"Plot feature importance scores\"\"\"\r\n         fig, ax = plt.subplots(figsize=self.figsize)\r\n         \r\n         # Sort by importance\r\n         sorted_idx = np.argsort(importance_scores)\r\n@@ -171,491 +121,65 @@\n         ax.set_title('Feature Importance')\r\n         \r\n         plt.tight_layout()\r\n         return fig\r\n-    \r\n-    @staticmethod\r\n-    def save_figure(\r\n-        fig: plt.Figure,\r\n-        filename: str,\r\n-        dpi: int = 300\r\n-    ):\r\n-        \"\"\"\r\n-        Save figure to file\r\n-        \r\n-        Args:\r\n-            fig: matplotlib figure\r\n-            filename: Output filename\r\n-            dpi: Resolution in dots per inch\r\n-        \"\"\"\r\n-        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n-        \r\n-        \r\n \r\n-import os\r\n-import torch\r\n-import numpy as np\r\n-import matplotlib.pyplot as plt\r\n-from datetime import datetime, timedelta\r\n-import pandas as pd\r\n-from typing import Tuple, Optional, List\r\n-\r\n-class PredictionVisualizer:\r\n-    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n-    \r\n-    def __init__(\r\n-            self,\r\n-            output_dir: str = \"prediction_plots\",\r\n-            fig_size: Tuple[int, int] = (15, 7),\r\n-            dpi: int = 300\r\n-    ):\r\n-        \"\"\"\r\n-        Initialize visualizer\r\n-        \r\n-        Args:\r\n-            output_dir: Directory to save plots\r\n-            fig_size: Figure size for plots\r\n-            dpi: DPI for saved figures\r\n-        \"\"\"\r\n-        self.output_dir = output_dir\r\n-        self.fig_size = fig_size\r\n-        self.dpi = dpi\r\n-        \r\n-        # Create output directory if it doesn't exist\r\n-        os.makedirs(output_dir, exist_ok=True)\r\n-        \r\n-        # Set style\r\n-        plt.style.use('seaborn')\r\n-    \r\n-    def _generate_timestamps(\r\n-            self,\r\n-            start_time: datetime,\r\n-            sequence_length: int,\r\n-            freq: str = 'H'\r\n-    ) -> List[datetime]:\r\n-        \"\"\"\r\n-        Generate timestamps for x-axis\r\n-        \r\n-        Args:\r\n-            start_time: Starting timestamp\r\n-            sequence_length: Number of timestamps to generate\r\n-            freq: Frequency of timestamps ('H' for hourly)\r\n-            \r\n-        Returns:\r\n-            List of timestamps\r\n-        \"\"\"\r\n-        try:\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-        except Exception as e:\r\n-            print(f\"Error generating timestamps: {str(e)}\")\r\n-            # Return fallback numeric x-axis\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-    \r\n-    def plot_prediction_sample(\r\n-            self,\r\n-            input_seq: torch.Tensor,\r\n-            actual_seq: torch.Tensor,\r\n-            predicted_seq: torch.Tensor,\r\n-            sample_id: int,\r\n-            start_time: Optional[datetime] = None,\r\n-            scaler = None\r\n-    ):\r\n-        \"\"\"\r\n-        Create and save a plot showing input, actual and predicted values\r\n-        \r\n-        Args:\r\n-            input_seq: Input sequence tensor\r\n-            actual_seq: Actual values tensor\r\n-            predicted_seq: Predicted values tensor\r\n-            sample_id: Sample identifier for filename\r\n-            start_time: Starting timestamp (optional)\r\n-            scaler: Scaler object for inverse transform (optional)\r\n-        \"\"\"\r\n-        try:\r\n-            # Move tensors to CPU and convert to numpy\r\n-            input_seq = input_seq.cpu().numpy()\r\n-            actual_seq = actual_seq.cpu().numpy()\r\n-            predicted_seq = predicted_seq.cpu().numpy()\r\n-            \r\n-            # If we have a scaler, inverse transform the values\r\n-            if scaler is not None:\r\n-                try:\r\n-                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n-                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n-                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Get sequence lengths\r\n-            input_len = len(input_seq)\r\n-            prediction_len = len(predicted_seq)\r\n-            total_len = input_len + prediction_len\r\n-            \r\n-            # Generate x-axis values\r\n-            if start_time is not None:\r\n-                x_values = self._generate_timestamps(start_time, total_len)\r\n-            else:\r\n-                x_values = list(range(total_len))\r\n-            \r\n-            # Create figure\r\n-            plt.figure(figsize=self.fig_size)\r\n-            \r\n-            # Plot input sequence\r\n-            plt.plot(x_values[:input_len], \r\n-                    input_seq[:, 0], \r\n-                    'b-', \r\n-                    label='Input', \r\n-                    alpha=0.5)\r\n-            \r\n-            # Plot actual values\r\n-            plt.plot(x_values[input_len:], \r\n-                    actual_seq[:, 0], \r\n-                    'g-', \r\n-                    label='Actual', \r\n-                    linewidth=2)\r\n-            \r\n-            # Plot predictions\r\n-            plt.plot(x_values[input_len:], \r\n-                    predicted_seq[:, 0], \r\n-                    'r--', \r\n-                    label='Predicted', \r\n-                    linewidth=2)\r\n-            \r\n-            # Add vertical line separating input and prediction\r\n-            plt.axvline(x=x_values[input_len-1], \r\n-                       color='gray', \r\n-                       linestyle='--', \r\n-                       alpha=0.5)\r\n-            \r\n-            # Customize plot\r\n-            plt.title('Input Sequence and Predictions', pad=20)\r\n-            plt.xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n-            plt.ylabel('Value')\r\n-            plt.legend()\r\n-            plt.grid(True, alpha=0.3)\r\n-            \r\n-            # Rotate x-axis labels if using timestamps\r\n-            if isinstance(x_values[0], datetime):\r\n-                plt.xticks(rotation=45)\r\n-            \r\n-            # Tight layout to prevent label cutoff\r\n-            plt.tight_layout()\r\n-            \r\n-            # Save plot\r\n-            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n-            plt.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-            print(f\"Saved prediction plot to {filename}\")\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating prediction plot: {str(e)}\")\r\n-            # Ensure figure is closed even if error occurs\r\n-            plt.close()\r\n-    \r\n-    def plot_multiple_samples(\r\n-            self,\r\n-            model: torch.nn.Module,\r\n-            dataset,\r\n-            num_samples: int = 5,\r\n-            scaler = None,\r\n-            device: torch.device = torch.device('cpu')\r\n-    ):\r\n-        \"\"\"\r\n-        Create plots for multiple random samples from dataset\r\n-        \r\n-        Args:\r\n-            model: Trained model\r\n-            dataset: Dataset containing samples\r\n-            num_samples: Number of samples to plot\r\n-            scaler: Scaler object for inverse transform\r\n-            device: Device to run model on\r\n-        \"\"\"\r\n-        try:\r\n-            model.eval()  # Set model to evaluation mode\r\n-            \r\n-            # Generate random indices\r\n-            total_samples = len(dataset)\r\n-            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n-            \r\n-            with torch.no_grad():\r\n-                for idx in indices:\r\n-                    # Get sample from dataset\r\n-                    input_seq, decoder_input, target = dataset[idx]\r\n-                    \r\n-                    # Prepare input for model\r\n-                    input_batch = input_seq.unsqueeze(0).to(device)\r\n-                    \r\n-                    # Get prediction\r\n-                    prediction, _ = model(input_batch)\r\n-                    \r\n-                    # Remove batch dimension\r\n-                    prediction = prediction.squeeze(0)\r\n-                    \r\n-                    # Plot sample\r\n-                    self.plot_prediction_sample(\r\n-                        input_seq=input_seq,\r\n-                        actual_seq=target,\r\n-                        predicted_seq=prediction,\r\n-                        sample_id=idx,\r\n-                        scaler=scaler\r\n-                    )\r\n-                    \r\n-        except Exception as e:\r\n-            print(f\"Error plotting multiple samples: {str(e)}\")\r\n-\r\n-    def create_error_analysis_plots(\r\n-            self,\r\n-            actual_values: torch.Tensor,\r\n-            predicted_values: torch.Tensor,\r\n-            scaler = None\r\n-    ):\r\n-        \"\"\"\r\n-        Create error analysis plots (error distribution, scatter plot)\r\n-        \r\n-        Args:\r\n-            actual_values: Tensor of actual values\r\n-            predicted_values: Tensor of predicted values\r\n-            scaler: Scaler object for inverse transform\r\n-        \"\"\"\r\n-        try:\r\n-            # Convert to numpy and reshape\r\n-            actual = actual_values.cpu().numpy().reshape(-1)\r\n-            predicted = predicted_values.cpu().numpy().reshape(-1)\r\n-            \r\n-            if scaler is not None:\r\n-                try:\r\n-                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n-                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-1)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Calculate errors\r\n-            errors = predicted - actual\r\n-            \r\n-            # Error distribution plot\r\n-            plt.figure(figsize=self.fig_size)\r\n-            plt.hist(errors, bins=50, edgecolor='black')\r\n-            plt.title('Error Distribution')\r\n-            plt.xlabel('Prediction Error')\r\n-            plt.ylabel('Frequency')\r\n-            plt.tight_layout()\r\n-            plt.savefig(os.path.join(self.output_dir, 'error_distribution.png'), \r\n-                       dpi=self.dpi, \r\n-                       bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-            # Scatter plot\r\n-            plt.figure(figsize=self.fig_size)\r\n-            plt.scatter(actual, predicted, alpha=0.5)\r\n-            z\r\n-            # Add diagonal line\r\n-            min_val = min(actual.min(), predicted.min())\r\n-            max_val = max(actual.max(), predicted.max())\r\n-            plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n-            \r\n-            plt.title('Actual vs Predicted Values')\r\n-            plt.xlabel('Actual Values')\r\n-            plt.ylabel('Predicted Values')\r\n-            plt.tight_layout()\r\n-            plt.savefig(os.path.join(self.output_dir, 'actual_vs_predicted.png'), \r\n-                       dpi=self.dpi, \r\n-                       bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating analysis plots: {str(e)}\")\r\n-            plt.close()\n-\"\"\"\r\n-Visualization utilities for time series forecasting.\r\n-\r\n-Dependencies:\r\n-- matplotlib>=3.7.2\r\n-- seaborn>=0.12.2\r\n-\"\"\"\r\n-\r\n-import matplotlib.pyplot as plt\r\n-import seaborn as sns\r\n-import numpy as np\r\n-from typing import List, Optional, Tuple\r\n-import torch\r\n-\r\n-class TimeSeriesVisualizer:\r\n-    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n-    \r\n-    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n-        \"\"\"\r\n-        Initialize visualizer\r\n-        \r\n-        Args:\r\n-            figsize: Default figure size for plots\r\n-        \"\"\"\r\n-        self.figsize = figsize\r\n-        # Set style\r\n-        sns.set_style(\"whitegrid\")\r\n-        plt.rcParams['figure.figsize'] = figsize\r\n-        \r\n-    def plot_training_history(\r\n+    def plot_batch_predictions(\r\n         self,\r\n-        train_losses: List[float],\r\n-        val_losses: List[float],\r\n-        title: str = \"Training History\"\r\n-    ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot training and validation losses\r\n-        \r\n-        Args:\r\n-            train_losses: List of training losses\r\n-            val_losses: List of validation losses\r\n-            title: Plot title\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        epochs = range(1, len(train_losses) + 1)\r\n-        \r\n-        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n-        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n-        \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Epoch')\r\n-        ax.set_ylabel('Loss')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        return fig\r\n-    \r\n-    def plot_predictions(\r\n-        self,\r\n         true_values: torch.Tensor,\r\n         predictions: torch.Tensor,\r\n-        timestamps: Optional[List] = None,\r\n-        title: str = \"Predictions vs Actual\"\r\n+        batch_idx: int = 0,\r\n+        n_samples: int = 5,\r\n+        title: str = \"Sample Predictions\"\r\n     ) -> plt.Figure:\r\n         \"\"\"\r\n-        Plot predictions against actual values\r\n+        Plot individual predictions from a batch\r\n         \r\n         Args:\r\n-            true_values: Ground truth values\r\n-            predictions: Model predictions\r\n-            timestamps: Optional list of timestamps\r\n+            true_values: Tensor of shape [batch, seq_len, features]\r\n+            predictions: Tensor of shape [batch, seq_len, features]\r\n+            batch_idx: Which batch to plot from\r\n+            n_samples: Number of samples to plot\r\n             title: Plot title\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n         \"\"\"\r\n-        # Convert to numpy if tensors\r\n-        if isinstance(true_values, torch.Tensor):\r\n-            true_values = true_values.cpu().numpy()\r\n-        if isinstance(predictions, torch.Tensor):\r\n-            predictions = predictions.cpu().numpy()\r\n-            \r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        # Convert to numpy\r\n+        true_values = true_values.cpu().detach().numpy()\r\n+        predictions = predictions.cpu().detach().numpy()\r\n         \r\n-        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n+        # Create figure with subplots\r\n+        n_samples = min(n_samples, true_values.shape[0])\r\n+        fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4*n_samples))\r\n+        if n_samples == 1:\r\n+            axes = [axes]\r\n         \r\n-        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n-        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n+        # Plot each sample\r\n+        for i, ax in enumerate(axes):\r\n+            if i < n_samples:\r\n+                true_seq = true_values[i, :, 0]\r\n+                pred_seq = predictions[i, :, 0]\r\n+                \r\n+                ax.plot(true_seq, 'b-', label='Actual', alpha=0.7)\r\n+                ax.plot(pred_seq, 'r--', label='Predicted', alpha=0.7)\r\n+                \r\n+                ax.set_title(f'Sample {i+1}')\r\n+                ax.set_xlabel('Time Step')\r\n+                ax.set_ylabel('Value')\r\n+                ax.legend()\r\n+                ax.grid(True)\r\n         \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n-        ax.set_ylabel('Value')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        # Rotate x-axis labels if timestamps are provided\r\n-        if timestamps is not None:\r\n-            plt.xticks(rotation=45)\r\n-            \r\n+        plt.suptitle(title)\r\n         plt.tight_layout()\r\n         return fig\r\n-    \r\n-    def plot_attention_weights(\r\n-        self,\r\n-        attention_weights: torch.Tensor,\r\n-        index: int = 0\r\n-    ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot attention weights heatmap\r\n-        \r\n-        Args:\r\n-            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n-            index: Batch index to plot\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        # Get weights for specified batch\r\n-        weights = attention_weights[index].cpu().numpy()\r\n-        \r\n-        # Create subplot for each attention head\r\n-        n_heads = weights.shape[0]\r\n-        fig, axes = plt.subplots(\r\n-            1, n_heads,\r\n-            figsize=(4 * n_heads, 4),\r\n-            squeeze=False\r\n-        )\r\n-        \r\n-        for i, ax in enumerate(axes[0]):\r\n-            sns.heatmap(\r\n-                weights[i],\r\n-                ax=ax,\r\n-                cmap='viridis',\r\n-                cbar=True\r\n-            )\r\n-            ax.set_title(f'Head {i+1}')\r\n-            ax.set_xlabel('Key')\r\n-            ax.set_ylabel('Query')\r\n-            \r\n-        plt.tight_layout()\r\n-        return fig\r\n-    \r\n-    def plot_feature_importance(\r\n-        self,\r\n-        importance_scores: np.ndarray,\r\n-        feature_names: List[str]\r\n-    ) -> plt.Figure:\r\n-        \"\"\"\r\n-        Plot feature importance scores\r\n-        \r\n-        Args:\r\n-            importance_scores: Array of importance scores\r\n-            feature_names: List of feature names\r\n-            \r\n-        Returns:\r\n-            matplotlib figure\r\n-        \"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        # Sort by importance\r\n-        sorted_idx = np.argsort(importance_scores)\r\n-        pos = np.arange(sorted_idx.shape[0]) + .5\r\n-        \r\n-        ax.barh(pos, importance_scores[sorted_idx])\r\n-        ax.set_yticks(pos)\r\n-        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n-        ax.set_xlabel('Importance Score')\r\n-        ax.set_title('Feature Importance')\r\n-        \r\n-        plt.tight_layout()\r\n-        return fig\r\n-    \r\n+\r\n     @staticmethod\r\n     def save_figure(\r\n         fig: plt.Figure,\r\n         filename: str,\r\n         dpi: int = 300\r\n     ):\r\n-        \"\"\"\r\n-        Save figure to file\r\n-        \r\n-        Args:\r\n-            fig: matplotlib figure\r\n-            filename: Output filename\r\n-            dpi: Resolution in dots per inch\r\n-        \"\"\"\r\n+        \"\"\"Save figure to file\"\"\"\r\n         fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n+        plt.close(fig)\r\n         \r\n         \r\n \r\n import os\r\n@@ -710,14 +234,13 @@\n         Returns:\r\n             List of timestamps\r\n         \"\"\"\r\n         try:\r\n-            timestamps = [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-            return timestamps\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n         except Exception as e:\r\n             print(f\"Error generating timestamps: {str(e)}\")\r\n             # Return fallback numeric x-axis\r\n-            return list(range(sequence_length))\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n     \r\n     def plot_prediction_sample(\r\n             self,\r\n             input_seq: torch.Tensor,\r\n"
                },
                {
                    "date": 1733345600256,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,8 +6,10 @@\n - seaborn>=0.12.2\r\n \"\"\"\r\n \r\n import matplotlib.pyplot as plt\r\n+from matplotlib.figure import Figure  # Add this import\r\n+from matplotlib.dates import date2num\r\n import seaborn as sns\r\n import numpy as np\r\n from typing import List, Optional, Tuple\r\n import torch\r\n@@ -37,21 +39,21 @@\n             \r\n         # Handle different input shapes\r\n         if len(data.shape) == 3:  # [batch, seq_len, features]\r\n             # Take first feature and average across batches\r\n-            data = data[:, :, 0].mean(axis=0)\r\n+            data = np.mean(data[:, :, 0], axis=0)  # Fixed mean operation\r\n         elif len(data.shape) == 2:  # [seq_len, features]\r\n             data = data[:, 0]\r\n             \r\n-        return data\r\n+        return data.astype(np.float32)  # Ensure numpy array return type\r\n         \r\n     def plot_predictions(\r\n         self,\r\n         true_values: torch.Tensor,\r\n         predictions: torch.Tensor,\r\n         timestamps: Optional[List] = None,\r\n         title: str = \"Predictions vs Actual\"\r\n-    ) -> plt.Figure:\r\n+    ) -> Figure:  # Fixed return type\r\n         \"\"\"Plot predictions against actual values\"\"\"\r\n         # Prepare data for plotting\r\n         true_values = self._prepare_data_for_plotting(true_values)\r\n         predictions = self._prepare_data_for_plotting(predictions)\r\n@@ -84,9 +86,9 @@\n         self,\r\n         train_losses: List[float],\r\n         val_losses: List[float],\r\n         title: str = \"Training History\"\r\n-    ) -> plt.Figure:\r\n+    ) -> Figure:\r\n         \"\"\"Plot training and validation losses\"\"\"\r\n         fig, ax = plt.subplots(figsize=self.figsize)\r\n         epochs = range(1, len(train_losses) + 1)\r\n         \r\n@@ -105,9 +107,9 @@\n     def plot_feature_importance(\r\n         self,\r\n         importance_scores: np.ndarray,\r\n         feature_names: List[str]\r\n-    ) -> plt.Figure:\r\n+    ) -> Figure:\r\n         \"\"\"Plot feature importance scores\"\"\"\r\n         fig, ax = plt.subplots(figsize=self.figsize)\r\n         \r\n         # Sort by importance\r\n@@ -129,9 +131,9 @@\n         predictions: torch.Tensor,\r\n         batch_idx: int = 0,\r\n         n_samples: int = 5,\r\n         title: str = \"Sample Predictions\"\r\n-    ) -> plt.Figure:\r\n+    ) -> Figure:\r\n         \"\"\"\r\n         Plot individual predictions from a batch\r\n         \r\n         Args:\r\n@@ -185,8 +187,9 @@\n import os\r\n import torch\r\n import numpy as np\r\n import matplotlib.pyplot as plt\r\n+from matplotlib.dates import date2num\r\n from datetime import datetime, timedelta\r\n import pandas as pd\r\n from typing import Tuple, Optional, List\r\n \r\n@@ -248,9 +251,9 @@\n             predicted_seq: torch.Tensor,\r\n             sample_id: int,\r\n             start_time: Optional[datetime] = None,\r\n             scaler = None\r\n-    ):\r\n+    ) -> None:\r\n         \"\"\"\r\n         Create and save a plot showing input, actual and predicted values\r\n         \r\n         Args:\r\n@@ -311,12 +314,14 @@\n                     label='Predicted', \r\n                     linewidth=2)\r\n             \r\n             # Add vertical line separating input and prediction\r\n-            plt.axvline(x=x_values[input_len-1], \r\n-                       color='gray', \r\n-                       linestyle='--', \r\n-                       alpha=0.5)\r\n+            if isinstance(x_values[input_len-1], datetime):\r\n+                x_val = date2num(x_values[input_len-1])\r\n+            else:\r\n+                x_val = float(x_values[input_len-1])\r\n+                \r\n+            plt.axvline(x=x_val, color='gray', linestyle='--', alpha=0.5)\r\n             \r\n             # Customize plot\r\n             plt.title('Input Sequence and Predictions', pad=20)\r\n             plt.xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n@@ -437,9 +442,9 @@\n             \r\n             # Scatter plot\r\n             plt.figure(figsize=self.fig_size)\r\n             plt.scatter(actual, predicted, alpha=0.5)\r\n-            z\r\n+            \r\n             # Add diagonal line\r\n             min_val = min(actual.min(), predicted.min())\r\n             max_val = max(actual.max(), predicted.max())\r\n             plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n"
                },
                {
                    "date": 1733345759279,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,12 @@\n         self.figsize = figsize\r\n         sns.set_style(\"whitegrid\")\r\n         plt.rcParams['figure.figsize'] = figsize\r\n \r\n-    def _prepare_data_for_plotting(self, data: torch.Tensor) -> np.ndarray:\r\n+    def _prepare_data_for_plotting(\r\n+        self, \r\n+        data: Union[torch.Tensor, np.ndarray]\r\n+    ) -> np.ndarray:\r\n         \"\"\"\r\n         Convert tensor to 2D numpy array suitable for plotting\r\n         \r\n         Args:\r\n@@ -39,21 +42,21 @@\n             \r\n         # Handle different input shapes\r\n         if len(data.shape) == 3:  # [batch, seq_len, features]\r\n             # Take first feature and average across batches\r\n-            data = np.mean(data[:, :, 0], axis=0)  # Fixed mean operation\r\n+            data = np.mean(data[:, :, 0], axis=0)\r\n         elif len(data.shape) == 2:  # [seq_len, features]\r\n             data = data[:, 0]\r\n             \r\n-        return data.astype(np.float32)  # Ensure numpy array return type\r\n-        \r\n+        return data.astype(np.float32)\r\n+\r\n     def plot_predictions(\r\n         self,\r\n-        true_values: torch.Tensor,\r\n-        predictions: torch.Tensor,\r\n+        true_values: Union[torch.Tensor, np.ndarray],\r\n+        predictions: Union[torch.Tensor, np.ndarray],\r\n         timestamps: Optional[List] = None,\r\n         title: str = \"Predictions vs Actual\"\r\n-    ) -> Figure:  # Fixed return type\r\n+    ) -> Figure:\r\n         \"\"\"Plot predictions against actual values\"\"\"\r\n         # Prepare data for plotting\r\n         true_values = self._prepare_data_for_plotting(true_values)\r\n         predictions = self._prepare_data_for_plotting(predictions)\r\n@@ -126,10 +129,10 @@\n         return fig\r\n \r\n     def plot_batch_predictions(\r\n         self,\r\n-        true_values: torch.Tensor,\r\n-        predictions: torch.Tensor,\r\n+        true_values: Union[torch.Tensor, np.ndarray],\r\n+        predictions: Union[torch.Tensor, np.ndarray],\r\n         batch_idx: int = 0,\r\n         n_samples: int = 5,\r\n         title: str = \"Sample Predictions\"\r\n     ) -> Figure:\r\n@@ -142,11 +145,13 @@\n             batch_idx: Which batch to plot from\r\n             n_samples: Number of samples to plot\r\n             title: Plot title\r\n         \"\"\"\r\n-        # Convert to numpy\r\n-        true_values = true_values.cpu().detach().numpy()\r\n-        predictions = predictions.cpu().detach().numpy()\r\n+        # Convert to numpy if needed\r\n+        if isinstance(true_values, torch.Tensor):\r\n+            true_values = true_values.cpu().detach().numpy()\r\n+        if isinstance(predictions, torch.Tensor):\r\n+            predictions = predictions.cpu().detach().numpy()\r\n         \r\n         # Create figure with subplots\r\n         n_samples = min(n_samples, true_values.shape[0])\r\n         fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4*n_samples))\r\n@@ -173,17 +178,17 @@\n         return fig\r\n \r\n     @staticmethod\r\n     def save_figure(\r\n-        fig: plt.Figure,\r\n+        fig: Figure,\r\n         filename: str,\r\n         dpi: int = 300\r\n-    ):\r\n+    ) -> None:\r\n         \"\"\"Save figure to file\"\"\"\r\n         fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n         plt.close(fig)\r\n+\r\n         \r\n-        \r\n \r\n import os\r\n import torch\r\n import numpy as np\r\n"
                },
                {
                    "date": 1733345877715,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n from matplotlib.figure import Figure  # Add this import\r\n from matplotlib.dates import date2num\r\n import seaborn as sns\r\n import numpy as np\r\n-from typing import List, Optional, Tuple\r\n+from typing import List, Optional, Tuple, Union\r\n import torch\r\n \r\n class TimeSeriesVisualizer:\r\n     \"\"\"Visualization tools for time series data and model results\"\"\"\r\n@@ -186,10 +186,270 @@\n         \"\"\"Save figure to file\"\"\"\r\n         fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n         plt.close(fig)\r\n \r\n+\r\n+class PredictionVisualizer:\r\n+    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n+    \r\n+    def __init__(\r\n+            self,\r\n+            output_dir: str = \"prediction_plots\",\r\n+            fig_size: Tuple[int, int] = (15, 7),\r\n+            dpi: int = 300\r\n+    ):\r\n+        \"\"\"\r\n+        Initialize visualizer\r\n         \r\n+        Args:\r\n+            output_dir: Directory to save plots\r\n+            fig_size: Figure size for plots\r\n+            dpi: DPI for saved figures\r\n+        \"\"\"\r\n+        self.output_dir = output_dir\r\n+        self.fig_size = fig_size\r\n+        self.dpi = dpi\r\n+        \r\n+        # Create output directory if it doesn't exist\r\n+        os.makedirs(output_dir, exist_ok=True)\r\n+        \r\n+        # Set style\r\n+        plt.style.use('seaborn')\r\n+    \r\n+    def _generate_timestamps(\r\n+            self,\r\n+            start_time: datetime,\r\n+            sequence_length: int,\r\n+            freq: str = 'H'\r\n+    ) -> List[datetime]:\r\n+        \"\"\"\r\n+        Generate timestamps for x-axis\r\n+        \r\n+        Args:\r\n+            start_time: Starting timestamp\r\n+            sequence_length: Number of timestamps to generate\r\n+            freq: Frequency of timestamps ('H' for hourly)\r\n+            \r\n+        Returns:\r\n+            List of timestamps\r\n+        \"\"\"\r\n+        try:\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+        except Exception as e:\r\n+            print(f\"Error generating timestamps: {str(e)}\")\r\n+            # Return fallback numeric x-axis\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+    \r\n+    def plot_prediction_sample(\r\n+            self,\r\n+            input_seq: Union[torch.Tensor, np.ndarray],\r\n+            actual_seq: Union[torch.Tensor, np.ndarray],\r\n+            predicted_seq: Union[torch.Tensor, np.ndarray],\r\n+            sample_id: int,\r\n+            start_time: Optional[datetime] = None,\r\n+            scaler = None\r\n+    ) -> None:\r\n+        \"\"\"\r\n+        Create and save a plot showing input, actual and predicted values\r\n+        \"\"\"\r\n+        try:\r\n+            # Convert tensors to numpy if needed\r\n+            if isinstance(input_seq, torch.Tensor):\r\n+                input_seq = input_seq.cpu().numpy()\r\n+            if isinstance(actual_seq, torch.Tensor):\r\n+                actual_seq = actual_seq.cpu().numpy()\r\n+            if isinstance(predicted_seq, torch.Tensor):\r\n+                predicted_seq = predicted_seq.cpu().numpy()\r\n+            \r\n+            # If we have a scaler, inverse transform the values\r\n+            if scaler is not None:\r\n+                try:\r\n+                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n+                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n+                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n+            \r\n+            # Get sequence lengths\r\n+            input_len = len(input_seq)\r\n+            prediction_len = len(predicted_seq)\r\n+            total_len = input_len + prediction_len\r\n+            \r\n+            # Generate x-axis values\r\n+            if start_time is not None:\r\n+                x_values = self._generate_timestamps(start_time, total_len)\r\n+            else:\r\n+                x_values = list(range(total_len))\r\n+            \r\n+            # Create figure and axis objects\r\n+            fig, ax = plt.subplots(figsize=self.fig_size)\r\n+            \r\n+            # Plot input sequence\r\n+            ax.plot(x_values[:input_len], \r\n+                   input_seq[:, 0], \r\n+                   'b-', \r\n+                   label='Input', \r\n+                   alpha=0.5)\r\n+            \r\n+            # Plot actual values\r\n+            ax.plot(x_values[input_len:], \r\n+                   actual_seq[:, 0], \r\n+                   'g-', \r\n+                   label='Actual', \r\n+                   linewidth=2)\r\n+            \r\n+            # Plot predictions\r\n+            ax.plot(x_values[input_len:], \r\n+                   predicted_seq[:, 0], \r\n+                   'r--', \r\n+                   label='Predicted', \r\n+                   linewidth=2)\r\n+            \r\n+            # Add vertical line separating input and prediction\r\n+            if isinstance(x_values[input_len-1], datetime):\r\n+                x_val = date2num(x_values[input_len-1])\r\n+            else:\r\n+                x_val = float(x_values[input_len-1])\r\n+                \r\n+            ax.axvline(x=x_val, color='gray', linestyle='--', alpha=0.5)\r\n+            \r\n+            # Customize plot\r\n+            ax.set_title('Input Sequence and Predictions', pad=20)\r\n+            ax.set_xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n+            ax.set_ylabel('Value')\r\n+            ax.legend()\r\n+            ax.grid(True, alpha=0.3)\r\n+            \r\n+            # Rotate x-axis labels if using timestamps\r\n+            if isinstance(x_values[0], datetime):\r\n+                plt.xticks(rotation=45)\r\n+            \r\n+            # Tight layout to prevent label cutoff\r\n+            plt.tight_layout()\r\n+            \r\n+            # Save plot\r\n+            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n+            fig.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close(fig)\r\n+            \r\n+            print(f\"Saved prediction plot to {filename}\")\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating prediction plot: {str(e)}\")\r\n+            plt.close()\r\n \r\n+    def plot_multiple_samples(\r\n+            self,\r\n+            model: torch.nn.Module,\r\n+            dataset,\r\n+            num_samples: int = 5,\r\n+            scaler = None,\r\n+            device: torch.device = torch.device('cpu')\r\n+    ) -> None:\r\n+        \"\"\"\r\n+        Create plots for multiple random samples from dataset\r\n+        \"\"\"\r\n+        try:\r\n+            model.eval()  # Set model to evaluation mode\r\n+            \r\n+            # Generate random indices\r\n+            total_samples = len(dataset)\r\n+            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n+            \r\n+            with torch.no_grad():\r\n+                for idx in indices:\r\n+                    # Get sample from dataset\r\n+                    input_seq, decoder_input, target = dataset[idx]\r\n+                    \r\n+                    # Prepare input for model\r\n+                    input_batch = input_seq.unsqueeze(0).to(device)\r\n+                    \r\n+                    # Get prediction\r\n+                    prediction, _ = model(input_batch)\r\n+                    \r\n+                    # Remove batch dimension\r\n+                    prediction = prediction.squeeze(0)\r\n+                    \r\n+                    # Plot sample\r\n+                    self.plot_prediction_sample(\r\n+                        input_seq=input_seq,\r\n+                        actual_seq=target,\r\n+                        predicted_seq=prediction,\r\n+                        sample_id=idx,\r\n+                        scaler=scaler\r\n+                    )\r\n+                    \r\n+        except Exception as e:\r\n+            print(f\"Error plotting multiple samples: {str(e)}\")\r\n+\r\n+    def create_error_analysis_plots(\r\n+            self,\r\n+            actual_values: Union[torch.Tensor, np.ndarray],\r\n+            predicted_values: Union[torch.Tensor, np.ndarray],\r\n+            scaler = None\r\n+    ) -> None:\r\n+        \"\"\"\r\n+        Create error analysis plots (error distribution, scatter plot)\r\n+        \"\"\"\r\n+        try:\r\n+            # Convert to numpy if needed\r\n+            if isinstance(actual_values, torch.Tensor):\r\n+                actual = actual_values.cpu().numpy().reshape(-1)\r\n+            else:\r\n+                actual = actual_values.reshape(-1)\r\n+                \r\n+            if isinstance(predicted_values, torch.Tensor):\r\n+                predicted = predicted_values.cpu().numpy().reshape(-1)\r\n+            else:\r\n+                predicted = predicted_values.reshape(-1)\r\n+            \r\n+            if scaler is not None:\r\n+                try:\r\n+                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n+                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-predicted.shape)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n+            \r\n+            # Calculate errors\r\n+            errors = predicted - actual\r\n+            \r\n+            # Create figure and axis for error distribution plot\r\n+            fig_err, ax_err = plt.subplots(figsize=self.fig_size)\r\n+            ax_err.hist(errors, bins=50, edgecolor='black')\r\n+            ax_err.set_title('Error Distribution')\r\n+            ax_err.set_xlabel('Prediction Error')\r\n+            ax_err.set_ylabel('Frequency')\r\n+            plt.tight_layout()\r\n+            \r\n+            # Save error distribution plot\r\n+            error_dist_path = os.path.join(self.output_dir, 'error_distribution.png')\r\n+            fig_err.savefig(error_dist_path, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close(fig_err)\r\n+            \r\n+            # Create figure and axis for scatter plot\r\n+            fig_scatter, ax_scatter = plt.subplots(figsize=self.fig_size)\r\n+            ax_scatter.scatter(actual, predicted, alpha=0.5)\r\n+            \r\n+            # Add diagonal line for perfect predictions\r\n+            min_val = min(actual.min(), predicted.min())\r\n+            max_val = max(actual.max(), predicted.max())\r\n+            ax_scatter.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n+            \r\n+            ax_scatter.set_title('Actual vs Predicted Values')\r\n+            ax_scatter.set_xlabel('Actual Values')\r\n+            ax_scatter.set_ylabel('Predicted Values')\r\n+            plt.tight_layout()\r\n+            \r\n+            # Save scatter plot\r\n+            scatter_path = os.path.join(self.output_dir, 'actual_vs_predicted.png')\r\n+            fig_scatter.savefig(scatter_path, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close(fig_scatter)\r\n+            \r\n+        except Exception as e:\r\n+            print(f\"Error creating analysis plots: {str(e)}\")\r\n+            plt.close('all')  # Ensure all figures are closed in case of error            \r\n+        \r\n+\r\n import os\r\n import torch\r\n import numpy as np\r\n import matplotlib.pyplot as plt\r\n"
                },
                {
                    "date": 1733345994514,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,14 +6,17 @@\n - seaborn>=0.12.2\r\n \"\"\"\r\n \r\n import matplotlib.pyplot as plt\r\n-from matplotlib.figure import Figure  # Add this import\r\n+from matplotlib.figure import Figure\r\n from matplotlib.dates import date2num\r\n import seaborn as sns\r\n import numpy as np\r\n+import torch\r\n from typing import List, Optional, Tuple, Union\r\n-import torch\r\n+from datetime import datetime, timedelta\r\n+import os\r\n+import pandas as pd\r\n \r\n class TimeSeriesVisualizer:\r\n     \"\"\"Visualization tools for time series data and model results\"\"\"\r\n     \r\n@@ -445,284 +448,5 @@\n             plt.close(fig_scatter)\r\n             \r\n         except Exception as e:\r\n             print(f\"Error creating analysis plots: {str(e)}\")\r\n-            plt.close('all')  # Ensure all figures are closed in case of error            \r\n-        \r\n-\r\n-import os\r\n-import torch\r\n-import numpy as np\r\n-import matplotlib.pyplot as plt\r\n-from matplotlib.dates import date2num\r\n-from datetime import datetime, timedelta\r\n-import pandas as pd\r\n-from typing import Tuple, Optional, List\r\n-\r\n-class PredictionVisualizer:\r\n-    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n-    \r\n-    def __init__(\r\n-            self,\r\n-            output_dir: str = \"prediction_plots\",\r\n-            fig_size: Tuple[int, int] = (15, 7),\r\n-            dpi: int = 300\r\n-    ):\r\n-        \"\"\"\r\n-        Initialize visualizer\r\n-        \r\n-        Args:\r\n-            output_dir: Directory to save plots\r\n-            fig_size: Figure size for plots\r\n-            dpi: DPI for saved figures\r\n-        \"\"\"\r\n-        self.output_dir = output_dir\r\n-        self.fig_size = fig_size\r\n-        self.dpi = dpi\r\n-        \r\n-        # Create output directory if it doesn't exist\r\n-        os.makedirs(output_dir, exist_ok=True)\r\n-        \r\n-        # Set style\r\n-        plt.style.use('seaborn')\r\n-    \r\n-    def _generate_timestamps(\r\n-            self,\r\n-            start_time: datetime,\r\n-            sequence_length: int,\r\n-            freq: str = 'H'\r\n-    ) -> List[datetime]:\r\n-        \"\"\"\r\n-        Generate timestamps for x-axis\r\n-        \r\n-        Args:\r\n-            start_time: Starting timestamp\r\n-            sequence_length: Number of timestamps to generate\r\n-            freq: Frequency of timestamps ('H' for hourly)\r\n-            \r\n-        Returns:\r\n-            List of timestamps\r\n-        \"\"\"\r\n-        try:\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-        except Exception as e:\r\n-            print(f\"Error generating timestamps: {str(e)}\")\r\n-            # Return fallback numeric x-axis\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-    \r\n-    def plot_prediction_sample(\r\n-            self,\r\n-            input_seq: torch.Tensor,\r\n-            actual_seq: torch.Tensor,\r\n-            predicted_seq: torch.Tensor,\r\n-            sample_id: int,\r\n-            start_time: Optional[datetime] = None,\r\n-            scaler = None\r\n-    ) -> None:\r\n-        \"\"\"\r\n-        Create and save a plot showing input, actual and predicted values\r\n-        \r\n-        Args:\r\n-            input_seq: Input sequence tensor\r\n-            actual_seq: Actual values tensor\r\n-            predicted_seq: Predicted values tensor\r\n-            sample_id: Sample identifier for filename\r\n-            start_time: Starting timestamp (optional)\r\n-            scaler: Scaler object for inverse transform (optional)\r\n-        \"\"\"\r\n-        try:\r\n-            # Move tensors to CPU and convert to numpy\r\n-            input_seq = input_seq.cpu().numpy()\r\n-            actual_seq = actual_seq.cpu().numpy()\r\n-            predicted_seq = predicted_seq.cpu().numpy()\r\n-            \r\n-            # If we have a scaler, inverse transform the values\r\n-            if scaler is not None:\r\n-                try:\r\n-                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n-                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n-                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Get sequence lengths\r\n-            input_len = len(input_seq)\r\n-            prediction_len = len(predicted_seq)\r\n-            total_len = input_len + prediction_len\r\n-            \r\n-            # Generate x-axis values\r\n-            if start_time is not None:\r\n-                x_values = self._generate_timestamps(start_time, total_len)\r\n-            else:\r\n-                x_values = list(range(total_len))\r\n-            \r\n-            # Create figure\r\n-            plt.figure(figsize=self.fig_size)\r\n-            \r\n-            # Plot input sequence\r\n-            plt.plot(x_values[:input_len], \r\n-                    input_seq[:, 0], \r\n-                    'b-', \r\n-                    label='Input', \r\n-                    alpha=0.5)\r\n-            \r\n-            # Plot actual values\r\n-            plt.plot(x_values[input_len:], \r\n-                    actual_seq[:, 0], \r\n-                    'g-', \r\n-                    label='Actual', \r\n-                    linewidth=2)\r\n-            \r\n-            # Plot predictions\r\n-            plt.plot(x_values[input_len:], \r\n-                    predicted_seq[:, 0], \r\n-                    'r--', \r\n-                    label='Predicted', \r\n-                    linewidth=2)\r\n-            \r\n-            # Add vertical line separating input and prediction\r\n-            if isinstance(x_values[input_len-1], datetime):\r\n-                x_val = date2num(x_values[input_len-1])\r\n-            else:\r\n-                x_val = float(x_values[input_len-1])\r\n-                \r\n-            plt.axvline(x=x_val, color='gray', linestyle='--', alpha=0.5)\r\n-            \r\n-            # Customize plot\r\n-            plt.title('Input Sequence and Predictions', pad=20)\r\n-            plt.xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n-            plt.ylabel('Value')\r\n-            plt.legend()\r\n-            plt.grid(True, alpha=0.3)\r\n-            \r\n-            # Rotate x-axis labels if using timestamps\r\n-            if isinstance(x_values[0], datetime):\r\n-                plt.xticks(rotation=45)\r\n-            \r\n-            # Tight layout to prevent label cutoff\r\n-            plt.tight_layout()\r\n-            \r\n-            # Save plot\r\n-            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n-            plt.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-            print(f\"Saved prediction plot to {filename}\")\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating prediction plot: {str(e)}\")\r\n-            # Ensure figure is closed even if error occurs\r\n-            plt.close()\r\n-    \r\n-    def plot_multiple_samples(\r\n-            self,\r\n-            model: torch.nn.Module,\r\n-            dataset,\r\n-            num_samples: int = 5,\r\n-            scaler = None,\r\n-            device: torch.device = torch.device('cpu')\r\n-    ):\r\n-        \"\"\"\r\n-        Create plots for multiple random samples from dataset\r\n-        \r\n-        Args:\r\n-            model: Trained model\r\n-            dataset: Dataset containing samples\r\n-            num_samples: Number of samples to plot\r\n-            scaler: Scaler object for inverse transform\r\n-            device: Device to run model on\r\n-        \"\"\"\r\n-        try:\r\n-            model.eval()  # Set model to evaluation mode\r\n-            \r\n-            # Generate random indices\r\n-            total_samples = len(dataset)\r\n-            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n-            \r\n-            with torch.no_grad():\r\n-                for idx in indices:\r\n-                    # Get sample from dataset\r\n-                    input_seq, decoder_input, target = dataset[idx]\r\n-                    \r\n-                    # Prepare input for model\r\n-                    input_batch = input_seq.unsqueeze(0).to(device)\r\n-                    \r\n-                    # Get prediction\r\n-                    prediction, _ = model(input_batch)\r\n-                    \r\n-                    # Remove batch dimension\r\n-                    prediction = prediction.squeeze(0)\r\n-                    \r\n-                    # Plot sample\r\n-                    self.plot_prediction_sample(\r\n-                        input_seq=input_seq,\r\n-                        actual_seq=target,\r\n-                        predicted_seq=prediction,\r\n-                        sample_id=idx,\r\n-                        scaler=scaler\r\n-                    )\r\n-                    \r\n-        except Exception as e:\r\n-            print(f\"Error plotting multiple samples: {str(e)}\")\r\n-\r\n-    def create_error_analysis_plots(\r\n-            self,\r\n-            actual_values: torch.Tensor,\r\n-            predicted_values: torch.Tensor,\r\n-            scaler = None\r\n-    ):\r\n-        \"\"\"\r\n-        Create error analysis plots (error distribution, scatter plot)\r\n-        \r\n-        Args:\r\n-            actual_values: Tensor of actual values\r\n-            predicted_values: Tensor of predicted values\r\n-            scaler: Scaler object for inverse transform\r\n-        \"\"\"\r\n-        try:\r\n-            # Convert to numpy and reshape\r\n-            actual = actual_values.cpu().numpy().reshape(-1)\r\n-            predicted = predicted_values.cpu().numpy().reshape(-1)\r\n-            \r\n-            if scaler is not None:\r\n-                try:\r\n-                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n-                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-1)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Calculate errors\r\n-            errors = predicted - actual\r\n-            \r\n-            # Error distribution plot\r\n-            plt.figure(figsize=self.fig_size)\r\n-            plt.hist(errors, bins=50, edgecolor='black')\r\n-            plt.title('Error Distribution')\r\n-            plt.xlabel('Prediction Error')\r\n-            plt.ylabel('Frequency')\r\n-            plt.tight_layout()\r\n-            plt.savefig(os.path.join(self.output_dir, 'error_distribution.png'), \r\n-                       dpi=self.dpi, \r\n-                       bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-            # Scatter plot\r\n-            plt.figure(figsize=self.fig_size)\r\n-            plt.scatter(actual, predicted, alpha=0.5)\r\n-            \r\n-            # Add diagonal line\r\n-            min_val = min(actual.min(), predicted.min())\r\n-            max_val = max(actual.max(), predicted.max())\r\n-            plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n-            \r\n-            plt.title('Actual vs Predicted Values')\r\n-            plt.xlabel('Actual Values')\r\n-            plt.ylabel('Predicted Values')\r\n-            plt.tight_layout()\r\n-            plt.savefig(os.path.join(self.output_dir, 'actual_vs_predicted.png'), \r\n-                       dpi=self.dpi, \r\n-                       bbox_inches='tight')\r\n-            plt.close()\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating analysis plots: {str(e)}\")\r\n-            plt.close()\n\\ No newline at end of file\n+            plt.close('all')  # Ensure all figures are closed in case of error\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733346273347,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,12 +3,26 @@\n \r\n Dependencies:\r\n - matplotlib>=3.7.2\r\n - seaborn>=0.12.2\r\n+- numpy>=1.24.3\r\n+- torch>=2.0.1\r\n \"\"\"\r\n \r\n import matplotlib.pyplot as plt\r\n from matplotlib.figure import Figure\r\n+from matplotlib.dates import date2num, num2date\r\n+import seaborn as sns\r\n+import numpy as np\r\n+import numpy.typing as npt\r\n+import torch\r\n+from typing import List, Optional, Tuple, Union, Any\r\n+from datetime import datetime, timedelta\r\n+import os\r\n+import pandas as pd\r\n+\r\n+import matplotlib.pyplot as plt\r\n+from matplotlib.figure import Figure\r\n from matplotlib.dates import date2num\r\n import seaborn as sns\r\n import numpy as np\r\n import torch\r\n@@ -16,8 +30,137 @@\n from datetime import datetime, timedelta\r\n import os\r\n import pandas as pd\r\n \r\n+class PredictionVisualizer:\r\n+    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n+    \r\n+    def __init__(\r\n+            self,\r\n+            output_dir: str = \"prediction_plots\",\r\n+            fig_size: Tuple[int, int] = (15, 7),\r\n+            dpi: int = 300\r\n+    ):\r\n+        self.output_dir = output_dir\r\n+        self.fig_size = fig_size\r\n+        self.dpi = dpi\r\n+        os.makedirs(output_dir, exist_ok=True)\r\n+        plt.style.use('seaborn')\r\n+    \r\n+    def _convert_time_to_num(self, time_point: Union[datetime, int]) -> float:\r\n+        \"\"\"Helper to safely convert datetime or int to float for plotting\"\"\"\r\n+        if isinstance(time_point, datetime):\r\n+            return date2num(time_point)\r\n+        return float(time_point)\r\n+    \r\n+    def _generate_timestamps(\r\n+            self,\r\n+            start_time: datetime,\r\n+            sequence_length: int,\r\n+            freq: str = 'H'\r\n+    ) -> List[datetime]:\r\n+        \"\"\"Generate timestamps list\"\"\"\r\n+        timestamps = []\r\n+        current_time = start_time\r\n+        try:\r\n+            for _ in range(sequence_length):\r\n+                timestamps.append(current_time)\r\n+                current_time += timedelta(hours=1 if freq == 'H' else 0)\r\n+            return timestamps\r\n+        except Exception as e:\r\n+            print(f\"Error generating timestamps: {str(e)}\")\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+    \r\n+    def plot_prediction_sample(\r\n+            self,\r\n+            input_seq: Union[torch.Tensor, np.ndarray],\r\n+            actual_seq: Union[torch.Tensor, np.ndarray],\r\n+            predicted_seq: Union[torch.Tensor, np.ndarray],\r\n+            sample_id: int,\r\n+            start_time: Optional[datetime] = None,\r\n+            scaler: Any = None\r\n+    ) -> None:\r\n+        \"\"\"Create and save a plot showing input, actual and predicted values\"\"\"\r\n+        try:\r\n+            # Convert to numpy arrays safely\r\n+            input_seq = self._ensure_numpy(input_seq)\r\n+            actual_seq = self._ensure_numpy(actual_seq)\r\n+            predicted_seq = self._ensure_numpy(predicted_seq)\r\n+            \r\n+            # Apply inverse transform if scaler provided\r\n+            if scaler is not None:\r\n+                try:\r\n+                    input_seq = self._apply_scaler(input_seq, scaler)\r\n+                    actual_seq = self._apply_scaler(actual_seq, scaler)\r\n+                    predicted_seq = self._apply_scaler(predicted_seq, scaler)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Inverse transform failed: {str(e)}\")\r\n+            \r\n+            # Create x-axis values\r\n+            input_len = len(input_seq)\r\n+            prediction_len = len(predicted_seq)\r\n+            total_len = input_len + prediction_len\r\n+            \r\n+            x_values = (self._generate_timestamps(start_time, total_len) \r\n+                       if start_time is not None \r\n+                       else np.arange(total_len))\r\n+            \r\n+            # Create figure and plot\r\n+            fig, ax = plt.subplots(figsize=self.fig_size)\r\n+            \r\n+            # Plot sequences\r\n+            ax.plot(x_values[:input_len], input_seq[:, 0], 'b-', \r\n+                   label='Input', alpha=0.5)\r\n+            ax.plot(x_values[input_len:], actual_seq[:, 0], 'g-', \r\n+                   label='Actual', linewidth=2)\r\n+            ax.plot(x_values[input_len:], predicted_seq[:, 0], 'r--', \r\n+                   label='Predicted', linewidth=2)\r\n+            \r\n+            # Add vertical separator line\r\n+            separator_x = (self._convert_time_to_num(x_values[input_len-1]) \r\n+                         if isinstance(x_values[0], datetime) \r\n+                         else float(x_values[input_len-1]))\r\n+            ax.axvline(x=separator_x, color='gray', linestyle='--', alpha=0.5)\r\n+            \r\n+            # Customize plot\r\n+            ax.set_title('Input Sequence and Predictions', pad=20)\r\n+            ax.set_xlabel('Time' if start_time is None else 'Timestamp')\r\n+            ax.set_ylabel('Value')\r\n+            ax.legend()\r\n+            ax.grid(True, alpha=0.3)\r\n+            \r\n+            if isinstance(x_values[0], datetime):\r\n+                plt.xticks(rotation=45)\r\n+            \r\n+            plt.tight_layout()\r\n+            \r\n+            # Save plot\r\n+            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n+            fig.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close(fig)\r\n+            \r\n+            print(f\"Saved prediction plot to {filename}\")\r\n+        \r\n+        except Exception as e:\r\n+            print(f\"Error creating prediction plot: {str(e)}\")\r\n+            plt.close('all')\r\n+\r\n+    def _ensure_numpy(self, data: Union[torch.Tensor, np.ndarray]) -> np.ndarray:\r\n+        \"\"\"Safely convert input to numpy array\"\"\"\r\n+        if isinstance(data, torch.Tensor):\r\n+            return data.cpu().detach().numpy()\r\n+        return np.asarray(data)\r\n+\r\n+    def _apply_scaler(self, data: np.ndarray, scaler: Any) -> np.ndarray:\r\n+        \"\"\"Apply inverse transform using scaler\"\"\"\r\n+        reshaped = data.reshape(-1, 1)\r\n+        transformed = scaler.inverse_transform(reshaped)\r\n+        return transformed.reshape(data.shape)\r\n+    \r\n+    \r\n+    \r\n+    \r\n+    \r\n class TimeSeriesVisualizer:\r\n     \"\"\"Visualization tools for time series data and model results\"\"\"\r\n     \r\n     def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n@@ -187,266 +330,5 @@\n         dpi: int = 300\r\n     ) -> None:\r\n         \"\"\"Save figure to file\"\"\"\r\n         fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n-        plt.close(fig)\r\n-\r\n-\r\n-class PredictionVisualizer:\r\n-    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n-    \r\n-    def __init__(\r\n-            self,\r\n-            output_dir: str = \"prediction_plots\",\r\n-            fig_size: Tuple[int, int] = (15, 7),\r\n-            dpi: int = 300\r\n-    ):\r\n-        \"\"\"\r\n-        Initialize visualizer\r\n-        \r\n-        Args:\r\n-            output_dir: Directory to save plots\r\n-            fig_size: Figure size for plots\r\n-            dpi: DPI for saved figures\r\n-        \"\"\"\r\n-        self.output_dir = output_dir\r\n-        self.fig_size = fig_size\r\n-        self.dpi = dpi\r\n-        \r\n-        # Create output directory if it doesn't exist\r\n-        os.makedirs(output_dir, exist_ok=True)\r\n-        \r\n-        # Set style\r\n-        plt.style.use('seaborn')\r\n-    \r\n-    def _generate_timestamps(\r\n-            self,\r\n-            start_time: datetime,\r\n-            sequence_length: int,\r\n-            freq: str = 'H'\r\n-    ) -> List[datetime]:\r\n-        \"\"\"\r\n-        Generate timestamps for x-axis\r\n-        \r\n-        Args:\r\n-            start_time: Starting timestamp\r\n-            sequence_length: Number of timestamps to generate\r\n-            freq: Frequency of timestamps ('H' for hourly)\r\n-            \r\n-        Returns:\r\n-            List of timestamps\r\n-        \"\"\"\r\n-        try:\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-        except Exception as e:\r\n-            print(f\"Error generating timestamps: {str(e)}\")\r\n-            # Return fallback numeric x-axis\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-    \r\n-    def plot_prediction_sample(\r\n-            self,\r\n-            input_seq: Union[torch.Tensor, np.ndarray],\r\n-            actual_seq: Union[torch.Tensor, np.ndarray],\r\n-            predicted_seq: Union[torch.Tensor, np.ndarray],\r\n-            sample_id: int,\r\n-            start_time: Optional[datetime] = None,\r\n-            scaler = None\r\n-    ) -> None:\r\n-        \"\"\"\r\n-        Create and save a plot showing input, actual and predicted values\r\n-        \"\"\"\r\n-        try:\r\n-            # Convert tensors to numpy if needed\r\n-            if isinstance(input_seq, torch.Tensor):\r\n-                input_seq = input_seq.cpu().numpy()\r\n-            if isinstance(actual_seq, torch.Tensor):\r\n-                actual_seq = actual_seq.cpu().numpy()\r\n-            if isinstance(predicted_seq, torch.Tensor):\r\n-                predicted_seq = predicted_seq.cpu().numpy()\r\n-            \r\n-            # If we have a scaler, inverse transform the values\r\n-            if scaler is not None:\r\n-                try:\r\n-                    input_seq = scaler.inverse_transform(input_seq.reshape(-1, 1)).reshape(input_seq.shape)\r\n-                    actual_seq = scaler.inverse_transform(actual_seq.reshape(-1, 1)).reshape(actual_seq.shape)\r\n-                    predicted_seq = scaler.inverse_transform(predicted_seq.reshape(-1, 1)).reshape(predicted_seq.shape)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Get sequence lengths\r\n-            input_len = len(input_seq)\r\n-            prediction_len = len(predicted_seq)\r\n-            total_len = input_len + prediction_len\r\n-            \r\n-            # Generate x-axis values\r\n-            if start_time is not None:\r\n-                x_values = self._generate_timestamps(start_time, total_len)\r\n-            else:\r\n-                x_values = list(range(total_len))\r\n-            \r\n-            # Create figure and axis objects\r\n-            fig, ax = plt.subplots(figsize=self.fig_size)\r\n-            \r\n-            # Plot input sequence\r\n-            ax.plot(x_values[:input_len], \r\n-                   input_seq[:, 0], \r\n-                   'b-', \r\n-                   label='Input', \r\n-                   alpha=0.5)\r\n-            \r\n-            # Plot actual values\r\n-            ax.plot(x_values[input_len:], \r\n-                   actual_seq[:, 0], \r\n-                   'g-', \r\n-                   label='Actual', \r\n-                   linewidth=2)\r\n-            \r\n-            # Plot predictions\r\n-            ax.plot(x_values[input_len:], \r\n-                   predicted_seq[:, 0], \r\n-                   'r--', \r\n-                   label='Predicted', \r\n-                   linewidth=2)\r\n-            \r\n-            # Add vertical line separating input and prediction\r\n-            if isinstance(x_values[input_len-1], datetime):\r\n-                x_val = date2num(x_values[input_len-1])\r\n-            else:\r\n-                x_val = float(x_values[input_len-1])\r\n-                \r\n-            ax.axvline(x=x_val, color='gray', linestyle='--', alpha=0.5)\r\n-            \r\n-            # Customize plot\r\n-            ax.set_title('Input Sequence and Predictions', pad=20)\r\n-            ax.set_xlabel('Time' if isinstance(x_values[0], datetime) else 'Time Step')\r\n-            ax.set_ylabel('Value')\r\n-            ax.legend()\r\n-            ax.grid(True, alpha=0.3)\r\n-            \r\n-            # Rotate x-axis labels if using timestamps\r\n-            if isinstance(x_values[0], datetime):\r\n-                plt.xticks(rotation=45)\r\n-            \r\n-            # Tight layout to prevent label cutoff\r\n-            plt.tight_layout()\r\n-            \r\n-            # Save plot\r\n-            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n-            fig.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close(fig)\r\n-            \r\n-            print(f\"Saved prediction plot to {filename}\")\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating prediction plot: {str(e)}\")\r\n-            plt.close()\r\n-\r\n-    def plot_multiple_samples(\r\n-            self,\r\n-            model: torch.nn.Module,\r\n-            dataset,\r\n-            num_samples: int = 5,\r\n-            scaler = None,\r\n-            device: torch.device = torch.device('cpu')\r\n-    ) -> None:\r\n-        \"\"\"\r\n-        Create plots for multiple random samples from dataset\r\n-        \"\"\"\r\n-        try:\r\n-            model.eval()  # Set model to evaluation mode\r\n-            \r\n-            # Generate random indices\r\n-            total_samples = len(dataset)\r\n-            indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)\r\n-            \r\n-            with torch.no_grad():\r\n-                for idx in indices:\r\n-                    # Get sample from dataset\r\n-                    input_seq, decoder_input, target = dataset[idx]\r\n-                    \r\n-                    # Prepare input for model\r\n-                    input_batch = input_seq.unsqueeze(0).to(device)\r\n-                    \r\n-                    # Get prediction\r\n-                    prediction, _ = model(input_batch)\r\n-                    \r\n-                    # Remove batch dimension\r\n-                    prediction = prediction.squeeze(0)\r\n-                    \r\n-                    # Plot sample\r\n-                    self.plot_prediction_sample(\r\n-                        input_seq=input_seq,\r\n-                        actual_seq=target,\r\n-                        predicted_seq=prediction,\r\n-                        sample_id=idx,\r\n-                        scaler=scaler\r\n-                    )\r\n-                    \r\n-        except Exception as e:\r\n-            print(f\"Error plotting multiple samples: {str(e)}\")\r\n-\r\n-    def create_error_analysis_plots(\r\n-            self,\r\n-            actual_values: Union[torch.Tensor, np.ndarray],\r\n-            predicted_values: Union[torch.Tensor, np.ndarray],\r\n-            scaler = None\r\n-    ) -> None:\r\n-        \"\"\"\r\n-        Create error analysis plots (error distribution, scatter plot)\r\n-        \"\"\"\r\n-        try:\r\n-            # Convert to numpy if needed\r\n-            if isinstance(actual_values, torch.Tensor):\r\n-                actual = actual_values.cpu().numpy().reshape(-1)\r\n-            else:\r\n-                actual = actual_values.reshape(-1)\r\n-                \r\n-            if isinstance(predicted_values, torch.Tensor):\r\n-                predicted = predicted_values.cpu().numpy().reshape(-1)\r\n-            else:\r\n-                predicted = predicted_values.reshape(-1)\r\n-            \r\n-            if scaler is not None:\r\n-                try:\r\n-                    actual = scaler.inverse_transform(actual.reshape(-1, 1)).reshape(-1)\r\n-                    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(-predicted.shape)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Could not apply inverse transform: {str(e)}\")\r\n-            \r\n-            # Calculate errors\r\n-            errors = predicted - actual\r\n-            \r\n-            # Create figure and axis for error distribution plot\r\n-            fig_err, ax_err = plt.subplots(figsize=self.fig_size)\r\n-            ax_err.hist(errors, bins=50, edgecolor='black')\r\n-            ax_err.set_title('Error Distribution')\r\n-            ax_err.set_xlabel('Prediction Error')\r\n-            ax_err.set_ylabel('Frequency')\r\n-            plt.tight_layout()\r\n-            \r\n-            # Save error distribution plot\r\n-            error_dist_path = os.path.join(self.output_dir, 'error_distribution.png')\r\n-            fig_err.savefig(error_dist_path, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close(fig_err)\r\n-            \r\n-            # Create figure and axis for scatter plot\r\n-            fig_scatter, ax_scatter = plt.subplots(figsize=self.fig_size)\r\n-            ax_scatter.scatter(actual, predicted, alpha=0.5)\r\n-            \r\n-            # Add diagonal line for perfect predictions\r\n-            min_val = min(actual.min(), predicted.min())\r\n-            max_val = max(actual.max(), predicted.max())\r\n-            ax_scatter.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\r\n-            \r\n-            ax_scatter.set_title('Actual vs Predicted Values')\r\n-            ax_scatter.set_xlabel('Actual Values')\r\n-            ax_scatter.set_ylabel('Predicted Values')\r\n-            plt.tight_layout()\r\n-            \r\n-            # Save scatter plot\r\n-            scatter_path = os.path.join(self.output_dir, 'actual_vs_predicted.png')\r\n-            fig_scatter.savefig(scatter_path, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close(fig_scatter)\r\n-            \r\n-        except Exception as e:\r\n-            print(f\"Error creating analysis plots: {str(e)}\")\r\n-            plt.close('all')  # Ensure all figures are closed in case of error\n\\ No newline at end of file\n+        plt.close(fig)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733346473354,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -172,30 +172,26 @@\n     def _prepare_data_for_plotting(\r\n         self, \r\n         data: Union[torch.Tensor, np.ndarray]\r\n     ) -> np.ndarray:\r\n-        \"\"\"\r\n-        Convert tensor to 2D numpy array suitable for plotting\r\n-        \r\n-        Args:\r\n-            data: Input tensor of shape [batch, seq_len, features] or [seq_len, features]\r\n-            \r\n-        Returns:\r\n-            2D numpy array of shape [seq_len]\r\n-        \"\"\"\r\n         # Convert to numpy if it's a tensor\r\n         if isinstance(data, torch.Tensor):\r\n             data = data.cpu().detach().numpy()\r\n+        else:\r\n+            data = np.asarray(data)\r\n             \r\n         # Handle different input shapes\r\n         if len(data.shape) == 3:  # [batch, seq_len, features]\r\n             # Take first feature and average across batches\r\n             data = np.mean(data[:, :, 0], axis=0)\r\n         elif len(data.shape) == 2:  # [seq_len, features]\r\n             data = data[:, 0]\r\n             \r\n+        # Ensure data is a NumPy array before calling astype\r\n+        data = np.asarray(data)\r\n         return data.astype(np.float32)\r\n \r\n+\r\n     def plot_predictions(\r\n         self,\r\n         true_values: Union[torch.Tensor, np.ndarray],\r\n         predictions: Union[torch.Tensor, np.ndarray],\r\n"
                },
                {
                    "date": 1733346503741,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,323 @@\n+\"\"\"\r\n+Visualization utilities for time series forecasting.\r\n+\r\n+Dependencies:\r\n+- matplotlib>=3.7.2\r\n+- seaborn>=0.12.2\r\n+- numpy>=1.24.3\r\n+- torch>=2.0.1\r\n+\"\"\"\r\n+\r\n+import matplotlib.pyplot as plt\r\n+from matplotlib.figure import Figure\r\n+from matplotlib.dates import date2num, num2date\r\n+import seaborn as sns\r\n+import numpy as np\r\n+import numpy.typing as npt\r\n+import torch\r\n+from typing import List, Optional, Tuple, Union, Any\r\n+from datetime import datetime, timedelta\r\n+import os\r\n+import pandas as pd\r\n+\r\n+import matplotlib.pyplot as plt\r\n+from matplotlib.figure import Figure\r\n+from matplotlib.dates import date2num\r\n+import seaborn as sns\r\n+import numpy as np\r\n+import torch\r\n+from typing import List, Optional, Tuple, Union\r\n+from datetime import datetime, timedelta\r\n+import os\r\n+import pandas as pd\r\n+\r\n+class PredictionVisualizer:\r\n+    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n+    \r\n+    def __init__(\r\n+            self,\r\n+            output_dir: str = \"prediction_plots\",\r\n+            fig_size: Tuple[int, int] = (15, 7),\r\n+            dpi: int = 300\r\n+    ):\r\n+        self.output_dir = output_dir\r\n+        self.fig_size = fig_size\r\n+        self.dpi = dpi\r\n+        os.makedirs(output_dir, exist_ok=True)\r\n+        plt.style.use('seaborn')\r\n+    \r\n+    def _convert_time_to_num(self, time_point: Union[datetime, int]) -> float:\r\n+        \"\"\"Helper to safely convert datetime or int to float for plotting\"\"\"\r\n+        if isinstance(time_point, datetime):\r\n+            return date2num(time_point)\r\n+        return float(time_point)\r\n+    \r\n+    def _generate_timestamps(\r\n+            self,\r\n+            start_time: datetime,\r\n+            sequence_length: int,\r\n+            freq: str = 'H'\r\n+    ) -> List[datetime]:\r\n+        \"\"\"Generate timestamps list\"\"\"\r\n+        timestamps = []\r\n+        current_time = start_time\r\n+        try:\r\n+            for _ in range(sequence_length):\r\n+                timestamps.append(current_time)\r\n+                current_time += timedelta(hours=1 if freq == 'H' else 0)\r\n+            return timestamps\r\n+        except Exception as e:\r\n+            print(f\"Error generating timestamps: {str(e)}\")\r\n+            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n+    \r\n+    def plot_prediction_sample(\r\n+            self,\r\n+            input_seq: Union[torch.Tensor, np.ndarray],\r\n+            actual_seq: Union[torch.Tensor, np.ndarray],\r\n+            predicted_seq: Union[torch.Tensor, np.ndarray],\r\n+            sample_id: int,\r\n+            start_time: Optional[datetime] = None,\r\n+            scaler: Any = None\r\n+    ) -> None:\r\n+        \"\"\"Create and save a plot showing input, actual and predicted values\"\"\"\r\n+        try:\r\n+            # Convert to numpy arrays safely\r\n+            input_seq = self._ensure_numpy(input_seq)\r\n+            actual_seq = self._ensure_numpy(actual_seq)\r\n+            predicted_seq = self._ensure_numpy(predicted_seq)\r\n+            \r\n+            # Apply inverse transform if scaler provided\r\n+            if scaler is not None:\r\n+                try:\r\n+                    input_seq = self._apply_scaler(input_seq, scaler)\r\n+                    actual_seq = self._apply_scaler(actual_seq, scaler)\r\n+                    predicted_seq = self._apply_scaler(predicted_seq, scaler)\r\n+                except Exception as e:\r\n+                    print(f\"Warning: Inverse transform failed: {str(e)}\")\r\n+            \r\n+            # Create x-axis values\r\n+            input_len = len(input_seq)\r\n+            prediction_len = len(predicted_seq)\r\n+            total_len = input_len + prediction_len\r\n+            \r\n+            x_values = (self._generate_timestamps(start_time, total_len) \r\n+                       if start_time is not None \r\n+                       else np.arange(total_len))\r\n+            \r\n+            # Create figure and plot\r\n+            fig, ax = plt.subplots(figsize=self.fig_size)\r\n+            \r\n+            # Plot sequences\r\n+            ax.plot(x_values[:input_len], input_seq[:, 0], 'b-', \r\n+                   label='Input', alpha=0.5)\r\n+            ax.plot(x_values[input_len:], actual_seq[:, 0], 'g-', \r\n+                   label='Actual', linewidth=2)\r\n+            ax.plot(x_values[input_len:], predicted_seq[:, 0], 'r--', \r\n+                   label='Predicted', linewidth=2)\r\n+            \r\n+            # Add vertical separator line\r\n+            separator_x = (self._convert_time_to_num(x_values[input_len-1]) \r\n+                         if isinstance(x_values[0], datetime) \r\n+                         else float(x_values[input_len-1]))\r\n+            ax.axvline(x=separator_x, color='gray', linestyle='--', alpha=0.5)\r\n+            \r\n+            # Customize plot\r\n+            ax.set_title('Input Sequence and Predictions', pad=20)\r\n+            ax.set_xlabel('Time' if start_time is None else 'Timestamp')\r\n+            ax.set_ylabel('Value')\r\n+            ax.legend()\r\n+            ax.grid(True, alpha=0.3)\r\n+            \r\n+            if isinstance(x_values[0], datetime):\r\n+                plt.xticks(rotation=45)\r\n+            \r\n+            plt.tight_layout()\r\n+            \r\n+            # Save plot\r\n+            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n+            fig.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n+            plt.close(fig)\r\n+            \r\n+            print(f\"Saved prediction plot to {filename}\")\r\n+        \r\n+        except Exception as e:\r\n+            print(f\"Error creating prediction plot: {str(e)}\")\r\n+            plt.close('all')\r\n+\r\n+    def _ensure_numpy(self, data: Union[torch.Tensor, np.ndarray]) -> np.ndarray:\r\n+        \"\"\"Safely convert input to numpy array\"\"\"\r\n+        if isinstance(data, torch.Tensor):\r\n+            return data.cpu().detach().numpy()\r\n+        return np.asarray(data)\r\n+\r\n+    def _apply_scaler(self, data: np.ndarray, scaler: Any) -> np.ndarray:\r\n+        \"\"\"Apply inverse transform using scaler\"\"\"\r\n+        reshaped = data.reshape(-1, 1)\r\n+        transformed = scaler.inverse_transform(reshaped)\r\n+        return transformed.reshape(data.shape)\r\n+    \r\n+    \r\n+    \r\n+    \r\n+    \r\n+class TimeSeriesVisualizer:\r\n+    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n+    \r\n+    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n+        \"\"\"Initialize visualizer\"\"\"\r\n+        self.figsize = figsize\r\n+        sns.set_style(\"whitegrid\")\r\n+        plt.rcParams['figure.figsize'] = figsize\r\n+\r\n+    def _prepare_data_for_plotting(\r\n+        self, \r\n+        data: Union[torch.Tensor, np.ndarray]\r\n+    ) -> np.ndarray:\r\n+        # Convert to numpy if it's a tensor\r\n+        if isinstance(data, torch.Tensor):\r\n+            data = data.cpu().detach().numpy()\r\n+        else:\r\n+            data = np.asarray(data)\r\n+            \r\n+        # Handle different input shapes\r\n+        if len(data.shape) == 3:  # [batch, seq_len, features]\r\n+            # Take first feature and average across batches\r\n+            data = np.mean(data[:, :, 0], axis=0)\r\n+        elif len(data.shape) == 2:  # [seq_len, features]\r\n+            data = data[:, 0]\r\n+            \r\n+        # Ensure data is a NumPy array before calling astype\r\n+        data = np.asarray(data)\r\n+        return data.astype(np.float32)\r\n+\r\n+\r\n+    def plot_predictions(\r\n+        self,\r\n+        true_values: Union[torch.Tensor, np.ndarray],\r\n+        predictions: Union[torch.Tensor, np.ndarray],\r\n+        timestamps: Optional[List] = None,\r\n+        title: str = \"Predictions vs Actual\"\r\n+    ) -> Figure:\r\n+        \"\"\"Plot predictions against actual values\"\"\"\r\n+        # Prepare data for plotting\r\n+        true_values = self._prepare_data_for_plotting(true_values)\r\n+        predictions = self._prepare_data_for_plotting(predictions)\r\n+        \r\n+        # Create x-axis values\r\n+        x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n+        \r\n+        # Create figure\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        # Plot data\r\n+        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n+        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n+        \r\n+        # Customize plot\r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n+        ax.set_ylabel('Value')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        # Rotate x-axis labels if timestamps are provided\r\n+        if timestamps is not None:\r\n+            plt.xticks(rotation=45)\r\n+            \r\n+        plt.tight_layout()\r\n+        return fig\r\n+\r\n+    def plot_training_history(\r\n+        self,\r\n+        train_losses: List[float],\r\n+        val_losses: List[float],\r\n+        title: str = \"Training History\"\r\n+    ) -> Figure:\r\n+        \"\"\"Plot training and validation losses\"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        epochs = range(1, len(train_losses) + 1)\r\n+        \r\n+        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n+        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n+        \r\n+        ax.set_title(title)\r\n+        ax.set_xlabel('Epoch')\r\n+        ax.set_ylabel('Loss')\r\n+        ax.legend()\r\n+        ax.grid(True)\r\n+        \r\n+        plt.tight_layout()\r\n+        return fig\r\n+\r\n+    def plot_feature_importance(\r\n+        self,\r\n+        importance_scores: np.ndarray,\r\n+        feature_names: List[str]\r\n+    ) -> Figure:\r\n+        \"\"\"Plot feature importance scores\"\"\"\r\n+        fig, ax = plt.subplots(figsize=self.figsize)\r\n+        \r\n+        # Sort by importance\r\n+        sorted_idx = np.argsort(importance_scores)\r\n+        pos = np.arange(sorted_idx.shape[0]) + .5\r\n+        \r\n+        ax.barh(pos, importance_scores[sorted_idx])\r\n+        ax.set_yticks(pos)\r\n+        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n+        ax.set_xlabel('Importance Score')\r\n+        ax.set_title('Feature Importance')\r\n+        \r\n+        plt.tight_layout()\r\n+        return fig\r\n+\r\n+    def plot_batch_predictions(\r\n+        self,\r\n+        true_values: Union[torch.Tensor, np.ndarray],\r\n+        predictions: Union[torch.Tensor, np.ndarray],\r\n+        batch_idx: int = 0,\r\n+        n_samples: int = 5,\r\n+        title: str = \"Sample Predictions\"\r\n+    ) -> Figure:\r\n+        # Convert to numpy if needed\r\n+        if isinstance(true_values, torch.Tensor):\r\n+            true_values = true_values.cpu().detach().numpy()\r\n+        if isinstance(predictions, torch.Tensor):\r\n+            predictions = predictions.cpu().detach().numpy()\r\n+        \r\n+        # Create figure with subplots\r\n+        fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4 * n_samples))\r\n+        \r\n+        # Ensure axes is always a list of Axes objects\r\n+        if n_samples == 1:\r\n+            axes = [axes]\r\n+        else:\r\n+            axes = axes.flatten()\r\n+        \r\n+        # Plot each sample\r\n+        for i, ax in enumerate(axes[:n_samples]):\r\n+            true_seq = true_values[i, :, 0]\r\n+            pred_seq = predictions[i, :, 0]\r\n+            \r\n+            ax.plot(true_seq, 'b-', label='Actual', alpha=0.7)\r\n+            ax.plot(pred_seq, 'r--', label='Predicted', alpha=0.7)\r\n+            \r\n+            ax.set_title(f'Sample {i+1}')\r\n+            ax.set_xlabel('Time Step')\r\n+            ax.set_ylabel('Value')\r\n+            ax.legend()\r\n+            ax.grid(True)\r\n+        \r\n+        plt.suptitle(title)\r\n+        plt.tight_layout()\r\n+        return fig\r\n+\r\n+\r\n+    @staticmethod\r\n+    def save_figure(\r\n+        fig: Figure,\r\n+        filename: str,\r\n+        dpi: int = 300\r\n+    ) -> None:\r\n+        \"\"\"Save figure to file\"\"\"\r\n+        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n+        plt.close(fig)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733346554986,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -282,12 +282,15 @@\n         if isinstance(true_values, torch.Tensor):\r\n             true_values = true_values.cpu().detach().numpy()\r\n         if isinstance(predictions, torch.Tensor):\r\n             predictions = predictions.cpu().detach().numpy()\r\n+            \r\n         \r\n+        \r\n         # Create figure with subplots\r\n         fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4 * n_samples))\r\n         \r\n+        \r\n         # Ensure axes is always a list of Axes objects\r\n         if n_samples == 1:\r\n             axes = [axes]\r\n         else:\r\n@@ -319,335 +322,5 @@\n         dpi: int = 300\r\n     ) -> None:\r\n         \"\"\"Save figure to file\"\"\"\r\n         fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n-        plt.close(fig)\n-\"\"\"\r\n-Visualization utilities for time series forecasting.\r\n-\r\n-Dependencies:\r\n-- matplotlib>=3.7.2\r\n-- seaborn>=0.12.2\r\n-- numpy>=1.24.3\r\n-- torch>=2.0.1\r\n-\"\"\"\r\n-\r\n-import matplotlib.pyplot as plt\r\n-from matplotlib.figure import Figure\r\n-from matplotlib.dates import date2num, num2date\r\n-import seaborn as sns\r\n-import numpy as np\r\n-import numpy.typing as npt\r\n-import torch\r\n-from typing import List, Optional, Tuple, Union, Any\r\n-from datetime import datetime, timedelta\r\n-import os\r\n-import pandas as pd\r\n-\r\n-import matplotlib.pyplot as plt\r\n-from matplotlib.figure import Figure\r\n-from matplotlib.dates import date2num\r\n-import seaborn as sns\r\n-import numpy as np\r\n-import torch\r\n-from typing import List, Optional, Tuple, Union\r\n-from datetime import datetime, timedelta\r\n-import os\r\n-import pandas as pd\r\n-\r\n-class PredictionVisualizer:\r\n-    \"\"\"Handles visualization of model predictions with input windows\"\"\"\r\n-    \r\n-    def __init__(\r\n-            self,\r\n-            output_dir: str = \"prediction_plots\",\r\n-            fig_size: Tuple[int, int] = (15, 7),\r\n-            dpi: int = 300\r\n-    ):\r\n-        self.output_dir = output_dir\r\n-        self.fig_size = fig_size\r\n-        self.dpi = dpi\r\n-        os.makedirs(output_dir, exist_ok=True)\r\n-        plt.style.use('seaborn')\r\n-    \r\n-    def _convert_time_to_num(self, time_point: Union[datetime, int]) -> float:\r\n-        \"\"\"Helper to safely convert datetime or int to float for plotting\"\"\"\r\n-        if isinstance(time_point, datetime):\r\n-            return date2num(time_point)\r\n-        return float(time_point)\r\n-    \r\n-    def _generate_timestamps(\r\n-            self,\r\n-            start_time: datetime,\r\n-            sequence_length: int,\r\n-            freq: str = 'H'\r\n-    ) -> List[datetime]:\r\n-        \"\"\"Generate timestamps list\"\"\"\r\n-        timestamps = []\r\n-        current_time = start_time\r\n-        try:\r\n-            for _ in range(sequence_length):\r\n-                timestamps.append(current_time)\r\n-                current_time += timedelta(hours=1 if freq == 'H' else 0)\r\n-            return timestamps\r\n-        except Exception as e:\r\n-            print(f\"Error generating timestamps: {str(e)}\")\r\n-            return [start_time + timedelta(hours=i) for i in range(sequence_length)]\r\n-    \r\n-    def plot_prediction_sample(\r\n-            self,\r\n-            input_seq: Union[torch.Tensor, np.ndarray],\r\n-            actual_seq: Union[torch.Tensor, np.ndarray],\r\n-            predicted_seq: Union[torch.Tensor, np.ndarray],\r\n-            sample_id: int,\r\n-            start_time: Optional[datetime] = None,\r\n-            scaler: Any = None\r\n-    ) -> None:\r\n-        \"\"\"Create and save a plot showing input, actual and predicted values\"\"\"\r\n-        try:\r\n-            # Convert to numpy arrays safely\r\n-            input_seq = self._ensure_numpy(input_seq)\r\n-            actual_seq = self._ensure_numpy(actual_seq)\r\n-            predicted_seq = self._ensure_numpy(predicted_seq)\r\n-            \r\n-            # Apply inverse transform if scaler provided\r\n-            if scaler is not None:\r\n-                try:\r\n-                    input_seq = self._apply_scaler(input_seq, scaler)\r\n-                    actual_seq = self._apply_scaler(actual_seq, scaler)\r\n-                    predicted_seq = self._apply_scaler(predicted_seq, scaler)\r\n-                except Exception as e:\r\n-                    print(f\"Warning: Inverse transform failed: {str(e)}\")\r\n-            \r\n-            # Create x-axis values\r\n-            input_len = len(input_seq)\r\n-            prediction_len = len(predicted_seq)\r\n-            total_len = input_len + prediction_len\r\n-            \r\n-            x_values = (self._generate_timestamps(start_time, total_len) \r\n-                       if start_time is not None \r\n-                       else np.arange(total_len))\r\n-            \r\n-            # Create figure and plot\r\n-            fig, ax = plt.subplots(figsize=self.fig_size)\r\n-            \r\n-            # Plot sequences\r\n-            ax.plot(x_values[:input_len], input_seq[:, 0], 'b-', \r\n-                   label='Input', alpha=0.5)\r\n-            ax.plot(x_values[input_len:], actual_seq[:, 0], 'g-', \r\n-                   label='Actual', linewidth=2)\r\n-            ax.plot(x_values[input_len:], predicted_seq[:, 0], 'r--', \r\n-                   label='Predicted', linewidth=2)\r\n-            \r\n-            # Add vertical separator line\r\n-            separator_x = (self._convert_time_to_num(x_values[input_len-1]) \r\n-                         if isinstance(x_values[0], datetime) \r\n-                         else float(x_values[input_len-1]))\r\n-            ax.axvline(x=separator_x, color='gray', linestyle='--', alpha=0.5)\r\n-            \r\n-            # Customize plot\r\n-            ax.set_title('Input Sequence and Predictions', pad=20)\r\n-            ax.set_xlabel('Time' if start_time is None else 'Timestamp')\r\n-            ax.set_ylabel('Value')\r\n-            ax.legend()\r\n-            ax.grid(True, alpha=0.3)\r\n-            \r\n-            if isinstance(x_values[0], datetime):\r\n-                plt.xticks(rotation=45)\r\n-            \r\n-            plt.tight_layout()\r\n-            \r\n-            # Save plot\r\n-            filename = os.path.join(self.output_dir, f'prediction_sample_{sample_id}.png')\r\n-            fig.savefig(filename, dpi=self.dpi, bbox_inches='tight')\r\n-            plt.close(fig)\r\n-            \r\n-            print(f\"Saved prediction plot to {filename}\")\r\n-        \r\n-        except Exception as e:\r\n-            print(f\"Error creating prediction plot: {str(e)}\")\r\n-            plt.close('all')\r\n-\r\n-    def _ensure_numpy(self, data: Union[torch.Tensor, np.ndarray]) -> np.ndarray:\r\n-        \"\"\"Safely convert input to numpy array\"\"\"\r\n-        if isinstance(data, torch.Tensor):\r\n-            return data.cpu().detach().numpy()\r\n-        return np.asarray(data)\r\n-\r\n-    def _apply_scaler(self, data: np.ndarray, scaler: Any) -> np.ndarray:\r\n-        \"\"\"Apply inverse transform using scaler\"\"\"\r\n-        reshaped = data.reshape(-1, 1)\r\n-        transformed = scaler.inverse_transform(reshaped)\r\n-        return transformed.reshape(data.shape)\r\n-    \r\n-    \r\n-    \r\n-    \r\n-    \r\n-class TimeSeriesVisualizer:\r\n-    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n-    \r\n-    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n-        \"\"\"Initialize visualizer\"\"\"\r\n-        self.figsize = figsize\r\n-        sns.set_style(\"whitegrid\")\r\n-        plt.rcParams['figure.figsize'] = figsize\r\n-\r\n-    def _prepare_data_for_plotting(\r\n-        self, \r\n-        data: Union[torch.Tensor, np.ndarray]\r\n-    ) -> np.ndarray:\r\n-        # Convert to numpy if it's a tensor\r\n-        if isinstance(data, torch.Tensor):\r\n-            data = data.cpu().detach().numpy()\r\n-        else:\r\n-            data = np.asarray(data)\r\n-            \r\n-        # Handle different input shapes\r\n-        if len(data.shape) == 3:  # [batch, seq_len, features]\r\n-            # Take first feature and average across batches\r\n-            data = np.mean(data[:, :, 0], axis=0)\r\n-        elif len(data.shape) == 2:  # [seq_len, features]\r\n-            data = data[:, 0]\r\n-            \r\n-        # Ensure data is a NumPy array before calling astype\r\n-        data = np.asarray(data)\r\n-        return data.astype(np.float32)\r\n-\r\n-\r\n-    def plot_predictions(\r\n-        self,\r\n-        true_values: Union[torch.Tensor, np.ndarray],\r\n-        predictions: Union[torch.Tensor, np.ndarray],\r\n-        timestamps: Optional[List] = None,\r\n-        title: str = \"Predictions vs Actual\"\r\n-    ) -> Figure:\r\n-        \"\"\"Plot predictions against actual values\"\"\"\r\n-        # Prepare data for plotting\r\n-        true_values = self._prepare_data_for_plotting(true_values)\r\n-        predictions = self._prepare_data_for_plotting(predictions)\r\n-        \r\n-        # Create x-axis values\r\n-        x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n-        \r\n-        # Create figure\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        # Plot data\r\n-        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n-        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n-        \r\n-        # Customize plot\r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n-        ax.set_ylabel('Value')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        # Rotate x-axis labels if timestamps are provided\r\n-        if timestamps is not None:\r\n-            plt.xticks(rotation=45)\r\n-            \r\n-        plt.tight_layout()\r\n-        return fig\r\n-\r\n-    def plot_training_history(\r\n-        self,\r\n-        train_losses: List[float],\r\n-        val_losses: List[float],\r\n-        title: str = \"Training History\"\r\n-    ) -> Figure:\r\n-        \"\"\"Plot training and validation losses\"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        epochs = range(1, len(train_losses) + 1)\r\n-        \r\n-        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n-        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n-        \r\n-        ax.set_title(title)\r\n-        ax.set_xlabel('Epoch')\r\n-        ax.set_ylabel('Loss')\r\n-        ax.legend()\r\n-        ax.grid(True)\r\n-        \r\n-        plt.tight_layout()\r\n-        return fig\r\n-\r\n-    def plot_feature_importance(\r\n-        self,\r\n-        importance_scores: np.ndarray,\r\n-        feature_names: List[str]\r\n-    ) -> Figure:\r\n-        \"\"\"Plot feature importance scores\"\"\"\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        # Sort by importance\r\n-        sorted_idx = np.argsort(importance_scores)\r\n-        pos = np.arange(sorted_idx.shape[0]) + .5\r\n-        \r\n-        ax.barh(pos, importance_scores[sorted_idx])\r\n-        ax.set_yticks(pos)\r\n-        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n-        ax.set_xlabel('Importance Score')\r\n-        ax.set_title('Feature Importance')\r\n-        \r\n-        plt.tight_layout()\r\n-        return fig\r\n-\r\n-    def plot_batch_predictions(\r\n-        self,\r\n-        true_values: Union[torch.Tensor, np.ndarray],\r\n-        predictions: Union[torch.Tensor, np.ndarray],\r\n-        batch_idx: int = 0,\r\n-        n_samples: int = 5,\r\n-        title: str = \"Sample Predictions\"\r\n-    ) -> Figure:\r\n-        \"\"\"\r\n-        Plot individual predictions from a batch\r\n-        \r\n-        Args:\r\n-            true_values: Tensor of shape [batch, seq_len, features]\r\n-            predictions: Tensor of shape [batch, seq_len, features]\r\n-            batch_idx: Which batch to plot from\r\n-            n_samples: Number of samples to plot\r\n-            title: Plot title\r\n-        \"\"\"\r\n-        # Convert to numpy if needed\r\n-        if isinstance(true_values, torch.Tensor):\r\n-            true_values = true_values.cpu().detach().numpy()\r\n-        if isinstance(predictions, torch.Tensor):\r\n-            predictions = predictions.cpu().detach().numpy()\r\n-        \r\n-        # Create figure with subplots\r\n-        n_samples = min(n_samples, true_values.shape[0])\r\n-        fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4*n_samples))\r\n-        if n_samples == 1:\r\n-            axes = [axes]\r\n-        \r\n-        # Plot each sample\r\n-        for i, ax in enumerate(axes):\r\n-            if i < n_samples:\r\n-                true_seq = true_values[i, :, 0]\r\n-                pred_seq = predictions[i, :, 0]\r\n-                \r\n-                ax.plot(true_seq, 'b-', label='Actual', alpha=0.7)\r\n-                ax.plot(pred_seq, 'r--', label='Predicted', alpha=0.7)\r\n-                \r\n-                ax.set_title(f'Sample {i+1}')\r\n-                ax.set_xlabel('Time Step')\r\n-                ax.set_ylabel('Value')\r\n-                ax.legend()\r\n-                ax.grid(True)\r\n-        \r\n-        plt.suptitle(title)\r\n-        plt.tight_layout()\r\n-        return fig\r\n-\r\n-    @staticmethod\r\n-    def save_figure(\r\n-        fig: Figure,\r\n-        filename: str,\r\n-        dpi: int = 300\r\n-    ) -> None:\r\n-        \"\"\"Save figure to file\"\"\"\r\n-        fig.savefig(filename, dpi=dpi, bbox_inches='tight')\r\n         plt.close(fig)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733347030813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -194,34 +194,64 @@\n     def plot_predictions(\r\n         self,\r\n         true_values: Union[torch.Tensor, np.ndarray],\r\n         predictions: Union[torch.Tensor, np.ndarray],\r\n+        input_values: Optional[Union[torch.Tensor, np.ndarray]] = None,  # Add input_values parameter\r\n         timestamps: Optional[List] = None,\r\n         title: str = \"Predictions vs Actual\"\r\n     ) -> Figure:\r\n-        \"\"\"Plot predictions against actual values\"\"\"\r\n+        \"\"\"\r\n+        Plot predictions against actual values with input context\r\n+        \r\n+        Args:\r\n+            true_values: Actual future values\r\n+            predictions: Predicted future values\r\n+            input_values: Historical input values used for prediction\r\n+            timestamps: Optional time labels\r\n+            title: Plot title\r\n+        \"\"\"\r\n         # Prepare data for plotting\r\n         true_values = self._prepare_data_for_plotting(true_values)\r\n         predictions = self._prepare_data_for_plotting(predictions)\r\n         \r\n-        # Create x-axis values\r\n-        x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n+        if input_values is not None:\r\n+            input_values = self._prepare_data_for_plotting(input_values)\r\n+            \r\n+            # Create full x-axis range\r\n+            total_len = len(input_values) + len(true_values)\r\n+            x_values = (timestamps if timestamps is not None \r\n+                       else np.arange(total_len))\r\n+            \r\n+            # Create figure\r\n+            fig, ax = plt.subplots(figsize=self.figsize)\r\n+            \r\n+            # Plot input sequence\r\n+            ax.plot(x_values[:len(input_values)], input_values, \r\n+                   'g-', label='Historical Input', alpha=0.5)\r\n+            \r\n+            # Plot predictions and actual values\r\n+            ax.plot(x_values[len(input_values):], true_values, \r\n+                   'b-', label='Actual', alpha=0.7)\r\n+            ax.plot(x_values[len(input_values):], predictions, \r\n+                   'r--', label='Predicted', alpha=0.7)\r\n+            \r\n+            # Add vertical line to separate input from predictions\r\n+            ax.axvline(x=x_values[len(input_values)-1], \r\n+                      color='gray', linestyle='--', alpha=0.5)\r\n+        else:\r\n+            # Original plotting code without input sequence\r\n+            x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n+            fig, ax = plt.subplots(figsize=self.figsize)\r\n+            ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n+            ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n         \r\n-        # Create figure\r\n-        fig, ax = plt.subplots(figsize=self.figsize)\r\n-        \r\n-        # Plot data\r\n-        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n-        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n-        \r\n         # Customize plot\r\n         ax.set_title(title)\r\n         ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n         ax.set_ylabel('Value')\r\n         ax.legend()\r\n         ax.grid(True)\r\n         \r\n-        # Rotate x-axis labels if timestamps are provided\r\n         if timestamps is not None:\r\n             plt.xticks(rotation=45)\r\n             \r\n         plt.tight_layout()\r\n"
                },
                {
                    "date": 1733347661060,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,9 +196,10 @@\n         true_values: Union[torch.Tensor, np.ndarray],\r\n         predictions: Union[torch.Tensor, np.ndarray],\r\n         input_values: Optional[Union[torch.Tensor, np.ndarray]] = None,  # Add input_values parameter\r\n         timestamps: Optional[List] = None,\r\n-        title: str = \"Predictions vs Actual\"\r\n+        title: str = \"Predictions vs Actual\",\r\n+        show_confidence: bool = True\r\n     ) -> Figure:\r\n         \"\"\"\r\n         Plot predictions against actual values with input context\r\n         \r\n@@ -207,22 +208,28 @@\n             predictions: Predicted future values\r\n             input_values: Historical input values used for prediction\r\n             timestamps: Optional time labels\r\n             title: Plot title\r\n+            show_confidence: Whether to show confidence intervals\r\n         \"\"\"\r\n         # Prepare data for plotting\r\n         true_values = self._prepare_data_for_plotting(true_values)\r\n         predictions = self._prepare_data_for_plotting(predictions)\r\n         \r\n         if input_values is not None:\r\n             input_values = self._prepare_data_for_plotting(input_values)\r\n             \r\n+            # Calculate error metrics for this sample\r\n+            mse = np.mean((true_values - predictions) ** 2)\r\n+            mae = np.mean(np.abs(true_values - predictions))\r\n+            \r\n+            # Update title with error metrics\r\n+            title = f\"{title}\\nMSE: {mse:.4f}, MAE: {mae:.4f}\"\r\n+            \r\n             # Create full x-axis range\r\n             total_len = len(input_values) + len(true_values)\r\n-            x_values = (timestamps if timestamps is not None \r\n-                       else np.arange(total_len))\r\n+            x_values = timestamps if timestamps is not None else np.arange(total_len)\r\n             \r\n-            # Create figure\r\n             fig, ax = plt.subplots(figsize=self.figsize)\r\n             \r\n             # Plot input sequence\r\n             ax.plot(x_values[:len(input_values)], input_values, \r\n@@ -236,8 +243,18 @@\n             \r\n             # Add vertical line to separate input from predictions\r\n             ax.axvline(x=x_values[len(input_values)-1], \r\n                       color='gray', linestyle='--', alpha=0.5)\r\n+            \r\n+            # Add shaded region for prediction uncertainty\r\n+            if show_confidence:\r\n+                std_dev = np.std(true_values - predictions)\r\n+                upper = predictions + 2 * std_dev\r\n+                lower = predictions - 2 * std_dev\r\n+                ax.fill_between(x_values[len(input_values):], \r\n+                              lower, upper, \r\n+                              color='r', alpha=0.1, \r\n+                              label='95% Confidence')\r\n         else:\r\n             # Original plotting code without input sequence\r\n             x_values = timestamps if timestamps is not None else np.arange(len(true_values))\r\n             fig, ax = plt.subplots(figsize=self.figsize)\r\n"
                }
            ],
            "date": 1733311728768,
            "name": "Commit-0",
            "content": "\"\"\"\r\nVisualization utilities for time series forecasting.\r\n\r\nDependencies:\r\n- matplotlib>=3.7.2\r\n- seaborn>=0.12.2\r\n\"\"\"\r\n\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport numpy as np\r\nfrom typing import List, Optional, Tuple\r\nimport torch\r\n\r\nclass TimeSeriesVisualizer:\r\n    \"\"\"Visualization tools for time series data and model results\"\"\"\r\n    \r\n    def __init__(self, figsize: Tuple[int, int] = (12, 6)):\r\n        \"\"\"\r\n        Initialize visualizer\r\n        \r\n        Args:\r\n            figsize: Default figure size for plots\r\n        \"\"\"\r\n        self.figsize = figsize\r\n        # Set style\r\n        sns.set_style(\"whitegrid\")\r\n        plt.rcParams['figure.figsize'] = figsize\r\n        \r\n    def plot_training_history(\r\n        self,\r\n        train_losses: List[float],\r\n        val_losses: List[float],\r\n        title: str = \"Training History\"\r\n    ) -> plt.Figure:\r\n        \"\"\"\r\n        Plot training and validation losses\r\n        \r\n        Args:\r\n            train_losses: List of training losses\r\n            val_losses: List of validation losses\r\n            title: Plot title\r\n            \r\n        Returns:\r\n            matplotlib figure\r\n        \"\"\"\r\n        fig, ax = plt.subplots(figsize=self.figsize)\r\n        epochs = range(1, len(train_losses) + 1)\r\n        \r\n        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\r\n        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\r\n        \r\n        ax.set_title(title)\r\n        ax.set_xlabel('Epoch')\r\n        ax.set_ylabel('Loss')\r\n        ax.legend()\r\n        ax.grid(True)\r\n        \r\n        return fig\r\n    \r\n    def plot_predictions(\r\n        self,\r\n        true_values: torch.Tensor,\r\n        predictions: torch.Tensor,\r\n        timestamps: Optional[List] = None,\r\n        title: str = \"Predictions vs Actual\"\r\n    ) -> plt.Figure:\r\n        \"\"\"\r\n        Plot predictions against actual values\r\n        \r\n        Args:\r\n            true_values: Ground truth values\r\n            predictions: Model predictions\r\n            timestamps: Optional list of timestamps\r\n            title: Plot title\r\n            \r\n        Returns:\r\n            matplotlib figure\r\n        \"\"\"\r\n        # Convert to numpy if tensors\r\n        if isinstance(true_values, torch.Tensor):\r\n            true_values = true_values.cpu().numpy()\r\n        if isinstance(predictions, torch.Tensor):\r\n            predictions = predictions.cpu().numpy()\r\n            \r\n        fig, ax = plt.subplots(figsize=self.figsize)\r\n        \r\n        x_values = timestamps if timestamps is not None else range(len(true_values))\r\n        \r\n        ax.plot(x_values, true_values, 'b-', label='Actual', alpha=0.7)\r\n        ax.plot(x_values, predictions, 'r--', label='Predicted', alpha=0.7)\r\n        \r\n        ax.set_title(title)\r\n        ax.set_xlabel('Time' if timestamps is None else 'Timestamp')\r\n        ax.set_ylabel('Value')\r\n        ax.legend()\r\n        ax.grid(True)\r\n        \r\n        # Rotate x-axis labels if timestamps are provided\r\n        if timestamps is not None:\r\n            plt.xticks(rotation=45)\r\n            \r\n        plt.tight_layout()\r\n        return fig\r\n    \r\n    def plot_attention_weights(\r\n        self,\r\n        attention_weights: torch.Tensor,\r\n        index: int = 0\r\n    ) -> plt.Figure:\r\n        \"\"\"\r\n        Plot attention weights heatmap\r\n        \r\n        Args:\r\n            attention_weights: Attention weights tensor [batch, heads, seq_len, seq_len]\r\n            index: Batch index to plot\r\n            \r\n        Returns:\r\n            matplotlib figure\r\n        \"\"\"\r\n        # Get weights for specified batch\r\n        weights = attention_weights[index].cpu().numpy()\r\n        \r\n        # Create subplot for each attention head\r\n        n_heads = weights.shape[0]\r\n        fig, axes = plt.subplots(\r\n            1, n_heads,\r\n            figsize=(4 * n_heads, 4),\r\n            squeeze=False\r\n        )\r\n        \r\n        for i, ax in enumerate(axes[0]):\r\n            sns.heatmap(\r\n                weights[i],\r\n                ax=ax,\r\n                cmap='viridis',\r\n                cbar=True\r\n            )\r\n            ax.set_title(f'Head {i+1}')\r\n            ax.set_xlabel('Key')\r\n            ax.set_ylabel('Query')\r\n            \r\n        plt.tight_layout()\r\n        return fig\r\n    \r\n    def plot_feature_importance(\r\n        self,\r\n        importance_scores: np.ndarray,\r\n        feature_names: List[str]\r\n    ) -> plt.Figure:\r\n        \"\"\"\r\n        Plot feature importance scores\r\n        \r\n        Args:\r\n            importance_scores: Array of importance scores\r\n            feature_names: List of feature names\r\n            \r\n        Returns:\r\n            matplotlib figure\r\n        \"\"\"\r\n        fig, ax = plt.subplots(figsize=self.figsize)\r\n        \r\n        # Sort by importance\r\n        sorted_idx = np.argsort(importance_scores)\r\n        pos = np.arange(sorted_idx.shape[0]) + .5\r\n        \r\n        ax.barh(pos, importance_scores[sorted_idx])\r\n        ax.set_yticks(pos)\r\n        ax.set_yticklabels(np.array(feature_names)[sorted_idx])\r\n        ax.set_xlabel('Importance Score')\r\n        ax.set_title('Feature Importance')\r\n        \r\n        plt.tight_layout()\r\n        return fig\r\n    \r\n    @staticmethod\r\n    def save_figure(\r\n        fig: plt.Figure,\r\n        filename: str,\r\n        dpi: int = 300\r\n    ):\r\n        \"\"\"\r\n        Save figure to file\r\n        \r\n        Args:\r\n            fig: matplotlib figure\r\n            filename: Output filename\r\n            dpi: Resolution in dots per inch\r\n        \"\"\"\r\n        fig.savefig(filename, dpi=dpi, bbox_inches='tight')"
        }
    ]
}