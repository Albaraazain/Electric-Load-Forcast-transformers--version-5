{
    "sourceFile": "src/model/informer.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1733312338094,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733314690624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -190,17 +190,18 @@\n             Tuple of (output, attention_weights)\r\n         \"\"\"\r\n         # Encoding\r\n         enc_out = self.enc_embedding(x)\r\n-\r\n+        \r\n         # Encoder\r\n         enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n-\r\n+        \r\n         # Output projection\r\n         output = self.projection(enc_out)\r\n-        # Ensure the output and target dimensions match\r\n-        output = output[:, :x.size(1), :]\r\n-\r\n+        \r\n+        # Remove this line\r\n+        # output = output[:, :x.size(1), :]\r\n+        \r\n         return output, attns\r\n \r\n     def _init_weights(self):\r\n         \"\"\"Initialize model weights\"\"\"\r\n"
                },
                {
                    "date": 1733314829922,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -173,34 +173,33 @@\n \r\n         # Output projection\r\n         self.projection = nn.Linear(d_model, output_dim, bias=True)\r\n \r\n-    def forward(\r\n-            self,\r\n-            x: torch.Tensor,\r\n-            enc_self_mask: Optional[torch.Tensor] = None\r\n-    ) -> Tuple[torch.Tensor, list]:\r\n+    def forward(self, x: torch.Tensor, enc_self_mask: Optional[torch.Tensor] = None):\r\n         \"\"\"\r\n         Forward pass\r\n-\r\n         Args:\r\n             x: Input tensor of shape [batch_size, seq_length, input_dim]\r\n             enc_self_mask: Optional mask for encoder self-attention\r\n-\r\n-        Returns:\r\n-            Tuple of (output, attention_weights)\r\n         \"\"\"\r\n+        # Add debug prints\r\n+        print(f\"Forward pass input shape: {x.shape}\")\r\n+        \r\n         # Encoding\r\n         enc_out = self.enc_embedding(x)\r\n+        print(f\"Embedded shape: {enc_out.shape}\")\r\n         \r\n         # Encoder\r\n         enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n+        print(f\"Encoder output shape: {enc_out.shape}\")\r\n         \r\n         # Output projection\r\n         output = self.projection(enc_out)\r\n+        print(f\"Projection output shape: {output.shape}\")\r\n         \r\n-        # Remove this line\r\n-        # output = output[:, :x.size(1), :]\r\n+        # Ensure output matches target length (prediction_window - 1)\r\n+        output = output[:, :self.prediction_window-1, :]\r\n+        print(f\"Final output shape: {output.shape}\")\r\n         \r\n         return output, attns\r\n \r\n     def _init_weights(self):\r\n"
                },
                {
                    "date": 1733315174473,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,8 +121,9 @@\n             d_ff: int = 512,\r\n             dropout: float = 0.0,\r\n             activation: str = 'gelu',\r\n             distil: bool = True,\r\n+            prediction_window: int = 48,  \r\n     ):\r\n         \"\"\"\r\n         Initialize Informer model\r\n \r\n@@ -140,8 +141,9 @@\n         super(Informer, self).__init__()\r\n \r\n         self.input_dim = input_dim\r\n         self.output_dim = output_dim\r\n+        self.prediction_window = prediction_window\r\n \r\n         # Encoding\r\n         self.enc_embedding = nn.Linear(input_dim, d_model)\r\n \r\n"
                },
                {
                    "date": 1733315280649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -176,32 +176,19 @@\n         # Output projection\r\n         self.projection = nn.Linear(d_model, output_dim, bias=True)\r\n \r\n     def forward(self, x: torch.Tensor, enc_self_mask: Optional[torch.Tensor] = None):\r\n-        \"\"\"\r\n-        Forward pass\r\n-        Args:\r\n-            x: Input tensor of shape [batch_size, seq_length, input_dim]\r\n-            enc_self_mask: Optional mask for encoder self-attention\r\n-        \"\"\"\r\n-        # Add debug prints\r\n-        print(f\"Forward pass input shape: {x.shape}\")\r\n-        \r\n         # Encoding\r\n         enc_out = self.enc_embedding(x)\r\n-        print(f\"Embedded shape: {enc_out.shape}\")\r\n         \r\n         # Encoder\r\n         enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n-        print(f\"Encoder output shape: {enc_out.shape}\")\r\n         \r\n         # Output projection\r\n         output = self.projection(enc_out)\r\n-        print(f\"Projection output shape: {output.shape}\")\r\n         \r\n-        # Ensure output matches target length (prediction_window - 1)\r\n+        # Now this will work correctly\r\n         output = output[:, :self.prediction_window-1, :]\r\n-        print(f\"Final output shape: {output.shape}\")\r\n         \r\n         return output, attns\r\n \r\n     def _init_weights(self):\r\n"
                },
                {
                    "date": 1733315411430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -185,10 +185,10 @@\n         \r\n         # Output projection\r\n         output = self.projection(enc_out)\r\n         \r\n-        # Now this will work correctly\r\n-        output = output[:, :self.prediction_window-1, :]\r\n+        # Ensure output matches target length (prediction_window - 2)\r\n+        output = output[:, :self.prediction_window-2, :]\r\n         \r\n         return output, attns\r\n \r\n     def _init_weights(self):\r\n"
                },
                {
                    "date": 1733318641015,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -185,10 +185,10 @@\n         \r\n         # Output projection\r\n         output = self.projection(enc_out)\r\n         \r\n-        # Ensure output matches target length (prediction_window - 2)\r\n-        output = output[:, :self.prediction_window-2, :]\r\n+        # Ensure output matches target length (prediction_window - 1)\r\n+        output = output[:, :self.prediction_window-1, :]\r\n         \r\n         return output, attns\r\n \r\n     def _init_weights(self):\r\n"
                },
                {
                    "date": 1733337870677,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,209 @@\n+\"\"\"\r\n+Informer model implementation for time series forecasting.\r\n+\r\n+Dependencies:\r\n+- torch>=2.0.1\r\n+\"\"\"\r\n+\r\n+import torch\r\n+import torch.nn as nn\r\n+from typing import Optional, Tuple\r\n+\r\n+from .layers import ProbAttention, AttentionLayer\r\n+\r\n+class ConvLayer(nn.Module):\r\n+    \"\"\"Convolutional Layer for downsampling\"\"\"\r\n+\r\n+    def __init__(self, c_in: int):\r\n+        super(ConvLayer, self).__init__()\r\n+        self.downConv = nn.Conv1d(in_channels=c_in,\r\n+                                  out_channels=c_in,\r\n+                                  kernel_size=3,\r\n+                                  padding=1,\r\n+                                  padding_mode='circular')\r\n+        self.norm = nn.BatchNorm1d(c_in)\r\n+        self.activation = nn.ELU()\r\n+        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\r\n+\r\n+    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n+        x = self.downConv(x.permute(0, 2, 1))\r\n+        x = self.norm(x)\r\n+        x = self.activation(x)\r\n+        x = self.maxPool(x)\r\n+        x = x.transpose(1, 2)\r\n+        return x\r\n+\r\n+class EncoderLayer(nn.Module):\r\n+    \"\"\"Encoder layer with self-attention mechanism\"\"\"\r\n+\r\n+    def __init__(\r\n+            self,\r\n+            attention: nn.Module,\r\n+            d_model: int,\r\n+            d_ff: Optional[int] = None,\r\n+            dropout: float = 0.1,\r\n+            activation: str = \"relu\"\r\n+    ):\r\n+        super(EncoderLayer, self).__init__()\r\n+        d_ff = d_ff or 4 * d_model\r\n+        self.attention = attention\r\n+        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\r\n+        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\r\n+        self.norm1 = nn.LayerNorm(d_model)\r\n+        self.norm2 = nn.LayerNorm(d_model)\r\n+        self.dropout = nn.Dropout(dropout)\r\n+        self.activation = nn.ReLU() if activation == \"relu\" else nn.GELU()\r\n+\r\n+    def forward(\r\n+            self,\r\n+            x: torch.Tensor,\r\n+            attn_mask: Optional[torch.Tensor] = None\r\n+    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\r\n+        new_x, attn = self.attention(\r\n+            x, x, x,\r\n+            attn_mask=attn_mask\r\n+        )\r\n+        x = x + self.dropout(new_x)\r\n+        y = x = self.norm1(x)\r\n+        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\r\n+        y = self.dropout(self.conv2(y).transpose(-1,1))\r\n+        return self.norm2(x+y), attn\r\n+\r\n+class Encoder(nn.Module):\r\n+    \"\"\"Informer encoder\"\"\"\r\n+\r\n+    def __init__(\r\n+            self,\r\n+            attn_layers: nn.ModuleList,\r\n+            conv_layers: Optional[nn.ModuleList] = None,\r\n+            norm_layer: Optional[nn.Module] = None\r\n+    ):\r\n+        super(Encoder, self).__init__()\r\n+        self.attn_layers = attn_layers\r\n+        self.conv_layers = conv_layers if conv_layers is not None else None\r\n+        self.norm = norm_layer\r\n+\r\n+    def forward(\r\n+            self,\r\n+            x: torch.Tensor,\r\n+            attn_mask: Optional[torch.Tensor] = None\r\n+    ) -> Tuple[torch.Tensor, list]:\r\n+        attns = []\r\n+        if self.conv_layers is not None:\r\n+            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\r\n+                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n+                x = conv_layer(x)\r\n+                attns.append(attn)\r\n+            x, attn = self.attn_layers[-1](x)\r\n+            attns.append(attn)\r\n+        else:\r\n+            for attn_layer in self.attn_layers:\r\n+                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n+                attns.append(attn)\r\n+\r\n+        if self.norm is not None:\r\n+            x = self.norm(x)\r\n+\r\n+        return x, attns\r\n+\r\n+class Informer(nn.Module):\r\n+    \"\"\"\r\n+    Informer model for time series forecasting\r\n+    \"\"\"\r\n+\r\n+    def __init__(\r\n+            self,\r\n+            input_dim: int,\r\n+            output_dim: int,\r\n+            d_model: int = 512,\r\n+            n_heads: int = 8,\r\n+            e_layers: int = 3,\r\n+            d_ff: int = 512,\r\n+            dropout: float = 0.0,\r\n+            activation: str = 'gelu',\r\n+            distil: bool = True,\r\n+            prediction_window: int = 48,  \r\n+    ):\r\n+        \"\"\"\r\n+        Initialize Informer model\r\n+\r\n+        Args:\r\n+            input_dim: Number of input features\r\n+            output_dim: Number of output features\r\n+            d_model: Model dimension\r\n+            n_heads: Number of attention heads\r\n+            e_layers: Number of encoder layers\r\n+            d_ff: Dimension of feedforward network\r\n+            dropout: Dropout rate\r\n+            activation: Activation function type\r\n+            distil: Whether to use distilling in encoder\r\n+        \"\"\"\r\n+        super(Informer, self).__init__()\r\n+\r\n+        self.input_dim = input_dim\r\n+        self.output_dim = output_dim\r\n+        self.prediction_window = prediction_window\r\n+\r\n+        # Encoding\r\n+        self.enc_embedding = nn.Linear(input_dim, d_model)\r\n+\r\n+        # Encoder\r\n+        encoder_layers = []\r\n+        conv_layers = []\r\n+\r\n+        for i in range(e_layers):\r\n+            encoder_layers.append(\r\n+                EncoderLayer(\r\n+                    AttentionLayer(\r\n+                        ProbAttention(False, attention_dropout=dropout),\r\n+                        d_model, n_heads\r\n+                    ),\r\n+                    d_model,\r\n+                    d_ff,\r\n+                    dropout=dropout,\r\n+                    activation=activation\r\n+                )\r\n+            )\r\n+            if i < e_layers-1 and distil:\r\n+                conv_layers.append(ConvLayer(d_model))\r\n+\r\n+        self.encoder = Encoder(\r\n+            nn.ModuleList(encoder_layers),\r\n+            nn.ModuleList(conv_layers) if distil else None,\r\n+            norm_layer=nn.LayerNorm(d_model)\r\n+        )\r\n+\r\n+        # Output projection\r\n+        self.projection = nn.Linear(d_model, output_dim, bias=True)\r\n+\r\n+    def forward(self, x: torch.Tensor, enc_self_mask: Optional[torch.Tensor] = None):\r\n+        print(f\"\\nModel Forward Debug:\")\r\n+        print(f\"Input shape: {x.shape}\")\r\n+        \r\n+        # Encoding\r\n+        enc_out = self.enc_embedding(x)\r\n+        print(f\"After embedding shape: {enc_out.shape}\")\r\n+        \r\n+        # Encoder\r\n+        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n+        print(f\"After encoder shape: {enc_out.shape}\")\r\n+        \r\n+        # Output projection\r\n+        output = self.projection(enc_out)\r\n+        print(f\"After projection shape: {output.shape}\")\r\n+        \r\n+        # Ensure output matches target length\r\n+        output = output[:, :self.prediction_window-1, :]\r\n+        print(f\"Final output shape: {output.shape}\")\r\n+        print(f\"Prediction window size: {self.prediction_window}\")\r\n+        print(\"=\" * 50)\r\n+        \r\n+        return output, attns\r\n+\r\n+    def _init_weights(self):\r\n+        \"\"\"Initialize model weights\"\"\"\r\n+        for p in self.parameters():\r\n+            if p.dim() > 1:\r\n+                nn.init.xavier_uniform_(p)\r\n+            else:\r\n+                nn.init.uniform_(p)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733339017612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,232 +178,51 @@\n \r\n     def forward(self, x: torch.Tensor, enc_self_mask: Optional[torch.Tensor] = None):\r\n         print(f\"\\nModel Forward Debug:\")\r\n         print(f\"Input shape: {x.shape}\")\r\n+\r\n+        # Process in smaller chunks if input is too large\r\n+        batch_size = x.size(0)\r\n+        chunk_size = 16  # Process 16 samples at a time\r\n+        outputs = []\r\n         \r\n-        # Encoding\r\n-        enc_out = self.enc_embedding(x)\r\n-        print(f\"After embedding shape: {enc_out.shape}\")\r\n+        for i in range(0, batch_size, chunk_size):\r\n+            chunk = x[i:i+chunk_size]\r\n+            \r\n+            # Encoding\r\n+            enc_out = self.enc_embedding(chunk)\r\n+            \r\n+            # Encoder\r\n+            enc_out, _ = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n+            \r\n+            # Output projection\r\n+            chunk_output = self.projection(enc_out)\r\n+            \r\n+            # Store chunk output\r\n+            outputs.append(chunk_output)\r\n+\r\n+            # Clean up memory\r\n+            del enc_out\r\n+            torch.cuda.empty_cache()\r\n+\r\n+        # Combine chunks\r\n+        output = torch.cat(outputs, dim=0)\r\n         \r\n-        # Encoder\r\n-        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n-        print(f\"After encoder shape: {enc_out.shape}\")\r\n-        \r\n-        # Output projection\r\n-        output = self.projection(enc_out)\r\n+        # Debug prints\r\n         print(f\"After projection shape: {output.shape}\")\r\n         \r\n         # Ensure output matches target length\r\n         output = output[:, :self.prediction_window-1, :]\r\n         print(f\"Final output shape: {output.shape}\")\r\n         print(f\"Prediction window size: {self.prediction_window}\")\r\n         print(\"=\" * 50)\r\n         \r\n-        return output, attns\r\n+        # Return empty list for attns to save memory\r\n+        return output, []\r\n \r\n     def _init_weights(self):\r\n         \"\"\"Initialize model weights\"\"\"\r\n         for p in self.parameters():\r\n             if p.dim() > 1:\r\n                 nn.init.xavier_uniform_(p)\r\n             else:\r\n-                nn.init.uniform_(p)\n-\"\"\"\r\n-Informer model implementation for time series forecasting.\r\n-\r\n-Dependencies:\r\n-- torch>=2.0.1\r\n-\"\"\"\r\n-\r\n-import torch\r\n-import torch.nn as nn\r\n-from typing import Optional, Tuple\r\n-\r\n-from .layers import ProbAttention, AttentionLayer\r\n-\r\n-class ConvLayer(nn.Module):\r\n-    \"\"\"Convolutional Layer for downsampling\"\"\"\r\n-\r\n-    def __init__(self, c_in: int):\r\n-        super(ConvLayer, self).__init__()\r\n-        self.downConv = nn.Conv1d(in_channels=c_in,\r\n-                                  out_channels=c_in,\r\n-                                  kernel_size=3,\r\n-                                  padding=1,\r\n-                                  padding_mode='circular')\r\n-        self.norm = nn.BatchNorm1d(c_in)\r\n-        self.activation = nn.ELU()\r\n-        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\r\n-\r\n-    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n-        x = self.downConv(x.permute(0, 2, 1))\r\n-        x = self.norm(x)\r\n-        x = self.activation(x)\r\n-        x = self.maxPool(x)\r\n-        x = x.transpose(1, 2)\r\n-        return x\r\n-\r\n-class EncoderLayer(nn.Module):\r\n-    \"\"\"Encoder layer with self-attention mechanism\"\"\"\r\n-\r\n-    def __init__(\r\n-            self,\r\n-            attention: nn.Module,\r\n-            d_model: int,\r\n-            d_ff: Optional[int] = None,\r\n-            dropout: float = 0.1,\r\n-            activation: str = \"relu\"\r\n-    ):\r\n-        super(EncoderLayer, self).__init__()\r\n-        d_ff = d_ff or 4 * d_model\r\n-        self.attention = attention\r\n-        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\r\n-        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\r\n-        self.norm1 = nn.LayerNorm(d_model)\r\n-        self.norm2 = nn.LayerNorm(d_model)\r\n-        self.dropout = nn.Dropout(dropout)\r\n-        self.activation = nn.ReLU() if activation == \"relu\" else nn.GELU()\r\n-\r\n-    def forward(\r\n-            self,\r\n-            x: torch.Tensor,\r\n-            attn_mask: Optional[torch.Tensor] = None\r\n-    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\r\n-        new_x, attn = self.attention(\r\n-            x, x, x,\r\n-            attn_mask=attn_mask\r\n-        )\r\n-        x = x + self.dropout(new_x)\r\n-        y = x = self.norm1(x)\r\n-        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\r\n-        y = self.dropout(self.conv2(y).transpose(-1,1))\r\n-        return self.norm2(x+y), attn\r\n-\r\n-class Encoder(nn.Module):\r\n-    \"\"\"Informer encoder\"\"\"\r\n-\r\n-    def __init__(\r\n-            self,\r\n-            attn_layers: nn.ModuleList,\r\n-            conv_layers: Optional[nn.ModuleList] = None,\r\n-            norm_layer: Optional[nn.Module] = None\r\n-    ):\r\n-        super(Encoder, self).__init__()\r\n-        self.attn_layers = attn_layers\r\n-        self.conv_layers = conv_layers if conv_layers is not None else None\r\n-        self.norm = norm_layer\r\n-\r\n-    def forward(\r\n-            self,\r\n-            x: torch.Tensor,\r\n-            attn_mask: Optional[torch.Tensor] = None\r\n-    ) -> Tuple[torch.Tensor, list]:\r\n-        attns = []\r\n-        if self.conv_layers is not None:\r\n-            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\r\n-                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n-                x = conv_layer(x)\r\n-                attns.append(attn)\r\n-            x, attn = self.attn_layers[-1](x)\r\n-            attns.append(attn)\r\n-        else:\r\n-            for attn_layer in self.attn_layers:\r\n-                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n-                attns.append(attn)\r\n-\r\n-        if self.norm is not None:\r\n-            x = self.norm(x)\r\n-\r\n-        return x, attns\r\n-\r\n-class Informer(nn.Module):\r\n-    \"\"\"\r\n-    Informer model for time series forecasting\r\n-    \"\"\"\r\n-\r\n-    def __init__(\r\n-            self,\r\n-            input_dim: int,\r\n-            output_dim: int,\r\n-            d_model: int = 512,\r\n-            n_heads: int = 8,\r\n-            e_layers: int = 3,\r\n-            d_ff: int = 512,\r\n-            dropout: float = 0.0,\r\n-            activation: str = 'gelu',\r\n-            distil: bool = True,\r\n-            prediction_window: int = 48,  \r\n-    ):\r\n-        \"\"\"\r\n-        Initialize Informer model\r\n-\r\n-        Args:\r\n-            input_dim: Number of input features\r\n-            output_dim: Number of output features\r\n-            d_model: Model dimension\r\n-            n_heads: Number of attention heads\r\n-            e_layers: Number of encoder layers\r\n-            d_ff: Dimension of feedforward network\r\n-            dropout: Dropout rate\r\n-            activation: Activation function type\r\n-            distil: Whether to use distilling in encoder\r\n-        \"\"\"\r\n-        super(Informer, self).__init__()\r\n-\r\n-        self.input_dim = input_dim\r\n-        self.output_dim = output_dim\r\n-        self.prediction_window = prediction_window\r\n-\r\n-        # Encoding\r\n-        self.enc_embedding = nn.Linear(input_dim, d_model)\r\n-\r\n-        # Encoder\r\n-        encoder_layers = []\r\n-        conv_layers = []\r\n-\r\n-        for i in range(e_layers):\r\n-            encoder_layers.append(\r\n-                EncoderLayer(\r\n-                    AttentionLayer(\r\n-                        ProbAttention(False, attention_dropout=dropout),\r\n-                        d_model, n_heads\r\n-                    ),\r\n-                    d_model,\r\n-                    d_ff,\r\n-                    dropout=dropout,\r\n-                    activation=activation\r\n-                )\r\n-            )\r\n-            if i < e_layers-1 and distil:\r\n-                conv_layers.append(ConvLayer(d_model))\r\n-\r\n-        self.encoder = Encoder(\r\n-            nn.ModuleList(encoder_layers),\r\n-            nn.ModuleList(conv_layers) if distil else None,\r\n-            norm_layer=nn.LayerNorm(d_model)\r\n-        )\r\n-\r\n-        # Output projection\r\n-        self.projection = nn.Linear(d_model, output_dim, bias=True)\r\n-\r\n-    def forward(self, x: torch.Tensor, enc_self_mask: Optional[torch.Tensor] = None):\r\n-        # Encoding\r\n-        enc_out = self.enc_embedding(x)\r\n-        \r\n-        # Encoder\r\n-        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n-        \r\n-        # Output projection\r\n-        output = self.projection(enc_out)\r\n-        \r\n-        # Ensure output matches target length (prediction_window - 1)\r\n-        output = output[:, :self.prediction_window-1, :]\r\n-        \r\n-        return output, attns\r\n-\r\n-    def _init_weights(self):\r\n-        \"\"\"Initialize model weights\"\"\"\r\n-        for p in self.parameters():\r\n-            if p.dim() > 1:\r\n-                nn.init.xavier_uniform_(p)\r\n-            else:\r\n                 nn.init.uniform_(p)\n\\ No newline at end of file\n"
                }
            ],
            "date": 1733312338094,
            "name": "Commit-0",
            "content": "\"\"\"\r\nInformer model implementation for time series forecasting.\r\n\r\nDependencies:\r\n- torch>=2.0.1\r\n\"\"\"\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nfrom typing import Optional, Tuple\r\n\r\nfrom .layers import ProbAttention, AttentionLayer\r\n\r\nclass ConvLayer(nn.Module):\r\n    \"\"\"Convolutional Layer for downsampling\"\"\"\r\n\r\n    def __init__(self, c_in: int):\r\n        super(ConvLayer, self).__init__()\r\n        self.downConv = nn.Conv1d(in_channels=c_in,\r\n                                  out_channels=c_in,\r\n                                  kernel_size=3,\r\n                                  padding=1,\r\n                                  padding_mode='circular')\r\n        self.norm = nn.BatchNorm1d(c_in)\r\n        self.activation = nn.ELU()\r\n        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\r\n\r\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n        x = self.downConv(x.permute(0, 2, 1))\r\n        x = self.norm(x)\r\n        x = self.activation(x)\r\n        x = self.maxPool(x)\r\n        x = x.transpose(1, 2)\r\n        return x\r\n\r\nclass EncoderLayer(nn.Module):\r\n    \"\"\"Encoder layer with self-attention mechanism\"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            attention: nn.Module,\r\n            d_model: int,\r\n            d_ff: Optional[int] = None,\r\n            dropout: float = 0.1,\r\n            activation: str = \"relu\"\r\n    ):\r\n        super(EncoderLayer, self).__init__()\r\n        d_ff = d_ff or 4 * d_model\r\n        self.attention = attention\r\n        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\r\n        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\r\n        self.norm1 = nn.LayerNorm(d_model)\r\n        self.norm2 = nn.LayerNorm(d_model)\r\n        self.dropout = nn.Dropout(dropout)\r\n        self.activation = nn.ReLU() if activation == \"relu\" else nn.GELU()\r\n\r\n    def forward(\r\n            self,\r\n            x: torch.Tensor,\r\n            attn_mask: Optional[torch.Tensor] = None\r\n    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\r\n        new_x, attn = self.attention(\r\n            x, x, x,\r\n            attn_mask=attn_mask\r\n        )\r\n        x = x + self.dropout(new_x)\r\n        y = x = self.norm1(x)\r\n        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\r\n        y = self.dropout(self.conv2(y).transpose(-1,1))\r\n        return self.norm2(x+y), attn\r\n\r\nclass Encoder(nn.Module):\r\n    \"\"\"Informer encoder\"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            attn_layers: nn.ModuleList,\r\n            conv_layers: Optional[nn.ModuleList] = None,\r\n            norm_layer: Optional[nn.Module] = None\r\n    ):\r\n        super(Encoder, self).__init__()\r\n        self.attn_layers = attn_layers\r\n        self.conv_layers = conv_layers if conv_layers is not None else None\r\n        self.norm = norm_layer\r\n\r\n    def forward(\r\n            self,\r\n            x: torch.Tensor,\r\n            attn_mask: Optional[torch.Tensor] = None\r\n    ) -> Tuple[torch.Tensor, list]:\r\n        attns = []\r\n        if self.conv_layers is not None:\r\n            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\r\n                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n                x = conv_layer(x)\r\n                attns.append(attn)\r\n            x, attn = self.attn_layers[-1](x)\r\n            attns.append(attn)\r\n        else:\r\n            for attn_layer in self.attn_layers:\r\n                x, attn = attn_layer(x, attn_mask=attn_mask)\r\n                attns.append(attn)\r\n\r\n        if self.norm is not None:\r\n            x = self.norm(x)\r\n\r\n        return x, attns\r\n\r\nclass Informer(nn.Module):\r\n    \"\"\"\r\n    Informer model for time series forecasting\r\n    \"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            input_dim: int,\r\n            output_dim: int,\r\n            d_model: int = 512,\r\n            n_heads: int = 8,\r\n            e_layers: int = 3,\r\n            d_ff: int = 512,\r\n            dropout: float = 0.0,\r\n            activation: str = 'gelu',\r\n            distil: bool = True,\r\n    ):\r\n        \"\"\"\r\n        Initialize Informer model\r\n\r\n        Args:\r\n            input_dim: Number of input features\r\n            output_dim: Number of output features\r\n            d_model: Model dimension\r\n            n_heads: Number of attention heads\r\n            e_layers: Number of encoder layers\r\n            d_ff: Dimension of feedforward network\r\n            dropout: Dropout rate\r\n            activation: Activation function type\r\n            distil: Whether to use distilling in encoder\r\n        \"\"\"\r\n        super(Informer, self).__init__()\r\n\r\n        self.input_dim = input_dim\r\n        self.output_dim = output_dim\r\n\r\n        # Encoding\r\n        self.enc_embedding = nn.Linear(input_dim, d_model)\r\n\r\n        # Encoder\r\n        encoder_layers = []\r\n        conv_layers = []\r\n\r\n        for i in range(e_layers):\r\n            encoder_layers.append(\r\n                EncoderLayer(\r\n                    AttentionLayer(\r\n                        ProbAttention(False, attention_dropout=dropout),\r\n                        d_model, n_heads\r\n                    ),\r\n                    d_model,\r\n                    d_ff,\r\n                    dropout=dropout,\r\n                    activation=activation\r\n                )\r\n            )\r\n            if i < e_layers-1 and distil:\r\n                conv_layers.append(ConvLayer(d_model))\r\n\r\n        self.encoder = Encoder(\r\n            nn.ModuleList(encoder_layers),\r\n            nn.ModuleList(conv_layers) if distil else None,\r\n            norm_layer=nn.LayerNorm(d_model)\r\n        )\r\n\r\n        # Output projection\r\n        self.projection = nn.Linear(d_model, output_dim, bias=True)\r\n\r\n    def forward(\r\n            self,\r\n            x: torch.Tensor,\r\n            enc_self_mask: Optional[torch.Tensor] = None\r\n    ) -> Tuple[torch.Tensor, list]:\r\n        \"\"\"\r\n        Forward pass\r\n\r\n        Args:\r\n            x: Input tensor of shape [batch_size, seq_length, input_dim]\r\n            enc_self_mask: Optional mask for encoder self-attention\r\n\r\n        Returns:\r\n            Tuple of (output, attention_weights)\r\n        \"\"\"\r\n        # Encoding\r\n        enc_out = self.enc_embedding(x)\r\n\r\n        # Encoder\r\n        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\r\n\r\n        # Output projection\r\n        output = self.projection(enc_out)\r\n        # Ensure the output and target dimensions match\r\n        output = output[:, :x.size(1), :]\r\n\r\n        return output, attns\r\n\r\n    def _init_weights(self):\r\n        \"\"\"Initialize model weights\"\"\"\r\n        for p in self.parameters():\r\n            if p.dim() > 1:\r\n                nn.init.xavier_uniform_(p)\r\n            else:\r\n                nn.init.uniform_(p)"
        }
    ]
}