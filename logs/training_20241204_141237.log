2024-12-04 14:12:38,871 - __main__ - INFO - CUDA Environment:
2024-12-04 14:12:38,871 - __main__ - INFO - {'cuda_available': True, 'cuda_version': '11.8', 'gpu_name': 'NVIDIA GeForce RTX 4060 Laptop GPU', 'pytorch_version': '2.0.1', 'python_version': '3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:15:49) [MSC v.1941 64 bit (AMD64)]', 'gpu_count': 1, 'current_device': 0, 'memory_allocated': '0.00 GB', 'memory_cached': '0.00 GB'}
2024-12-04 14:12:38,871 - __main__ - INFO - Loading and preprocessing data...
2024-12-04 14:12:40,117 - __main__ - INFO - Starting training...
2024-12-04 14:12:40,133 - training.trainer - INFO - 
================================================================================
2024-12-04 14:12:40,133 - training.trainer - INFO - Starting Training
2024-12-04 14:12:40,133 - training.trainer - INFO - ================================================================================
2024-12-04 14:12:52,751 - training.trainer - INFO - 
==================================================
Epoch 0 - Batch Shapes:
Input: torch.Size([32, 192, 8])
Output: torch.Size([32, 48, 1])
Target: torch.Size([32, 192, 1])
==================================================
2024-12-04 14:12:58,985 - training.trainer - INFO - 
============================== Batch 50/1040 ==============================
Average Loss: 1.1763 | Learning Rate: 0.000002
================================================================================
2024-12-04 14:13:00,686 - training.trainer - INFO - 
============================== Batch 100/1040 ==============================
Average Loss: 1.1627 | Learning Rate: 0.000003
================================================================================
2024-12-04 14:13:02,232 - training.trainer - INFO - 
============================== Batch 150/1040 ==============================
Average Loss: 1.1056 | Learning Rate: 0.000005
================================================================================
2024-12-04 14:13:03,783 - training.trainer - INFO - 
============================== Batch 200/1040 ==============================
Average Loss: 1.0985 | Learning Rate: 0.000006
================================================================================
2024-12-04 14:13:05,387 - training.trainer - INFO - 
============================== Batch 250/1040 ==============================
Average Loss: 1.1534 | Learning Rate: 0.000008
================================================================================
2024-12-04 14:13:07,166 - training.trainer - INFO - 
============================== Batch 300/1040 ==============================
Average Loss: 1.0589 | Learning Rate: 0.000010
================================================================================
2024-12-04 14:13:08,723 - training.trainer - INFO - 
============================== Batch 350/1040 ==============================
Average Loss: 1.1015 | Learning Rate: 0.000011
================================================================================
2024-12-04 14:13:10,297 - training.trainer - INFO - 
============================== Batch 400/1040 ==============================
Average Loss: 1.0850 | Learning Rate: 0.000013
================================================================================
2024-12-04 14:13:11,788 - training.trainer - INFO - 
============================== Batch 450/1040 ==============================
Average Loss: 1.0716 | Learning Rate: 0.000014
================================================================================
2024-12-04 14:13:13,282 - training.trainer - INFO - 
============================== Batch 500/1040 ==============================
Average Loss: 1.0225 | Learning Rate: 0.000016
================================================================================
2024-12-04 14:13:14,840 - training.trainer - INFO - 
============================== Batch 550/1040 ==============================
Average Loss: 1.0592 | Learning Rate: 0.000018
================================================================================
2024-12-04 14:13:16,468 - training.trainer - INFO - 
============================== Batch 600/1040 ==============================
Average Loss: 1.0932 | Learning Rate: 0.000019
================================================================================
2024-12-04 14:13:18,053 - training.trainer - INFO - 
============================== Batch 650/1040 ==============================
Average Loss: 1.0695 | Learning Rate: 0.000021
================================================================================
2024-12-04 14:13:19,591 - training.trainer - INFO - 
============================== Batch 700/1040 ==============================
Average Loss: 1.0020 | Learning Rate: 0.000022
================================================================================
2024-12-04 14:13:21,041 - training.trainer - INFO - 
============================== Batch 750/1040 ==============================
Average Loss: 1.1524 | Learning Rate: 0.000024
================================================================================
2024-12-04 14:13:22,503 - training.trainer - INFO - 
============================== Batch 800/1040 ==============================
Average Loss: 1.0980 | Learning Rate: 0.000026
================================================================================
2024-12-04 14:13:24,056 - training.trainer - INFO - 
============================== Batch 850/1040 ==============================
Average Loss: 0.9539 | Learning Rate: 0.000027
================================================================================
2024-12-04 14:13:25,573 - training.trainer - INFO - 
============================== Batch 900/1040 ==============================
Average Loss: 1.0915 | Learning Rate: 0.000029
================================================================================
2024-12-04 14:13:27,070 - training.trainer - INFO - 
============================== Batch 950/1040 ==============================
Average Loss: 1.1294 | Learning Rate: 0.000030
================================================================================
2024-12-04 14:13:28,637 - training.trainer - INFO - 
============================== Batch 1000/1040 ==============================
Average Loss: 1.0569 | Learning Rate: 0.000032
================================================================================
